---
title: "Measure bias correction (linear case)"
format:
  html:
    toc: true
    html-math-method: katex
    css: styles.css
---

```{r}
#| message: false
#| warning: false
library(dplyr)
options(dplyr.summarise.inform = FALSE)
library(tibble)
library(tidyr)
library(glue)
library(tibble)
library(parallel)
library(tictoc)
library(ggplot2)
library(Matrix)
library(progress)
library(marginaleffects)
```

```{r}
devtools::load_all()
```

```{r}
#| echo: false
#| eval: false
load(file = "../results.RData")
```


Linear models on both modes

# Building constants

```{r}
set.seed(145L)
```

```{r}
N <- 1000L
phi <- rep(0.5, N)
```

Creating independent covariates

```{r}
p <- 1L

sex <- sample(c(0L, 1L), replace = TRUE, size = N, prob = c(0.5, 0.5))
age <- rnorm(n = N, mean = sex * 41.1 + (1L - sex) * 43.9, sd = 10.0)
age[age < 0.0] <- 0.0

Z <- data.frame(const = 1.0, 
                age = age, 
                sex = sex)

rm(age)
sex <- factor(sex)
levels(sex) <- c("Woman", "Man")
```

```{r}
summary(Z)
```

```{r}
data <- Z[, c("sex", "age")]
data$sex <- sex
ggplot(data) + 
  geom_density(aes(x = age, colour = sex)) +
  ggtitle("Age ~ sex")
rm(data)
```

```{r}
Z <- as.matrix(Z)
```

Creating parameters for two modes : "int" and "tel". `delta` is defined such that the average measure bias is equal to 1. It depends on `Z`.

```{r}
betaTel <- c(1.0, -0.1, 4.0)
print(betaTel)
delta <- c(1.0, -2.0 * mean(Z[, "age"])^-1L, 2.0 * N / sum(Z[, "sex"]))
betaInt <- betaTel + delta
  

print(betaInt)
```

$Y_{int}$ and $Y_{tel}$ expectations depending on `Z`:

```{r}
data.frame(tel = Z %*% betaTel, int = Z %*% betaInt) %>% 
  pivot_longer(cols = c("tel", "int"), names_to = "mode", values_to = "value") %>% 
  ggplot() + geom_density(aes(x = value, colour = mode))

glue("average value for telephone: {mean(Z %*% betaTel)}")
glue("average value for internet: {mean(Z %*% betaInt)}")
```

```{r}
totBias <- sum(Z %*% delta)
glue("total bias on U: {totBias}")
meanBias <- totBias / N
glue("average bias on U: {meanBias}")
```

We simulate a mode selection MAR (Missing At Random) under a logistic model, with $Z$ as variable:

```{r}
# With MAR

expit <- function(x) 1.0 / (1.0 + exp(-x))

alphaInt <- c(0.7, -0.02, -0.5)
pInt <- expit(Z %*% alphaInt) %>% as.vector()

alphaTel <- c(0.3, 0.02, -0.5)
pTel <- expit(Z %*% alphaTel) %>% as.vector()
```

Here are some details about the $p_{int}$ and $p_{tel}$:

```{r}
data.frame(mode = factor(rep(c("int", "tel"), each = N)), 
           prob = c(pInt, pTel)) %>% 
  ggplot() + 
  geom_density(aes(x = prob, color = mode)) +
  ggtitle("Distribution of p_int and p_tel")
```

```{r}
pInt[sex == "Man"] %>% summary()
pInt[sex == "Woman"] %>% summary()
```

```{r}
cat("internet probabilities:\n")
summary(pInt) %>% print()
cat("telephone probabilities:\n")
summary(pTel) %>% print()
```

# Simulation functions

Randomly affect a mode (or non-response) to each unit

```{r}
gen_choice_bimode <- function(I, p1, p2, checkRank = FALSE, Z = NULL)
{
  N <- length(p1)
  
  R1 <- runif(N) <= p1
  R2 <- runif(N) <= p2
  
  modes <- rep("nr", N)
  
  modes[I & R1] <- "int"
  modes[I & !R1 & R2] <- "tel"
  
  q <- ncol(Z)
  
  # While the rank for the submatrices are not enough
  # we rerun the simulation
  if (checkRank &&
      (rankMatrix(Z[R1, , drop = FALSE]) < q || 
      rankMatrix(Z[!R1 & R2, , drop = FALSE]) < q))
  {
    warning("Rank for submatrices are not enough")
    return(gen_choice_bimode(I, p1, p2, checkRank = TRUE, Z))
  }

  # probSelect : probability of selecting the chosen mode
  # if selected in sample S
  probSelect <- rep(NA_real_, N)
  
  probSelect[R1] <- p1[R1]
  probSelect[!R1 & R2] <- (1.0 - p1[!R1 & R2]) * p2[!R1 & R2]
  
  tibble(p1 = p1, r1 = R1, p2 = p2, r2 = R2, 
         mode = modes, probSelect = probSelect)
}
```

```{r}
gen_ExpY <- function(Z, 
                    betaInt, YintLaw = "gaussian", sdInt,
                    betaTel, YtelLaw = "gaussian", sdTel)
{
  if (YtelLaw == "gaussian")
  {

    expYtels <- as.vector(Z %*% betaTel)
    
    sdTel <- as.numeric(sdTel)
    sdTels <- rep(sdTel, N)
    # covarYtel <- diag(sdTels^2L)
      
  }
  else if (YtelLaw == "exponential")
  {
    sdTel <- "null"

    expYtels <- as.vector(abs(Z %*% betaTel))
    
    sdTels <- expYtels
    
    # covarYtel <- diag(sdTels^2L)
  }
  
  
  if (YintLaw == "gaussian")
  {
    
    expYints <- as.vector(Z %*% betaInt)
    
    sdInt <- as.numeric(sdInt)
    sdInts <- rep(sdInt, N)
    # covarYint <- diag(sdInts^2L)
    
  }
  
  else if (YintLaw == "exponential")
  {
    sdInt <- "null"
    

    expYints <- as.vector(abs(Z %*% betaInt))
    
    sdInts <- expYints
    # covarYint <- diag(sdInts^2L)
  }
  else if (YintLaw == "split3")
  {
    
    if (is.null(expYints))
      expYints <- as.vector(abs(Z %*% betaInt))
    
    quantilesInt <- quantile(expYints, probs = c(1.0 / 3.0, 2.0 / 3.0))
    
    sdInt <- as.numeric(sdInt)
    sdInts <- rep(as.numeric(sdInt), N)
    # covarYint <- diag(sdInts^2L)
    
    # Between first and second quantile of 3rd degree we add one
    expYints[expYints > quantilesInt[1L]] <- 
      expYints[expYints > quantilesInt[1L]] + 1.0
    
    # After the second quantile of 3rd degree we add one more
    expYints[expYints > quantilesInt[2L]] <- 
      expYints[expYints > quantilesInt[2L]] + 1.0
  }
  
  list(expYints = expYints, sdInts = sdInts,
       expYtels = expYtels, sdTels = sdTels)
  
}
```

```{r}
gen_Y <- function(Z, 
                  betaInt, sigmaInt, YintLaw = "gaussian",
                  betaTel, sigmaTel = sigmaInt, YtelLaw = "gaussian",
                  expYints = NULL, expYtels = NULL)
{
  
  N <- nrow(Z)
  
  recExpY <- is.null(expYints) || is.null(expYtels)
  
  if (recExpY)
  {
    dataY <- gen_ExpY(Z, 
                      betaInt, YintLaw, sigmaInt,
                      betaTel, YtelLaw, sigmaTel)
    
    expYints <- dataY$expYints
    sdInts <- dataY$sdInts
    
    expYtels <- dataY$expYtels
    sdTels <- dataY$sdTels
  }
  else
  {
    if (YtelLaw == "gaussian")
      sdTels <- rep(sigmaTel, N)
    else if (YtelLaw == "exponential")
      sdTels <- expYtels
    
    if (YintLaw == "gaussian")
      sdInts <- rep(sigmaInt, N)
    else if (YintLaw == "exponential")
      sdInts <- expYints
  }
  
  
  # Affecting values to Y_int and Y_tel
  if (YtelLaw == "gaussian")
    Ytels <- expYtels + rnorm(n = N, sd = sdTels)
    
  else if (YtelLaw == "exponential")
    Ytels <- rexp(n = N, rate = expYtels^-1L)
  
  if (YintLaw %in% c("gaussian", "split3"))
    Yints <- expYints + rnorm(n = N, sd = sdInts)

  else if (YintLaw == "exponential")
    Yints <- rexp(n = N, rate = expYints^-1L)
  
  
  results <- tibble(Yint = Yints, Ytel = Ytels)
  
  if (recExpY)
  {
    results <- results %>%
    mutate(expYint = expYints, .before = "Yint") %>% 
    mutate(expYtel = expYtels, .before = "Ytel")
  }
  
  results
}
```

```{r}
set_Yobs <- function(Yint, Ytel, modes)
{
  N <- length(Yint)
  
  Yobs <- rep(NA_real_, N)
  Yobs[modes == "int"] <- Yint[modes == "int"]
  Yobs[modes == "tel"] <- Ytel[modes == "tel"]
  
  Yobs
}
```

```{r}
set_phi <- function(phi = "eq", N)
{
  if (phi == "eq")
    phi <- rep(0.5, N)
  
  else if (phi == "1/3")
    phi <- rep(1.0 / 3.0, N)
  
  else if (phi == "2/3")
    phi <- rep(2.0 / 3.0, N)

  else if (phi == "var")
    phi <- seq_len(N) / N
  
  # When there is no bias, phi = 0.5
  # When the bias increase (in absolute), phi tends to zero
  # (it gives more weights to the unbiased value)
  else if (phi == "linear")
  {
    expDeltas <- expYints - expYtels
    maxBias <- max(abs(expDeltas))
    phi <- 0.5 - 0.5 * abs(expDeltas) / maxBias
  }
  else if (phi == "split3")
  {
    expDeltas <- expYints - expYtels
    absExpDeltas <- abs(expDeltas)
    quantiles <- quantile(absExpDeltas, c(1.0 / 3.0, 2.0 / 3.0))
    phi <- rep(0.5, N)
    phi[absExpDeltas >= quantiles[1L]] <- 1.0 / 3.0
    phi[absExpDeltas >= quantiles[2L]] <- 1.0 / 6.0
  }
    
  phi
}
```

Parameters:

-   `meanZ` and `varZ` if `Z` is variable (i.e. `fixZ == FALSE`). constant Z can be given with `Z`
-   $\alpha_{tel}$ and $\alpha_min$, coefficients of conditional expectations of $r_{tel}$ and $r_{int}$
-   $\beta_{tel}$ and $\beta_{int}$, coefficients of conditional expectations of $Y_{tel}$ and $Y_{int}$
-   the sampling type (`sampling`)
-   the conditional standard deviations of $Y_{tel}$ and $Y_{int}$ (`sdInt` and `sdTel`)
-   the law of $Y_{tel}$ (`YtelLaw`)
-   the law of $Y_{int}$ (`YintLaw`)
-   the state of $\phi$ (`phi`)
-   the number of iterations (`K`)
-   the random seed (`seed`)

```{r}
simulationUncounf <- 
  function(N, 
           sampling = "SRS",
           alphaInt, alphaTel, 
           betaInt, betaTel, 
           YintLaw = "gaussian", YtelLaw = "gaussian",
           sdInt = 1.0, sdTel = 1.0, 
           phi = rep(0.5, N), K = 1000L,
           Z = NULL,
           n = ceiling(N / 4L),
           seed = 123L,
           cluster = NULL)
  {
    
    stopClusterAtEnd <- is.null(cluster)
    # Z is exported only if the cluster is created in the function
    if (is.null(cluster))
    {
      nbCores <- detectCores() - 1L
      cluster <- makeCluster(nbCores)
    
      clusterExport(cluster, 
                    varlist = "Z",
                    envir = environment())
    }
    
    
    # Making clusters random-independants
    clusterSetRNGStream(cl = cluster, iseed = seed)
    
    clusterEvalQ(cluster, library(dplyr))
    clusterEvalQ(cluster, library(Matrix))
    clusterEvalQ(cluster, library(tibble))
    clusterEvalQ(cluster, library(marginaleffects))
    clusterEvalQ(cluster, library(MMsampling))
    
    clusterExport(cluster, varlist = c("sampling", 
                                       "betaInt", "betaTel", 
                                       "YintLaw", "YtelLaw", 
                                       "sdInt", "sdTel", 
                                       "n"),
                  envir = environment())
    
    expit <- function(x) 1.0 / (1.0 + exp(-x))

    pInt <- expit(Z %*% alphaInt) %>% as.numeric()
    pq1Mat <- pInt %*% t(pInt)
    diag(pq1Mat) <- pInt
    
    pTel <- expit(Z %*% alphaTel) %>% as.numeric()
    pq2Mat <- pTel %*% t(pTel)
    diag(pq2Mat) <- pTel
    
    clusterExport(cluster, 
                  varlist = c("pInt", "pq1Mat", "pTel", "pq2Mat"),
                  envir = environment())
    

    if (sampling == "SRS")
    {
      pi <- rep(n / N, N)
      piMat <- matrix(n * (n - 1L) / (N * (N - 1L)), nrow = N, ncol = N)
      diag(piMat) <- n / N
      
      clusterExport(cluster, 
                    varlist = c("pi", "piMat"),
                    envir = environment())
    }
    
    
    dataExpY <- gen_ExpY(Z, 
                         betaInt, YintLaw, sdInt,
                         betaTel, YtelLaw, sdTel)
    
    expYints <- dataExpY$expYints
    sdInts <- dataExpY$sdInts
    
    expYtels <- dataExpY$expYtels
    sdTels <- dataExpY$sdTels
    
    rm(dataExpY)
    
    
    # if (YtelLaw == "gaussian")
    # {
    #   expYtels <- as.vector(Z %*% betaTel)
    # }
    # else if (YtelLaw == "exponential")
    # {
    #   sdTel <- "null"
    #   expYtels <- as.vector(abs(Z %*% betaTel))
    # }
    # 
    # expTotTel <- sum(expYtels)
    # 
    # if (YintLaw == "gaussian")
    #   expYints <- as.vector(Z %*% betaInt)
    #   
    # else if (YintLaw == "exponential")
    # {
    #   sdInt <- "null"
    #   expYints <- as.vector(abs(Z %*% betaInt))
    # }
    # else if (YintLaw == "split3")
    # {
    #   expYints <- as.vector(Z %*% betaInt)
    #   quantilesInt <- quantile(expYints, probs = c(1.0 / 3.0, 2.0 / 3.0))
    #   
    # 
    #   sdInt <- as.numeric(sdInt)
    #   sdInts <- rep(as.numeric(sdInt), N)
    #   covarYint <- diag(sdInts^2L)
    #   
    #   # Between first and second quantile of 3rd degree we add one
    #   expYints[expYints > quantilesInt[1L]] <- 
    #     expYints[expYints > quantilesInt[1L]] + 1.0
    #   
    #   # After the second quantile of 3rd degree we add one more
    #   expYints[expYints > quantilesInt[2L]] <- 
    #     expYints[expYints > quantilesInt[2L]] + 1.0
    # }
    
    expTotYtel <- sum(expYtels)
    expTotYint <- sum(expYints)
    
    clusterExport(cluster,
                  varlist = c("expYtels", "expTotYtel",
                              "expYints", "expTotYint",
                              "sdInts", "sdTels"),
                  envir = environment())
    
    clusterExport(cluster, c("gen_choice_bimode", 
                  "gen_ExpY", "gen_Y", "set_Yobs", "set_phi"))
      
    
    if (class(phi) == "character")
      phiType <- phi
    else
      phiType <- "vector"
    
    phi <- set_phi(phi, N)
    
    # if (class(phi) == "character")
    #   phiType <- phi
    # else
    #   phiType <- "vector"
    # 
    # if (phi == "eq")
    #   phi <- rep(0.5, N)
    # 
    # else if (phi == "1/3")
    #   phi <- rep(1.0 / 3.0, N)
    # 
    # else if (phi == "2/3")
    #   phi <- rep(2.0 / 3.0, N)
    # 
    # else if (phi == "var")
    #   phi <- seq_len(N) / N
    
    # # When there is no bias, phi = 0.5
    # # When the bias increase (in absolute), phi tends to zero
    # # (it gives more weights to the unbiased value)
    # else if (phi == "linear")
    # {
    #   expDeltas <- expYints - expYtels
    #   maxBias <- max(abs(expDeltas))
    #   phi <- 0.5 - 0.5 * abs(expDeltas) / maxBias
    # }
    # else if (phi == "split3")
    # {
    #   expDeltas <- expYints - expYtels
    #   absExpDeltas <- abs(expDeltas)
    #   quantiles <- quantile(absExpDeltas, c(1.0 / 3.0, 2.0 / 3.0))
    #   phi <- rep(0.5, N)
    #   phi[absExpDeltas >= quantiles[1L]] <- 1.0 / 3.0
    #   phi[absExpDeltas >= quantiles[2L]] <- 1.0 / 6.0
    # }
      
    
    clusterExport(cluster, 
                  varlist = "phi", 
                  envir = environment())
    
    monoSim <- function(...)
    {
      nbExperiments <- 12L
      
      partialResults <- data.frame(parameter = character(nbExperiments),
                                   trueEstimator = logical(nbExperiments),
                                   probSelect = character(nbExperiments),
                                   invMatrices = character(nbExperiments),
                                   calculTotal = character(nbExperiments),
                                   estPhiBias = numeric(nbExperiments))
      
      row <- 1L
      
      q <- ncol(Z)
        
      
      if (sampling == "SRS")
      {
        selectedSample <- sample(seq_len(N), size = n, replace = FALSE)
        
        I <- logical(N)
        I[selectedSample] <- TRUE
        rm(selectedSample)
      }
      
      # Mode selection simulation
      # modeChoiceOK <- FALSE
      # 
      # while (!modeChoiceOK)
      # {
      #   # modeChoiceOK <- TRUE
      #   
      #   dataModes <- gen_choice_bimode(I, pInt, pTel)
      #   modes <- dataModes$mode
      #   maskInt <- modes == "int"
      #   nInt <- sum(maskInt)
      #   maskTel <- modes == "tel"
      #   nTel <- sum(maskTel)
      #   trueProbsSelect <- dataModes$probSelect
      #   
      #   if (rankMatrix(Z[maskInt, , drop = FALSE]) == q &&
      #       rankMatrix(Z[maskTel, , drop = FALSE]) == q)
      #     modeChoiceOK <- TRUE
      #   else
      #     warning("Singular Zint / Ztel")
      #   
      # }
      
      dataModes <- gen_choice_bimode(I, pInt, pTel)
      modes <- dataModes$mode
      
      maskInt <- modes == "int"
      nInt <- sum(maskInt)
      maskTel <- modes == "tel"
      nTel <- sum(maskTel)
      
      trueProbsSelect <- dataModes$probSelect
      
      rm(dataModes)
      
      trueWeights <- (pi * trueProbsSelect)^-1L
    
      # Estimation of mode selection probabilities
      estimProbsSelect <- 
        MMsampling::estim_response_prob_sequential(I, pi, Z,
                                                   modes, 
                                                   c("int", "tel"))$unconditional
    
      estimWeights <- (pi * estimProbsSelect)^-1L
      
      # Generating values for Y_int and Y_tel
      dataY <- gen_Y(Z, 
                     betaInt, sdInt, YintLaw,
                     betaTel, sdTel, YtelLaw,
                     expYints = expYints, expYtels = expYtels)
      
      Yints <- dataY$Yint
      Ytels <- dataY$Ytel
      
      rm(dataY)
      
      # Creating the observed outcome vector
      Yobs <- set_Yobs(Yint = Yints, Ytel = Ytels, modes = modes)
      
      #  # Affecting values to Y_int and Y_tel
      # if (YtelLaw == "gaussian")
      # {
      #   Ytels <- expYtels + rnorm(n = N, sd = sdTels)
      # }
      #   
      # 
      # else if (YtelLaw == "exponential")
      #   Ytels <- rexp(n = N, rate = expYtels^-1L)
      # 
      # expTotYtel <- sum(expYtels)
      # trueYtel <- sum(Ytels)
      # 
      # if (YintLaw %in% c("gaussian", "split3"))
      #   Yints <- expYints + rnorm(n = N, sd = sdInts)
      # 
      # else if (YintLaw == "exponential")
      #   Yints <- rexp(n = N, rate = expYints^-1L)
      
      trueYtel <- sum(Ytels)
      deltas <- Yints - Ytels
      
      # Evaluating the measure bias total (random value)
      truePhiBias <- crossprod(phi, deltas) %>% as.vector()
      expPhiBias <- crossprod(phi, expYints - expYtels) %>% as.vector()
      
      # Creating the observed outcome vector
      # Yobs <- rep(NA_real_, N)
      # Yobs[maskInt] <- Yints[maskInt]
      # Yobs[maskTel] <- Ytels[maskTel]
      
      sample <- MMsampling:::MMSample$new(Z = Z, pi = pi, I = I, 
                             modes = modes, Yobs = Yobs, phi = phi)
      
      # Full HT estimation, with full population matrix (Z^tZ)^-1 and
      # known probabilities
      resEval <-
        estim_delta_MCO(sample$Z, sample$Yobs, sample$modes,
                               "int", "tel", "HT", "HT", pi,
                        trueProbsSelect, sampleMatrix = FALSE) %>%
        estim_MB_by_MCO(Z, phi = phi) %>%
        sum()
      
  
      partialResults[row,] <- 
        c(parameter = "HT", trueEstimator = FALSE,
          probSelect = "true", invMatrices = "population",
          calculTotal = "population", estPhiBias = resEval)
      
      row <- row + 1L
  
      # Full HT estimation, with sample matrix (Z_S^TZ_S)^-1 and
      # known probabilities
      resEval <-
        estim_delta_MCO(sample$Z, sample$Yobs, sample$modes,
                               "int", "tel", "HT", "HT", pi,
                        trueProbsSelect, sampleMatrix = TRUE) %>%
        estim_MB_by_MCO(Z, phi = phi) %>%
        sum()
  
      partialResults[row,] <- c(parameter = "HT", trueEstimator = FALSE,
                                probSelect = "true", invMatrices = "samples", 
                                calculTotal = "population", estPhiBias = resEval)
      
      row <- row + 1L
      

      # Estimation on a unique MCO for Y1 and Y2, with beta X and only a constant
      # delta for the estimation of the measure bias
      deltaEval <- 
        estim_delta_MCO_unique_model_const(Z, Yobs, modes, "int", "tel")
      resEvalFull <- sum(phi) * deltaEval
      resEvalHT <- 
        as.vector(crossprod(phi[maskInt],
                            estimWeights[maskInt]) * 
                    deltaEval)
      
      
      partialResults[c(row, row + 1L),] <- 
        data.frame(parameter = "G-COMP_0_deg",
                   trueEstimator = TRUE,
                   probSelect = "null",
                   invMatrices = "null",
                   calculTotal = c("population", "sample"),
                   estPhiBias = c(resEvalFull, resEvalHT))
      
      
      row <- row + 2L
      
      
      # G-COMP first degree estimation, <=> double MCO estimation
      # tic()
      # estimdelta <- estim_delta_MCO(sample$Z, sample$Yobs, sample$modes, 
      #                   "int", "tel", "MCO", "MCO", pi, NULL)
      estMBs <- estim_delta_MCO(sample$Z, sample$Yobs, sample$modes, 
                                "int", "tel", "G-COMP", "G-COMP", pi, NULL, 
                                returnMB = TRUE, order = 1L)
      
      resEvalFull <- crossprod(phi, estMBs) %>% as.vector()
      
      resEvalHT <- crossprod(phi[maskInt] * estimWeights[maskInt],
                             estMBs[maskInt]) %>% as.vector()
      # toc() %>% print()
      
      
      
      partialResults[c(row, row + 1L),] <- 
        data.frame(parameter = "G-COMP_1_deg", trueEstimator = TRUE,
                   probSelect = "null", 
                   invMatrices = "null", calculTotal = c("population", "sample"),
                   estPhiBias = c(resEvalFull, resEvalHT))
      
      row <- row + 2L
      
      # G-COMP two degrees estimation
      # tic()
      estMBs <- estim_delta_MCO(sample$Z, sample$Yobs, sample$modes, 
                                "int", "tel", "G-COMP", "G-COMP", pi, NULL, 
                                returnMB = TRUE, order = 2L)
      
      resEvalFull <- crossprod(phi, estMBs) %>% as.vector()
      
      resEvalHT <- crossprod(phi[maskInt] * estimWeights[maskInt],
                             estMBs[maskInt]) %>% as.vector()
      # toc() %>% print()
      
      
      
      partialResults[c(row, row + 1L),] <- 
        data.frame(parameter = "G-COMP_2_deg", trueEstimator = TRUE,
                   probSelect = "null", 
                   invMatrices = "null", calculTotal = c("population", "sample"),
                   estPhiBias = c(resEvalFull, resEvalHT))
      
      row <- row + 2L
      
      
      
      # Full HT estimation, with full population matrix (Z^tZ)^-1 and
      # unknown probabilities
      # tic()
      estimdelta <- 
        estim_delta_MCO(sample$Z, sample$Yobs, sample$modes, 
                        "int", "tel", "HT", "HT", pi, 
                        estimProbsSelect, sampleMatrix = FALSE)
      
      resEvalFull <- estimdelta %>% 
        estim_MB_by_MCO(Z, phi = phi) %>% 
        sum()
      
      resEvalHT <- estimdelta %>% 
        estim_MB_by_MCO(Z, 
                        phi = phi, 
                        weights = estimWeights,
                        mask = maskInt) %>% 
        sum()
    
      # toc() %>% print()
     
      
      partialResults[c(row, row + 1L),] <- 
        data.frame(parameter = "HT", trueEstimator = TRUE,
                   probSelect = "estimation", invMatrices = "population", 
                   calculTotal = c("population", "sample"), 
                   estPhiBias = c(resEvalFull, resEvalHT))
      
      row <- row + 2L
      
      # Full HT estimation, with sample matrix (Z_S^TZ_S)^-1 and
      # unknown probabilities
      # tic()
      estimdelta <- 
        estim_delta_MCO(sample$Z, sample$Yobs, sample$modes, 
                        "int", "tel", "HT", "HT", pi, 
                        estimProbsSelect, sampleMatrix = TRUE) 
      
      
      resEvalFull <- estimdelta %>% 
        estim_MB_by_MCO(Z, phi = phi) %>% 
        sum()
      
      resEvalHT <- estimdelta %>% 
        estim_MB_by_MCO(Z, 
                        phi = phi, 
                        weights = estimWeights, 
                        mask = maskInt) %>% 
        sum()
    
      # toc() %>% print()
      
      partialResults[c(row, row + 1L),] <- 
        data.frame(parameter = "HT", trueEstimator = TRUE,
                   probSelect = "estimation", invMatrices = "samples", 
                   calculTotal = c("population", "sample"), 
                   estPhiBias = c(resEvalFull, resEvalHT))
      
      row <- row + 2L
      
      # Estimations of t_phi1 and t_phi2
      # - With true weights
      estTotPhiYintHTTrueMP <- 
        phi[maskInt] * 
        trueWeights[maskInt] * 
        Yints[maskInt]
      
      estTotPhiYintHTTrueMP <- sum(estTotPhiYintHTTrueMP)
      
      estTotPhiYtelHTTrueMP <- 
        (1.0 - phi[maskTel]) * 
        trueWeights[maskTel] * 
        Ytels[maskTel]
      
      # - With estimated weights
      estTotPhiYtelHTTrueMP <- sum(estTotPhiYtelHTTrueMP)
    
      estTotPhiYintHTEstMP <-
        phi[maskInt] *
        estimWeights[maskInt] *
        Yints[maskInt]
    
      estTotPhiYintHTEstMP <- sum(estTotPhiYintHTEstMP)
    
      estTotPhiYtelHTEstmMP <-
        (1.0 - phi[maskTel]) *
        estimWeights[maskTel] *
        Ytels[maskTel]
    
      estTotPhiYtelHTEstmMP <- sum(estTotPhiYtelHTEstmMP)
      
      estPhiYtelEstMP <-
        phi[maskTel] *
        estimWeights[maskTel] *
        Ytels[maskTel]
      
      estPhiYtelEstMP <- sum(estPhiYtelEstMP)
      
      normEstPhiBiasDiffHT <-
        (estTotPhiYintHTEstMP - estPhiYtelEstMP) / sum(phi)
      
      # Don't know why but some columns are
      #  automatically converted as character
      partialResults$estPhiBias <- as.numeric(partialResults$estPhiBias)
      partialResults$trueEstimator <- as.logical(partialResults$trueEstimator)
      # Value estimated only on telephone answers, with estimated selection probabilities
      benchmark <- crossprod(estimWeights[maskTel], Ytels[maskTel]) %>% 
        as.vector()
      trueWeightsBenchmark <- crossprod(trueWeights[maskTel], Ytels[maskTel]) %>% 
        as.vector()

      
      partialResults <- partialResults %>% 
        add_column(.before = 1L, expn = sum(pi)) %>% 
        add_column(.after = "expn", n = sum(I)) %>% 
        add_column(.after = "n", nInt = nInt) %>% 
        add_column(.after = "nInt", nTel = nTel) %>% 
        add_column(.after = "nTel", expYint = expTotYint) %>% 
        add_column(.after = "expYint", trueYtel = trueYtel) %>% 
        add_column(.after = "trueYtel", expYtel = expTotYtel) %>% 
        add_column(.before = "estPhiBias", truePhiBias = truePhiBias) %>% 
        add_column(.adter = "estPhiBias", normEstPhiBiasDiffHT = normEstPhiBiasDiffHT) %>% 
        add_column(.after = "truePhiBias", expPhiBias = expPhiBias) %>% 
        add_column(.after = "expPhiBias", 
                   estPhiYintTrueMP = estTotPhiYintHTTrueMP) %>% 
        add_column(.after = "estPhiYintTrueMP", avgEstWeightsInt = mean(trueWeights[maskInt])) %>% 
        add_column(.after = "estPhiYintTrueMP", 
                   estPhiYintEstMP = estTotPhiYintHTEstMP) %>% 
        add_column(.after = "estPhiYintEstMP", avgEstWeightsTel = mean(trueWeights[maskTel])) %>%
        add_column(.after = "avgEstWeightsTel", estPhiYtelEstMP = estPhiYtelEstMP) %>% 
        add_column(.after = "estPhiYtelEstMP", 
                   estPhiBarYtelTrueMP = estTotPhiYtelHTTrueMP) %>% 
        add_column(.after = "estPhiBarYtelTrueMP", 
                   estPhiBarYtelEstMP = estTotPhiYtelHTEstmMP) %>% 
        mutate(.after = "estPhiBarYtelEstMP",
               estYtelTrueMP = estPhiYintTrueMP + 
                 estPhiBarYtelTrueMP -
                 estPhiBias) %>% 
        mutate(.after = "estYtelTrueMP", 
               estYtelEstMP = estPhiYintEstMP + 
                 estPhiBarYtelEstMP -
                 estPhiBias) %>% 
        add_column(.after = "estYtelEstMP", benchmark = benchmark) %>% 
        add_column(.after = "benchmark", TWBenchmark = trueWeightsBenchmark)
        
      #results <- rbind(results, partialResults)
    }
    
    clusterExport(cluster, 
                  varlist = "monoSim", 
                  envir = environment())
    
    #results <- lapply(X = seq_len(K), FUN = monoSim)
    results <- parLapply(cluster, X = seq_len(K), fun = monoSim)
    
    if (stopClusterAtEnd)
      stopCluster(cluster)
      

    parameters <- results[[1L]] %>% 
    select(parameter, probSelect, invMatrices, calculTotal)
    
    parameters[, c("expVar2", "expVarPhi1", "expVarPhi2", 
                   "expCovarPhi12", "expVarPhiDelta", 
                   "expCovarPhi1Delta", "expCovarPhi2Delta")] <- NA_real_
  
    for (l in seq_len(nrow(parameters)))
    {
      parameter <- parameters[l, ]
      
      if (parameter$parameter == "HT" && 
          parameter$probSelect == "true" &&
          parameter$invMatrices == "population" && 
          parameter$calculTotal == "population")
      {
        expVars <- var_estim_tot_BM(modeTotBiased = "HT", modeTotRef = "HT",
                                    calculTotal = "population",
                                    expY1 = expYints, expY2 = expYtels,
                                    covarY1 = covarYint, covarY2 = covarYtel,
                                    piMat = piMat,
                                    pq1Mat = pq1Mat, pq2Mat = pq2Mat,
                                    phi = phi,
                                    subResults = TRUE)
        
        parameters[l, names(expVars)] <- expVars
      }
    }
    
    
    results <- do.call("rbind", results)
    
    if (any((betaInt - betaTel)[-1L] != 0.0))
        MBtype <- "variable"
      else
        MBtype <- "constant"
    
    results <- results %>% 
      add_column(.before = "n", sampling = sampling) %>% 
      add_column(.before = "sampling", N = N) %>% 
      add_column(.after = "n", YtelLaw = factor(YtelLaw)) %>% 
      add_column(.after = "YtelLaw", sdTel = sdTel) %>% 
      add_column(.after = "YtelLaw", YintLaw = factor(YintLaw)) %>% 
      add_column(.after = "YintLaw", sdInt = sdInt) %>% 
      add_column(.after = "YintLaw",
                 MBtype = factor(MBtype)) %>% 
      add_column(.after = "MBtype", phi = factor(phiType))
    

    suppressMessages(results <- results %>% inner_join(parameters, by = NULL))
    
      
    # We calculate the real variance of the benchmark estimator
    sdTWBenchmark <- var_HT_seq_phi2(expY2 = expYtels, 
                                     covarY2 = covarYtel,
                                     piMat = piMat,
                                     pq1Mat = pq1Mat,
                                     pq2Mat = pq2Mat,
                                     phi = numeric(N),
                                     correcEstimWeights = FALSE) %>% sqrt()
    
    results <- results %>% 
      mutate(expSDTWBenchmark = sdTWBenchmark)
    
    
    results
  }
```

-   `trueYtel`: $t_{tel} =\sum_{k \in U} y_{2k}$ for this iteration
-   `expYtel` : $\mathbb{E}[t_{tel}]=\mathbb{E} [\sum_{k \in U} y_{2k}]$
-   `estPhiBias` : $t_{\phi \hat{\Delta y}}$
-   `estPhiBiasDiffHT` : $\hat{t}_{\hat{p},\phi y_1} - \hat{t}_{\hat{p},\phi y_2}$
-   `truePhiBias` : $t_{\phi\Delta y}=\sum_{k\in U} \phi_k \Delta y_k$
-   `expPhiBias` : $\mathbb{E}[t_{\phi\Delta y}]$
-   `estPhiYintTrueMP` : $\hat{t}_{p,\phi y_1} = \sum_{k \in S_r}\frac{\phi_k y_{1k}}{\pi_k p_{1k}}$
-   `estPhiYintEstMP` : $\hat{t}_{\hat{p},\phi y_1} = \sum_{k \in S_r}\frac{\phi_k y_{1k}}{\pi_k \hat{p}_{1k}}$
-   `estYtelTrueMP` : $\hat{t}_{py_2}:= \hat{t}_{p,\phi y_1} + \hat{t}_{p,\bar{\phi} y_2} - t_{\phi \hat{\Delta y}}$
-   `estYtelEstMP` : $\hat{t}_{\hat{p}y_2}:= \hat{t}_{\hat{p},\phi y_1} + \hat{t}_{\hat{p},\bar{\phi} y_2} - t_{\phi \hat{\Delta y}}$
-   `expVar2` : $\mathbb{V}[\hat{t}_{\hat{p}y_2}]$ PAS ENCORE VRAI, À CONSIDÉRER
-   `TWBenchmark` : $\sum_{k \in S_{mr}} \frac{y_{2k}}{\pi_k(1-p_{1k})p_{2k}}$
-   `benchmark` : $\sum_{k \in S_{mr}} \frac{y_{2k}}{\pi_k(1-\hat{p}_{1k})\hat{p}_{2k}}$
-   `sdTWBenchmark` : standard deviation of the benchmark
-   `calculTotal` : `population` if we calculate $\hat{t}_{\phi \hat{\Delta y}}$ (imputation on the entire population), `sample` if it is $t_{\phi \hat{\Delta y}}$ (on $S_{r\bullet}$)


```{r}
#| echo: false
loop_simulation <- function(parameters, K = 2000L)
{
  nbCores <- detectCores() - 1L
  cluster <- makeCluster(nbCores)
  
  clusterExport(cluster, 
                varlist = "Z",
                envir = environment())

  results <- NULL
  nbResults <- 0L
  
  parameters <- parameters %>% distinct()
  
  betaTelMinus <- betaTel
  betaIntMinus <- betaInt
  
  # Case when the sign a the age coefficient for telephone is positive
  betaTelPlus <- betaTel
  betaTelPlus[-1L] <- -betaTel[-1L]
  betaIntPlus <- betaInt
  betaIntPlus[-1L] <- -betaInt[-1L]
  
  bar <- progress_bar$new(total = nrow(parameters),
                          format = "[:bar] :current/:total (:percent) eta: :eta")
  
  for (i in seq_len(nrow(parameters)))
  {
    tic()
    expParams <- parameters[i, ]
    #print(expParams)
  
    
    if (expParams$signAge == "plus")
    {
      betaIntTemp <- betaIntPlus
      betaTelTemp <- betaTelPlus
    }
    else if (expParams$signAge == "minus")
    {
      betaIntTemp <- betaIntMinus
      betaTelTemp <- betaTelMinus
    }
    
    if (expParams$constBias)
      betaIntTemp[-1L] <- betaTelTemp[-1L]
    
    expResults <- simulationUncounf(N, K = K,
                                    Z = Z,
                                    sampling = expParams$sampling,
                                    alphaInt = alphaInt,
                                    alphaTel = alphaTel,
                                    betaInt = betaIntTemp,
                                    betaTel = betaTelTemp,
                                    YtelLaw = expParams$YtelLaw,
                                    YintLaw = expParams$YintLaw,
                                    phi = expParams$phi,
                                    sdInt = expParams$sdY,
                                    sdTel = expParams$sdY,
                                    seed = 200L,
                                    cluster = cluster)
    
    expResults <- expResults %>% 
      rename(sd = sdInt) %>% 
      select(-sdTel) %>% 
      mutate(signAge = expParams$signAge)
  
    if (i == 1L)
      expNbResults <- nrow(expResults)
    
    nbResults <- nbResults + expNbResults
    expResults <- expResults %>% 
      add_column(.before = 1L, 
                 experiment = factor(rep(nbResults + seq_len(K), 
                                         each = expNbResults / K)))
    
    results <- rbind(results, expResults)
    
    #t <- toc(quiet = TRUE)
    
    #glue("{round(unname(t$toc - t$tic))}s ({i} / {nrow(parameters)})") %>% print()
    bar$tick()
  }
  
  stopCluster(cluster)
  
  results$signAge <- as.factor(results$signAge)
  results$parameter <- as.factor(results$parameter)
  results$probSelect <- as.factor(results$probSelect)
  results$invMatrices <- as.factor(results$invMatrices)
  results$calculTotal <- as.factor(results$calculTotal)
  
  results <- results %>% 
    mutate(.after = "estPhiBias", diffPhiBias = estPhiBias - truePhiBias) %>% 
    mutate(.after = "estPhiBarYtelEstMP", 
           diffYtelEstMP = estYtelEstMP - trueYtel) %>% 
    mutate(.after = "estPhiBarYtelTrueMP",
           diffYtelTrueMP = estYtelTrueMP - trueYtel) %>% 
    mutate(.after = "diffYtelTrueMP", 
           diffWithoutCorrectionEstMP = estPhiYintEstMP + 
             estPhiBarYtelEstMP - 
             trueYtel) %>% 
    mutate(.after = "diffYtelTrueMP", diffBenchmark = benchmark - trueYtel)
  
  results
}
```

# Measure bias evaluation

Evaluation of $K$ experiments:

```{r}
K <- 10L
Kvec <- seq_len(K)
```

```{r}
#| eval: false

load(file = "../results.RData")
```

Here we evaluate our estimators on the simplest cases : Gaussian laws with $\phi_k \equiv \frac{1}{2}$, a few values for $\sigma$ and a changing sign for $\beta_{tel,age}$.

```{r}
#| eval: false
# Grid of all evaluated parameters
parameters <- expand_grid(constBias = c(TRUE, FALSE),
                          sampling = "SRS",#c("SRS", "STSRS"),
                          YtelLaw = "gaussian",
                          YintLaw = "gaussian",
                          signAge = c("plus", "minus"),
                          phi = "eq",
                          sdY = 1.0) %>%
  # If there is only exponential laws the parameter sdY is of no interest
  mutate(sdY =
           ifelse(YtelLaw == "gaussian" |
                    YintLaw == "gaussian", sdY, "null")) 

resultsGaussian <- loop_simulation(parameters, K = K)
```

# Ex : Gaussian constant measure bias

Results of each parameter for the case of SRS with **constant** measure bias, $\beta_{tel,age} > 0$ and Gaussian laws (with $\sigma =1$).

## Measure bias total

$$\text{relError} = \frac{1}{K}\sum_{k=1}^K \frac{\hat{t}_{\phi\Delta y,k}-t_{\phi\Delta y,k}}{\mathbb{E}[t_{\phi\Delta y}]}$$

$$\text{relRMSE} = \frac{\sqrt{\frac{1}{K}\sum_{k=1}^K (\hat{t}_{\phi\Delta y,k}-t_{\phi\Delta y,k})^2}}{|\mathbb{E}[t_{\phi\Delta y}]|}$$

```{r}
temp <- resultsGaussian %>% 
  filter(YtelLaw == "gaussian", YintLaw == "gaussian", 
         sampling == "SRS", 
         MBtype == "constant", signAge == "plus", 
         trueEstimator) %>% 
  select(-sampling, -MBtype, -probSelect) %>% 
  group_by(parameter, invMatrices, calculTotal)

temp %>% 
  summarise(K = n(),
            relErrorWithoutCorr = round(mean(diffWithoutCorrectionEstMP / abs(expYtel)), 4L),
            relError = round(mean(diffPhiBias / abs(expPhiBias)), 4L), 
            relRMSE = round(sqrt(mean(diffPhiBias^2L / expPhiBias^2L)), 4L)) %>% 
  ungroup() %>% 
  arrange(relRMSE)
```

The relative error `relError` is close to zero for each estimator. It is clear that it is an improvement compared to the estimator that totally neglect the bias, i.e. $\hat{t}_{pq\phi1}-\hat{t}_{pq\bar{\phi}2}$. RMSEs are about the same, being in \[0.13, 0.18\]. For the best RMSE we have the model that consider the bias constant (up to a centered noise): the G-COMP model with a simple constant $\delta$ for the MB consideration.

## telephone total estimation

Our different estimators are all approximately unbiased, so we focus on the RMSE appearing when we estimate the total $t_2$ with each estimator:


```{r}
temp %>% 
  summarise(K = n(),
            relEstRMSE = round(sqrt(mean(diffYtelEstMP^2L / expYtel^2L)), 4L),
            relEstRMSEBenchmark = round(sqrt(mean(diffBenchmark^2L / expYtel^2L)), 4L),
            relExpRMSETWBenchmark = mean(expSDTWBenchmark / abs(expYtel))) %>% 
  ungroup() %>% 
  arrange(relEstRMSE)

rm(temp)
```

The `relEstRMSEBenchmark` variable is the estimated RMSE of the benchmark estimator. We can observe that among the different estimators, we have a few of them that offer a **lower RMSE than the benchmark**. We have, with $\phi \equiv \frac{1}{2}$ :

-   G-COMPUTATION with 0, 1 or 2 degrees and a estimation of the total $\phi\Delta$ via the sample or the population

-   The HT Thompson estimator with sample inverse matrices and a total on the sample or the population

Summing the bias on exclusively $S_{r\bullet}$ seems to be effective (with `calculTotal = sample`), which is great because in that case we don't need to know the $z_k$ for units that didn't respond by internet.

The case $\phi = \frac{1}{N}, \frac{2}{N}, \cdots$ gives a RMSE higher than the benchmark RMSE.

With $\phi$ fixed, the other estimators give a RMSE nearly equal the benckmark.

The `relExpRMSETWBenchmark` variable is the expected standard deviation of the benchmark calculated with the true selection probabilities. The bias is equal to zero with the true weights so the RMSE is equal to the standard deviation. Biases of the estimators are nearly zero so RMSE and standard deviations can be compared. We can observe that for every estimator the (estimated) RMSE is **clearly lower** than the standard deviation / RMSE of the benchmark with true probabilities.

## Convergence in law

```{r}
temp <- resultsGaussian %>% 
  filter(YtelLaw == "gaussian", YintLaw == "gaussian", 
         sampling == "SRS", 
         MBtype == "constant", signAge == "plus", 
         phi == "eq", trueEstimator) %>% 
  select(experiment, nInt, nTel, estPhiYintEstMP, expYint, avgEstWeightsInt,
         estPhiYtelEstMP, estPhiBarYtelEstMP, expYtel, normEstPhiBiasDiffHT) %>% 
  group_by(experiment) %>% 
  slice_head(n = 1L) %>% 
  ungroup()
```

### $\hat{t}_{pq\phi1}$

With $\phi \equiv \frac{1}{2}$

```{r}
estimatorsPhi1 <- temp$estPhiYintEstMP

empMean1 <- mean(estimatorsPhi1)

expMean1 <- as.numeric(0.5 * temp[1L, "expYint"])

glue("empirical mean: {empMean1} (expected: {expMean1})")
```

```{r}

empSD1 <- sd(estimatorsPhi1)

temp %>% 
ggplot() + 
  geom_density(aes(x = estPhiYintEstMP)) + 
  geom_vline(aes(xintercept = empMean1, colour = "constant"), show.legend = TRUE) +
  ggtitle("HT-phi1 estimator with estimated probabilities") +
  xlab("Estimator") +
  scale_color_manual(name = "bias", values = c(constant = "red"))

ks.test(x = (estimatorsPhi1 - empMean1) / empSD1, y = "pnorm")
```

### $\hat{t}_{pq\bar{\phi}2}$


With $\phi \equiv \frac{1}{2}$

```{r}
estimatorsPhi2 <- temp$estPhiYtelEstMP

empMean2 <- mean(estimatorsPhi2)

expMean2 <- 0.5 * as.numeric(temp[1L, "expYtel"])

glue("empirical mean: {empMean2} (expected: {expMean2})")
```

```{r}
empSD2 <- sd(estimatorsPhi2)

temp %>% 
ggplot() + 
  geom_density(aes(x = estimatorsPhi2)) + 
  geom_vline(aes(xintercept = empMean2, colour = "constant"), show.legend = TRUE) +
  ggtitle("HT-phi1 estimator with estimated probabilities") +
  xlab("Estimator") +
  scale_color_manual(name = "bias", values = c(constant = "red"))

ks.test(x = (estimatorsPhi2 - empMean2) / empSD2, y = "pnorm")
```

## Bias detection

```{r}
simulation_tphi <- function(Z,
                            sampling = "SRS",
                            alphaInt, alphaTel, 
                            betaInt, betaTel, 
                            YintLaw = "gaussian", YtelLaw = "gaussian",
                            sdInt = 1.0, sdTel = 1.0, 
                            phi = rep(0.5, N), K = 1000L,
                            n = ceiling(N / 4L),
                            seed = 123L)
{
  set.seed(seed)
  
  N <- nrow(Z)
  
  expit <- function(x) 1.0 / (1.0 + exp(-x))

  pInt <- expit(Z %*% alphaInt) %>% as.numeric()
  pq1Mat <- pInt %*% t(pInt)
  diag(pq1Mat) <- pInt
  
  pTel <- expit(Z %*% alphaTel) %>% as.numeric()
  pq2Mat <- pTel %*% t(pTel)
  diag(pq2Mat) <- pTel

  if (sampling == "SRS")
  {
    pi <- rep(n / N, N)
    piMat <- matrix(n * (n - 1L) / (N * (N - 1L)), nrow = N, ncol = N)
    diag(piMat) <- n / N
  }
  
  
  dataExpY <- gen_ExpY(Z, 
                       betaInt, YintLaw, sdInt,
                       betaTel, YtelLaw, sdTel)
  
  expYints <- dataExpY$expYints
  sdInts <- dataExpY$sdInts
  
  expYtels <- dataExpY$expYtels
  sdTels <- dataExpY$sdTels
  
  rm(dataExpY)
  
  phi <- set_phi(phi, N)
  
  
  monoSim <- function(...)
  {
    q <- ncol(Z)
        
      
    if (sampling == "SRS")
    {
      selectedSample <- sample(seq_len(N), size = n, replace = FALSE)
      
      I <- logical(N)
      I[selectedSample] <- TRUE
      rm(selectedSample)
    }
    
    
    dataModes <- gen_choice_bimode(I, pInt, pTel)
    modes <- dataModes$mode
    
    maskInt <- modes == "int"
    nInt <- sum(maskInt)
    maskTel <- modes == "tel"
    nTel <- sum(maskTel)
    
    trueProbsSelect <- dataModes$probSelect
    
    rm(dataModes)
    
    trueWeights <- (pi * trueProbsSelect)^-1L
  
    # Estimation of mode selection probabilities (taken unconditionally)
    estimProbsSelectTable <- 
      MMsampling::estim_response_prob_sequential(I, pi, Z,
                                                 modes, 
                                                 c("int", "tel"),
                                                 chosenOnly = FALSE)$unconditional
  
    estimProbsSelect <- get_value_by_mode(estimProbsSelectTable, modes)
    
  
    estimWeights <- (pi * estimProbsSelect)^-1L
    
    # Generating values for Y_int and Y_tel
    dataY <- gen_Y(Z, 
                   betaInt, sdInt, YintLaw,
                   betaTel, sdTel, YtelLaw,
                   expYints = expYints, expYtels = expYtels)
    
    Yints <- dataY$Yint
    Ytels <- dataY$Ytel
    
    rm(dataY)
    
    # Creating the observed outcome vector
    Yobs <- set_Yobs(Yint = Yints, Ytel = Ytels, modes = modes)
    
    # Estimations with Y1
    totPhi1TW <- sum(phi[maskInt] * trueWeights[maskInt] * Yobs[maskInt])
    totPhi1EW <- sum(phi[maskInt] * estimWeights[maskInt] * Yobs[maskInt])
    
    estimpq1Mat <- 
      estimProbsSelectTable[, "int"] %*% t(estimProbsSelectTable[, "int"])
    
    diag(estimpq1Mat) <- estimProbsSelectTable[, "int"]
    
      # the variance of Y1 is assumed known for simplicity
    estimApprVarPhi1 <- 
      estim_appr_var_seq_phi1(Yobs,
                              modes, I,
                              piMat,
                              estimpq1Mat, Z,
                              phi, correcEstimWeights = FALSE,
                              sd1 = sdInt)
      # parameter equal to
      #  phi_k (y_1k - average on U of the y_1l) / sum of the phi_k on U,
      #  equal to phi_k y_1k / sum of the phi_k on U - average on U of the y_1l
      #  (the last term is not a statistic)
    totCenteredPhi1EW <- 
      sum(phi[maskInt] * 
            (estimWeights[maskInt] * Yobs[maskInt] - mean(Yints))) /
      sum(phi[maskInt] * estimWeights[maskInt])
    
    estimApprVarCenteredInt <- 
      estim_var_centered_phiweb(Yobs,
                                modes, I,
                                piMat,
                                estimpq1Mat, Z,
                                phi, correcEstimWeights = FALSE)
    
    # Estimations with Y2
    totPhi2TW <- sum(phi[maskTel] * trueWeights[maskTel] * Yobs[maskTel])
    totPhi2EW <- sum(phi[maskTel] * estimWeights[maskTel] * Yobs[maskTel])
    
    ## NOTE : Attention calcul probas estimées ici, précédemment pris sans
    ## conditionnement
    c(totPhi1TW = totPhi1TW, totPhi1EW = totPhi1EW, 
      estimApprVarPhi1 = estimApprVarPhi1,
      totCenteredPhi1EW = totCenteredPhi1EW,
      estimApprVarCenteredInt = estimApprVarCenteredInt,
      totPhi2TW = totPhi2TW, totPhi2EW = totPhi2EW)
  }
  
  sapply(seq_len(K), FUN = monoSim) %>% t() %>% as_tibble()
}
```


```{r}
Kbis <- 2000L
```

```{r}
betaIntTemp <- betaTel
betaIntTemp[1L] <- betaIntTemp[1L] + 1.0

compareTphi <- simulation_tphi(K = Kbis,
                               Z = Z,
                               sampling = "SRS",
                               alphaInt = alphaInt,
                               alphaTel = alphaTel,
                               betaInt = betaIntTemp,
                               betaTel = betaTel,
                               YtelLaw = "gaussian",
                               YintLaw = "gaussian",
                               phi = "eq",
                               sdInt = 1.0,
                               sdTel = 1.0,
                               seed = 200L)
```


```{r}
compareTphi$differenceEW <- compareTphi$totPhi1EW - compareTphi$totPhi2EW
```

```{r}
varPhi1 <- var(compareTphi[seq_len(Kbis / 2.0), "totPhi1EW"])
varPhi2 <- var(compareTphi[seq_len(Kbis / 2.0), "totPhi2EW"])
varDiffPhi <- 
  var(compareTphi[seq_len(Kbis / 2.0), "totPhi1EW"] - 
        compareTphi[seq_len(Kbis / 2.0), "totPhi2EW"])
```

```{r}
mean(compareTphi$estimApprVarPhi1[-seq_len(Kbis / 2.0)])
```

```{r}
var(compareTphi$totCenteredPhi1EW[seq_len(Kbis / 2.0)])
```

```{r}
mean(compareTphi$estimApprVarCenteredInt[-seq_len(Kbis / 2.0)])
```

```{r}
rm(varPhi1, varPhi2, varDiffPhi, compareTphi)
```


### Superposition

We would like to test our ability to detect the presence or absence of a constant measure bias with the superposition of confidence intervals of $\hat{t}_{pq\phi1}$ and $\hat{t}_{pq\phi2}$. If there is no measure bias then we can assume there will be superposition of the confidence intervals.

We will change the value of the constants and test the coverage of our test. We consider the ratio between the measure bias and the expected mean of the telephone answers.

```{r}
ratioDeltas <- c(0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 1.0, 2.0)
expMean2 <- mean(Z %*% betaTel)
deltas <- ratioDeltas * abs(expMean2)
```

Then for each measure bias we try the recognition of an eventual measure bias, with confidence intervals with errors $\alpha_1 = \alpha_2 = 0.05$.


```{r}
Kbis <- 10000L

alpha1 <- alpha2 <- .05

sdDiffPhiVec <- NULL

resSuperpositions <- data.frame(ratio = ratioDeltas, 
                                delta = deltas, 
                                percSuperposition = 0.0,
                                percPresenceMean2 = 0.0)

for (delta in deltas)
{
  
  betaIntTemp <- betaTel
  betaIntTemp[1L] <- betaIntTemp[1L] + delta
  
  compareTphi <- simulation_tphi(K = Kbis,
                                 Z = Z,
                                 sampling = "SRS",
                                 alphaInt = alphaInt,
                                 alphaTel = alphaTel,
                                 betaInt = betaIntTemp,
                                 betaTel = betaTel,
                                 YtelLaw = "gaussian",
                                 YintLaw = "gaussian",
                                 phi = "eq",
                                 sdInt = 1.0,
                                 sdTel = 1.0,
                                 seed = 200L)

  subsetVar <- seq_len(Kbis / 2.0)
  estimatorsPhi1 <- compareTphi[, "totPhi1EW"]
  estimatorsPhi1ForVar <- estimatorsPhi1[subsetVar]
  sdPhi1 <- sd(estimatorsPhi1ForVar)
  estimatorsPhi1ForCI <- estimatorsPhi1[-subsetVar]
  
  estimatorsPhi2 <- compareTphi[, "totPhi2EW"]
  estimatorsPhi2ForVar <- estimatorsPhi2[subsetVar]
  sdPhi2 <- sd(estimatorsPhi2ForVar)
  estimatorsPhi2ForCI <- estimatorsPhi2[-subsetVar]
  
  
  sdDiffPhi <- sd(estimatorsPhi1ForVar - estimatorsPhi2ForVar)
  
  sdDiffPhiVec <- c(sdDiffPhiVec, sdDiffPhi)
  
  CI1lowerBis <- estimatorsPhi1ForCI - qnorm(1.0 - alpha1 / 2.0) * sdPhi1
  CI1upperBis <- estimatorsPhi1ForCI + qnorm(1.0 - alpha1 / 2.0) * sdPhi1
  
  CI2lower <- estimatorsPhi2ForCI - qnorm(1.0 - alpha2 / 2.0) * sdPhi2
  CI2upper <- estimatorsPhi2ForCI + qnorm(1.0 - alpha2 / 2.0) * sdPhi2

  superposition <- 
    (CI1lowerBis <= CI2lower & CI2lower <= CI1upperBis) | 
    (CI1lowerBis <= CI2upper & CI2upper <= CI1upperBis) |
    (CI2lower <= CI1lowerBis & CI1lowerBis <= CI2upper) | 
    (CI2lower <= CI1upperBis & CI1upperBis <= CI2upper)
  
  # Mean weighted by 1/2 because we took \phi_k = 0.5
  presenceExpMean2 <- 
    (CI1lowerBis <= 0.5 * expMean2 & 0.5 * expMean2 <= CI1upperBis) & 
    (CI2lower <= 0.5 * expMean2 & 0.5 * expMean2 <= CI2upper)
  
  percSuperposition <- 100.0 * mean(superposition)
  percPresenceMean2 <- 100.0 * mean(presenceExpMean2)
  
  resSuperpositions[resSuperpositions$delta == delta, 
                    c("percSuperposition", "percPresenceMean2")] <-
    c(percSuperposition, percPresenceMean2)
}

resSuperpositions
```

Superposition on the true total is not great. In fact we have that

$$\max \{\alpha_1,\alpha_2\}\leq\alpha_{12}\leq\alpha_1 + \min\{\alpha_1,\alpha_2\} + \alpha_2$$
with $1-\alpha_{12}$ the probability of having a superposition on the supposed total $t_{\phi2}$ of the two confidence intervals. 

Using the superposition implies a lot of false negative non-measure bias detection. The percentage of superposition becomes zero only after a ratio of $1.0$.

### HT-difference

We would like to check if, in the case of a constant bias, the estimator

$$\frac{1}{||\phi||_1}(\hat{t}_{pq\phi1}-\hat{t}_{pq\phi2})$$

detects the bias, in the sense of its expected value is equal to the constant bias $\delta$. Moreover, we would like to be sure that this estimator tends to a normal law. Of course this estimator shouldn't be used to estimate the total of the bias in the global estimator, because it would directly erase the information coming from $S_{r\bullet}$.

Here we use the empirical standard deviation based on our $K$ observations. 

#### $\delta = 1$

For $\delta = 1$, we would like to have an empirical mean close to it:

```{r}
estimBias <- temp$normEstPhiBiasDiffHT
empMean <- mean(estimBias)
glue("empirical mean: {empMean} (expected: {1})")
```

Note that both the estimators used are only approximately unbiased.

we check the normality of our estimator:

```{r}
empSD <- sd(estimBias)
temp %>% 
ggplot() + 
  geom_density(aes(x = normEstPhiBiasDiffHT)) + 
  geom_vline(aes(xintercept = 1.0, colour = "constant"), show.legend = TRUE) +
  ggtitle("Detection of a constant bias") +
  xlab("normalized HT-difference estimator") +
  scale_color_manual(name = "bias", values = c(constant = "red"))

ks.test(x = (estimBias - 1.0) / empSD, y = "pnorm")
```

With an important p-value the Kolmogorov-Smirnov test ensure that our estimator is normal.

#### Coverage depending on $\delta$

Then we evaluate the coverage of our confidence intervals. For $\alpha = 0.05$, we have


```{r}
alpha <- .05

nInt <- as.numeric(temp$nInt)

resDetection <- data.frame(ratio = ratioDeltas, 
                           delta = deltas, 
                           percPresenceZero = 0.0,
                           percPresenceDelta = 0.0)


for (delta in deltas)
{
  estimatorPhiDelta <- 1.0 / (0.5 * N) * (estimatorsPhi1 + 
  .5 * avgEstWeightsInt * nInt * (delta - 1.0) - 
  estimatorsPhi2)

  empSDPhiDelta <- sd(estimatorPhiDelta)

  CIlower <-  estimatorPhiDelta - qnorm(1.0 - alpha / 2.0) * empSDPhiDelta
  CIupper <- estimatorPhiDelta + qnorm(1.0 - alpha / 2.0) * empSDPhiDelta
  
  presenceZero <- CIlower <= 0.0 & 0.0 <= CIupper
  
  percPresenceZero <- 100.0 * mean(presenceZero) 
  
  presenceDelta <- CIlower <= delta & delta <= CIupper
  
  percPresenceDelta <- 100.0 * mean(presenceDelta)
  
  resDetection[resSuperpositions$delta == delta, 
                    c("percPresenceZero", "percPresenceDelta")] <- 
    c(percPresenceZero, percPresenceDelta)
}


resDetection
```

```{r}
empSD <- sd(estimBias)

alpha <- 0.05
CIlower <- estimBias - qnorm(1.0 - alpha / 2.0) * empSD
CIupper <- estimBias + qnorm(1.0 - alpha / 2.0) * empSD

coverage <- mean(CIlower <= 1.0 & 1.0 <= CIupper)

glue("coverage: {coverage} (expected: {1 - alpha})")
```


# Ex : Gaussian variable measure bias

Results of each parameter for the case of SRS with **variable** measure bias and Gaussian laws and $\sigma = 1$. First we focus on the bias:

```{r}
temp <- resultsGaussian %>% 
  filter(YtelLaw == "gaussian", YintLaw == "gaussian", 
         sampling == "SRS", MBtype == "variable", trueEstimator) %>% 
  select(-sampling, -MBtype, -probSelect) %>% 
  group_by(sd, signAge, parameter, invMatrices, calculTotal) %>% 
  summarise(#reldiffTotalTrueMean = round(mean(diffYtelTrueMP / abs(expYtel)) , 4L), 
            relError = round(mean(diffYtelEstMP / abs(expYtel)) , 4L),
            relErrorBenchmark = round(mean(diffBenchmark / abs(expYtel)), 4L),
            #relRMSETrue = round(sqrt(mean(diffYtelTrueMP^2L / expYtel^2L)), 4L),
            relRMSEParam = round(sqrt(mean(diffYtelEstMP^2L / expYtel^2L)), 4L),
            relEstRMSEBenchmark = round(sqrt(mean(diffBenchmark^2L / expYtel^2L)), 4L),
            relExpRMSETWBenchmark = round(mean(expSDTWBenchmark / abs(expYtel)), 4L)) %>% 
  ungroup() %>% 
  group_by(signAge) %>% 
  arrange(abs(relError), .by_group = TRUE) %>% 
  ungroup()

temp %>% 
  select(-relRMSEParam, -relEstRMSEBenchmark, -relExpRMSETWBenchmark)
```

We can observe that the relative estimated bias is close to zero.

Even with a variable measure bias, the G-COMP model with only a constant for the bias is approximately unbiased. It is due to the fact that we chose here a centered measure bias, respectively to the couple (age, sex).

And now the RMSE:

```{r}
temp %>% 
  select(-relError, -relErrorBenchmark) %>% 
  mutate(percRMSE = 100.0 * relRMSEParam / relEstRMSEBenchmark, .after = relEstRMSEBenchmark) %>% 
  arrange(relRMSEParam, .by_group = TRUE)
```

The estimator HT with **complete** inverse matrices and summing the bias on the sample only is the greatest (in term of RMSE). Its RMSE is better than the RMSE of the benchmark, which is itself better than the benchmark with true probabilities.

Summing on $S_{r\bullet}$ exclusively seems also working like with the constant case. More importantly the calculation on the sample only gives the greatest result.

Even if the G-COMP 0 degree model is unbiased, in every case it does not give efficient RMSE (always greater than the benchmark).

Only a few of the estimators give an interesting RMSE. Some of the others can give a RMSE about more than twice the RMSE of the benchmark. It is important to chose carefully the used estimator. On the other hand we can observe that the positive gain **is not really high**:

```{r}
temp %>%
  mutate(ratioRMSE = relRMSEParam / relEstRMSEBenchmark) %>% 
  ggplot() + geom_histogram(aes(x = ratioRMSE)) +
  ggtitle("Ratio RMSE parameter compared to RMSE benchmark")
```

Estimators with a better RMSE than the benchmark that are the most present:

```{r}
temp %>% 
  select(-relError, -relErrorBenchmark) %>% 
  filter(relRMSEParam <= relEstRMSEBenchmark) %>% 
  group_by(parameter, invMatrices, calculTotal) %>% 
  summarize(n = n()) %>% 
  arrange(-n)
```

Three of the estimators are **exclusively based** on the data of the sample $S_{r\bullet}$.

And the parameters that offer the worse RMSE compared to the benchmark:

```{r}
temp %>% 
  select(-relError, -relErrorBenchmark, -relExpRMSETWBenchmark) %>% 
  slice_max(relRMSEParam, n = 5L)
```

```{r}
rm(temp)
```


## Impact of the standard deviation

We focus on the impact of the standard deviation. Is there estimators that give better RMSE than the benchmark, independently of $\sigma$? The bias is is considered as variable.

```{r}
#| eval: false
parameters <- expand_grid(constBias = FALSE,
                          sampling = "SRS",#c("SRS", "STSRS"),
                          YtelLaw = "gaussian",
                          YintLaw = "gaussian",
                          signAge = c("plus", "minus"),
                          phi = "eq",
                          sdY = c(0.1, 1.0, 2.0, 5.0, 10.0, 20.0, 40.0, 60.0))

resultsSD <- loop_simulation(parameters, K = K)
```

```{r}
temp <- resultsSD %>% 
  filter(trueEstimator) %>% 
  select(-YintLaw, -YtelLaw, -sampling, -MBtype, -probSelect) %>% 
  group_by(signAge, sd, phi, parameter, invMatrices, calculTotal) %>% 
  summarise(#reldiffTotalTrueMean = round(mean(diffYtelTrueMP / abs(expYtel)) , 4L), 
            relError = round(mean(diffYtelEstMP / abs(expYtel)) , 4L),
            relErrorBenchmark = round(mean(diffBenchmark / abs(expYtel)), 4L),
            #relRMSETrue = round(sqrt(mean(diffYtelTrueMP^2L / expYtel^2L)), 4L),
            relRMSEParam = round(sqrt(mean(diffYtelEstMP^2L / expYtel^2L)), 4L),
            relEstRMSEBenchmark = round(sqrt(mean(diffBenchmark^2L / expYtel^2L)), 4L),
            relExpRMSETWBenchmark = round(mean(expSDTWBenchmark / abs(expYtel)), 4L)) %>% 
  ungroup() %>% 
  group_by(signAge, sd) %>% 
  arrange(relRMSEParam, .by_group = TRUE) %>% 
  ungroup()
```

```{r}
temp %>% 
  group_by(signAge, sd) %>% 
  filter(relRMSEParam <= relEstRMSEBenchmark) %>% 
  mutate(percRMSE = 100.0 * relRMSEParam / relEstRMSEBenchmark, .after = relEstRMSEBenchmark) %>% 
  arrange(percRMSE, .by_group = TRUE)
```
We can observe there is always estimators that are better than the benchmark (but sometimes not that much), for any couple (`signAge`, `sd`). In particular, the estimator `HT-samples-sample` is always present. Our estimators are still approximately unbiased but their variance increase with $\sigma$.

For each couple (signAge, sd), we draw the best estimator:

```{r}
temp %>% 
  group_by(signAge, sd) %>% 
  filter(relRMSEParam <= relEstRMSEBenchmark) %>% 
  mutate(percRMSE = 100.0 * relRMSEParam / relEstRMSEBenchmark, .after = relEstRMSEBenchmark) %>% 
  slice_min(percRMSE)
```

For low values of $\sigma$ the best estimator is HT-population-sample. For $\sigma \geq 10$ it is best to use the 1 degree G-Computation model. However with $\sigma \geq 10$ the gain is really weak.

Trajectories are similar for the both values of `signAge`, even if for small values of $\sigma$ the ratios are quite higher for `signAge = plus`. It seems that the ratio convergences to a value that is right under 1.

Best estimators depending on `signAge` and $\sigma$:

```{r}
temp %>% 
  select(-relError, -relErrorBenchmark) %>% 
  mutate(ratioRMSE = relRMSEParam / relEstRMSEBenchmark) %>%
  group_by(signAge, sd) %>% 
  slice_min(ratioRMSE) %>% 
  select(signAge, sd, phi, parameter, invMatrices, calculTotal, ratioRMSE)
```

The greatness of an estimator does not depend on `signAge` (if it is the best for `signAge = minus`, it is the best for `signAge = plus`).

The RMSE ratio increases with $\sigma$. For any value of `signAge` and for $\sigma \in \{0,1,2\}$ we have really interesting ratios, while for higher values the ratio is always right under one, which means that in those conditions there are estimators that are better than the benchmark but not that much (if we follows blindly  the empirical results).

The estimator needs to be chosen rightfully, specifically pour low values of $\sigma$ : the RMSE can be about 45% higher than the benchmark in the worst case.

```{r}
temp %>% 
  group_by(signAge, sd) %>% 
  summarize(minRatioRMSE = min(relRMSEParam / relEstRMSEBenchmark),
            maxRatioRMSE = max(relRMSEParam / relEstRMSEBenchmark))
```
If we focus on `HT-samples-sample`, we have the following results:

```{r}
temp %>% 
  filter(parameter == "HT", invMatrices == "samples", calculTotal == "sample") %>% 
  mutate(ratioRMSE = relRMSEParam / relEstRMSEBenchmark) %>% 
  ggplot() + geom_point(aes(x = sd, y = ratioRMSE, color = signAge)) +
  geom_hline(yintercept = 1.0, color = "red") +
  ggtitle("Ratio of the RMSE depending on the standard deviation (HT-samples-sample)")
```
And if we draw the best result we have with all estimators:

```{r}
temp %>% 
  select(-relError, -relErrorBenchmark) %>% 
  mutate(ratioRMSE = relRMSEParam / relEstRMSEBenchmark) %>%
  group_by(signAge, sd) %>% 
  slice_min(ratioRMSE) %>% 
  select(signAge, sd, phi, parameter, invMatrices, calculTotal, ratioRMSE) %>% 
  ggplot() + geom_point(aes(x = sd, y = ratioRMSE, color = signAge)) +
  geom_hline(yintercept = 1.0, color = "red") +
  ggtitle("Ratio of the RMSE depending on the standard deviation (best estimator)")
```

## Impact of $\phi$

We propose different values for $\phi$, in the Gaussian case with variable bias and variable $\sigma$:

```{r}
#| eval: false
parameters <- expand_grid(constBias = FALSE,
                          sampling = "SRS",
                          YtelLaw = "gaussian",
                          YintLaw = "gaussian",
                          signAge = c("plus", "minus"),
                          phi = c("eq", "1/3", "2/3",
                                  "var", "linear", "split3"),
                          sdY = c(1.0, 2.0, 5.0))

resultsPhi <- loop_simulation(parameters, K = K)
```

```{r}
temp <- resultsPhi %>% 
  filter(trueEstimator) %>% 
  select(-YintLaw, -YtelLaw, -sampling, -MBtype, -probSelect) %>% 
  group_by(signAge, sd, phi, parameter, invMatrices, calculTotal) %>% 
  summarise(#reldiffTotalTrueMean = round(mean(diffYtelTrueMP / abs(expYtel)) , 4L), 
            relError = round(mean(diffYtelEstMP / abs(expYtel)) , 4L),
            relErrorBenchmark = round(mean(diffBenchmark / abs(expYtel)), 4L),
            #relRMSETrue = round(sqrt(mean(diffYtelTrueMP^2L / expYtel^2L)), 4L),
            relRMSEParam = round(sqrt(mean(diffYtelEstMP^2L / expYtel^2L)), 4L),
            relEstRMSEBenchmark = round(sqrt(mean(diffBenchmark^2L / expYtel^2L)), 4L),
            relExpRMSETWBenchmark = round(mean(expSDTWBenchmark / abs(expYtel)), 4L)) %>% 
  ungroup() %>% 
  group_by(signAge, sd, phi) %>% 
  arrange(relRMSEParam, .by_group = TRUE) %>% 
  ungroup()
```

List of the estimators and their RMSE ratio depending on signAge, sigma and phi :
```{r}
temp %>% 
  filter(relRMSEParam <= relEstRMSEBenchmark) %>% 
  group_by(signAge, sd, parameter, invMatrices, calculTotal) %>% 
  mutate(ratioRMSE = relRMSEParam / relEstRMSEBenchmark) %>%
  select(-relError, -relErrorBenchmark, 
         -relRMSEParam, -relEstRMSEBenchmark,
         -relExpRMSETWBenchmark) %>% 
  arrange(ratioRMSE, .by_group = TRUE)
```

We remove the linear, var and split3 options because they give bad results. 

Here we print the minimum and maximum RMSE ratios obtained with each situation and each estimator that gives at least one result with an RMSE better than the benchmark:

```{r}
temp %>% 
  filter(!phi %in% c("var", "linear", "split3")) %>% 
  group_by(signAge, sd, parameter, invMatrices, calculTotal) %>% 
  filter(relRMSEParam < relEstRMSEBenchmark) %>% 
  mutate(ratioRMSE = relRMSEParam / relEstRMSEBenchmark) %>%
  select(-relError, -relErrorBenchmark, 
         -relRMSEParam, -relEstRMSEBenchmark,
         -relExpRMSETWBenchmark) %>% 
  summarize(minRMSE = min(ratioRMSE), 
            maxRMSE = max(ratioRMSE), 
            diffMaxMin = maxRMSE - minRMSE,
            percMaxMin = 100.0 * (diffMaxMin) / maxRMSE) %>% 
  group_by(signAge, sd) %>% 
  arrange(minRMSE, .by_group = TRUE)
```

List of the best(s) estimator(s) (for the RMSE) for each couple (`signAge`, `sd`):
```{r}
temp %>% 
  filter(relRMSEParam <= relEstRMSEBenchmark) %>% 
  group_by(signAge, sd) %>% 
  mutate(ratioRMSE = relRMSEParam / relEstRMSEBenchmark) %>%
  select(-relError, -relErrorBenchmark, 
         -relRMSEParam, -relEstRMSEBenchmark,
         -relExpRMSETWBenchmark) %>% 
  slice_min(ratioRMSE)
```

For any situation the best estimator is `(HT-population-sample)`, with $\phi_k \equiv \frac{2}{3}$. Like previously the RMSE ratio increases with $\sigma$.


Evolution of the RMSE ratio depending on $\sigma$, $\phi$ and `signAge`, for the estimator `(HT-population-sample)`:

```{r}
temp %>% 
  filter(parameter == "HT", invMatrices == "population", calculTotal == "sample") %>% 
  mutate(ratioRMSE = relRMSEParam / relEstRMSEBenchmark) %>% 
  ggplot() + 
  geom_point(aes(x = sd, y = ratioRMSE, color = phi, shape = signAge)) +
  geom_hline(yintercept = 1.0, color = "red") +
  ggtitle("Ratio of the RMSE depending on the standard deviation and phi (HT-population-sample)")
```

Evolution of the RMSE ratio depending on $\sigma$, $\phi$ and `signAge`, for the estimator `(HT-samples-sample)`:
```{r}
temp %>% 
  filter(parameter == "HT", invMatrices == "samples", calculTotal == "sample") %>% 
  mutate(ratioRMSE = relRMSEParam / relEstRMSEBenchmark) %>% 
  ggplot() + 
  geom_point(aes(x = sd, y = ratioRMSE, color = phi, shape = signAge)) +
  geom_hline(yintercept = 1.0, color = "red") +
  ggtitle("Ratio of the RMSE depending on the standard deviation and phi (HT-samples-sample)")
```
`var` (i.e. a random choice for $\phi_k$) and `split3` gives really bad results. So we will remove it from now on.

```{r}
temp %>% 
  filter(parameter == "HT", invMatrices == "samples", calculTotal == "sample") %>% 
  filter(phi != "var", phi != "split3") %>% 
  mutate(ratioRMSE = relRMSEParam / relEstRMSEBenchmark) %>% 
  ggplot() + 
  geom_point(aes(x = sd, y = ratioRMSE, color = phi, shape = signAge)) +
  geom_hline(yintercept = 1.0, color = "red") +
  ggtitle("Ratio of the RMSE depending on the standard deviation and phi")
```

The "linear" possibility gives bad results (with ratio stricly superior to 1). 
The choice of the constant depends of the situation. However, the difference between the ratios is not extremely important.

Note: There is a superposition of "eq", 1/3 and 2/3 for any $\sigma$ with `signAge=plus`.

## Bias detection


We would like to check if, in the case of a constant bias, the estimator

$$\frac{1}{||\phi||_1}(\hat{t}_{pq\phi1}-\hat{t}_{pq\phi2})$$

detects the bias, in the sense of its expected value is equal to the constant bias $\delta$. Moreover, we would like to be sure that this estimator tends to a normal law.

Here we use the empirical standard deviation based on our $K$ observations. 

```{r}
temp <- resultsGaussian %>% 
  filter(YtelLaw == "gaussian", YintLaw == "gaussian", 
         sampling == "SRS", 
         MBtype == "variable", signAge == "plus", 
         trueEstimator) %>% 
  select(experiment, normEstPhiBiasDiffHT) %>% 
  group_by(experiment) %>% 
  slice_head() %>% 
  ungroup() %>% 
  select(normEstPhiBiasDiffHT)

estimBias <- temp$normEstPhiBiasDiffHT
```

The expected value is equal to 

$$\frac{1}{||\phi||_1}(||\phi||_1\delta_0 + \sum_{k \in U} \phi_k. age_k. \delta_{age} + \sum_{k \in U} \phi_k .sexe_k. \delta_{sexe})$$

In our situation we have that $\sum_{k \in U} age_k. \delta_{age} + \sum_{k \in U}.sexe_k. \delta_{sexe} = 0$, by construction. So if the $\phi_k$ are constant (which is the case here), the expected value simply becomes $\delta_0$, which is equal to $1$.

```{r}
empMean <- mean(estimBias)
glue("empirical mean: {empMean} (expected: {1})")
```

The empirical mean is close to the nominal value, even with approximately unbiased estimators.

For $\alpha = 0.05$, we have

```{r}
empSD <- sd(estimBias)

alpha <- 0.05
CIlower <- estimBias - qnorm(1.0 - alpha / 2.0) * empSD
CIupper <- estimBias + qnorm(1.0 - alpha / 2.0) * empSD

coverage <- mean(CIlower <= 1.0 & 1.0 <= CIupper)

glue("coverage: {coverage} (expected: {1 - alpha})")
```

the coverage is very close to the target.


We check the normality of our estimator:

```{r}
temp %>% 
ggplot() + 
  geom_density(aes(x = normEstPhiBiasDiffHT)) + 
  geom_vline(aes(xintercept = 1.0, colour = "expected"), show.legend = TRUE) +
  ggtitle("Detection of a variable bias (average)") +
  xlab("normalized HT-difference estimator") +
  scale_color_manual(name = "bias", values = c(expected = "red"))


ks.test(x = (estimBias - 1.0) / empSD, y = "pnorm")
```

With an important p-value the Kolmogorov-Smirnov test ensure that our estimator is normal.


# More general cases

Percentage of values for $z_k^T\beta_{tel}$ that are $< 0$ with `signAge=minus`:

```{r}
glue("{sum(Z %*% betaTel < 0.0) * 100.0 / N} %")
```


```{r}
#| eval: false

# Grid of all evaluated parameters
parameters <- expand_grid(constBias = c(TRUE, FALSE),
                          sampling = "SRS",#c("SRS", "STSRS"),
                          YtelLaw = c("gaussian", "exponential"),
                          YintLaw = c("gaussian", "exponential", "split3"),
                          signAge = c("plus", "minus"),
                          phi = c("eq", "var"),
                          sdY = c(1.0, 2.0, 5.0)) %>%
  # If there is only exponential laws the parameter sdY is of no interest
  mutate(sdY =
           ifelse(YtelLaw == "gaussian" |
                    YintLaw == "gaussian", sdY, NA_real_)) %>% 
  filter(YtelLaw != "gaussian" | YintLaw != "gaussian")

resultsGeneral <- loop_simulation(parameters)
```


## Telephone total estimation

The size of the grid of the hyperparameters (and so the number of cases) is huge, so each case cannot be studied individually.

Note : in the case of an exponential law for $Y_{int}$ or $Y_{tel}$, the standard deviation parameter is not considered (the standard deviation will be equal to $(z_k^T\beta)^2$, with the adequate $\beta$).

```{r}
temp <- resultsGeneral %>% 
  filter(trueEstimator) %>% 
  group_by(YintLaw, YtelLaw, sd, signAge, MBtype, phi,
           sampling, parameter, invMatrices, calculTotal)
```

Here we have the optimal relative RMSE for each condition:

```{r}
temp <- temp %>% 
  summarise(relError = round(mean(diffYtelEstMP / abs(expYtel)) , 4L),
            relDiffBenchmarkMean = round(mean(diffBenchmark / abs(expYtel)), 4L),
            relRMSEParam = round(sqrt(mean(diffYtelEstMP^2L / expYtel^2L)), 4L),
            relEstRMSEBenchmark = round(sqrt(mean(diffBenchmark^2L / expYtel^2L)), 4L)) %>% 
  ungroup() 

temp %>% 
  group_by(sd, YintLaw, YtelLaw, signAge, MBtype, sampling) %>% 
  slice_min(relRMSEParam)
```

Number of situations that possess a better RMSE with some parameter different than the benchmark:

```{r}
tempBis <- temp %>% 
  group_by(YtelLaw, sd, YintLaw, sampling, signAge, MBtype)

nbExperiments <- n_groups(tempBis)

nbSuccesses <- tempBis %>% 
  summarise(nbEstimators = sum(relRMSEParam <= relEstRMSEBenchmark),
            bestRelRMSE = min(relRMSEParam),
            relEstRMSEBenchmark = mean(relEstRMSEBenchmark)) %>% 
  arrange(bestRelRMSE / relEstRMSEBenchmark) %>% 
  filter(nbEstimators > 0L) %>% 
  nrow()
  
glue("{nbSuccesses} / {nbExperiments} with at least one interesting estimator")

rm(tempBis)
```

Estimators that are the most present (which have a lower value of RMSE compared to the benchmark, not necessarily the lowest):

```{r}
temp %>% 
  select(-relError, -relDiffBenchmarkMean) %>% 
  filter(relRMSEParam <= relEstRMSEBenchmark) %>% 
  group_by(phi, parameter, invMatrices, calculTotal) %>% 
  summarize(n = n(), ratio = n / nbExperiments) %>% 
  arrange(-n)
```

Case when HT-sample-sample is the best:

```{r}
temp %>% 
  group_by(YtelLaw, sd, YintLaw, sampling, signAge, MBtype) %>% 
  filter(relRMSEParam <= relEstRMSEBenchmark) %>% 
  slice_min(relRMSEParam) %>% 
  filter(parameter == "HT", 
         invMatrices == "samples",
         calculTotal == "sample") %>% 
  distinct(YtelLaw, sd, YintLaw, sampling, signAge, MBtype)
```

This estimator seems to be optimal only is the measure bias is conditionally constant.

Case when HT-population-population is the best:

```{r}
temp %>% 
  group_by(YtelLaw, sd, YintLaw, sampling, signAge, MBtype) %>% 
  filter(relRMSEParam <= relEstRMSEBenchmark) %>% 
  slice_min(relRMSEParam) %>% 
  filter(parameter == "HT", 
         invMatrices == "population",
         calculTotal == "population") %>% 
  distinct(YtelLaw, sd, YintLaw, sampling, signAge, MBtype)
```


```{r}
rm(temp)
```

## Variances

Here we focus on the special case when selection probabilities are known and the estimator is Horvitz-Thompson with the complete inverse matrices and the summation for $\hat{t}_{\phi\Delta}$ is made on the entire population. The goal is to compare the estimated (co)variances with the ones expected by the theory.

```{r}
temp <- resultsGeneral %>% 
  filter(parameter == "HT", probSelect == "true", 
         invMatrices == "population", calculTotal == "population")


# tempBis <- temp %>% 
#   filter(sampling == "SRS",
#          YintLaw == "gaussian", YtelLaw == "gaussian",
#          phi == "eq", sd == "1", MBtype == "variable",
#          signAge == "plus")
```

Before comparison, we can observe on the Gaussian case (variable measure bias, positive coefficient for age on telephone, $\phi_k \equiv \frac{1}{2}$) with $\sigma =1$ that the variance do not stabilize completely:

```{r}
# sumSqErrors <- cumsum(tempBis[, c("diffPhiBias", "diffYtelEstMP")]^2L)
# 
# RMSEs <- 
#   data.frame(totPhiDelta =  sumSqErrors[-1L, "diffPhiBias"] / Kvec[-1L],
#              totYtel = sumSqErrors[-1L, "diffYtelEstMP"] / Kvec[-1L],
#              K = Kvec[-1L])
# 
# RMSEs %>% 
#   pivot_longer(cols = c("totPhiDelta", "totYtel"), 
#                names_to = "target", 
#                values_to = "estRMSE") %>% 
#   ggplot() +
#   geom_point(aes(x = K, y = estRMSE, colour = target)) +
#   ggtitle("Estimated RMSE depending on the number of evaluations (K)")
# 
# rm(tempBis, RMSEs)
```


```{r}
temp %>% 
  group_by(sampling, YintLaw, YtelLaw, sd, MBtype, signAge, phi) %>% 
  summarise(K = n(),
            estSDEstimator = sd(estYtelTrueMP),
            expSDEstimator = sqrt(mean(expVar2)),
            estVarPhi1 = var(estPhiYintTrueMP),
            expVarPhi1 = mean(expVarPhi1),
            estVarPhi2 = var(estPhiBarYtelTrueMP),
            expVarPhi2 = mean(expVarPhi2),
            estCovarphi12 = cov(estPhiYintTrueMP, estPhiBarYtelTrueMP),
            expCovarPhi12 = mean(expCovarPhi12),
            estCovarphi1Delta = cov(estPhiYintTrueMP, estPhiBias),
            expCovarPhi1Delta = mean(expCovarPhi1Delta),
            estVarPhiDelta = var(estPhiBias),
            expVarPhiDelta = mean(expVarPhiDelta),
            estCovarphi2Delta = cov(estPhiBarYtelTrueMP, estPhiBias),
            expCovarPhi2Delta = mean(expCovarPhi2Delta))
```

```{r}
rm(temp)
```



