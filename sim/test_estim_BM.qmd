```{r}
library(dplyr)
options(dplyr.summarise.inform = FALSE)
library(tidyr)
library(glue)
library(tibble)
library(parallel)
library(tictoc)
library(ggplot2)
library(Matrix)
library(progress)
library(marginaleffects)
```

```{r}
devtools::load_all()
```

# Linear models on both modes

## Building constants

```{r}
set.seed(145L)
```

```{r}
N <- 1000L
phi <- rep(0.5, N)
```

Creating independent covariates

```{r}
p <- 1L

sex <- sample(c(0L, 1L), replace = TRUE, size = N, prob = c(0.5, 0.5))
age <- rnorm(n = N, mean = sex * 41.1 + (1L - sex) * 43.9, sd = 10.0)
age[age < 0.0] <- 0.0

Z <- data.frame(const = 1.0, 
                age = age, 
                sex = sex)

rm(age)
sex <- factor(sex)
levels(sex) <- c("Woman", "Man")
```

```{r}
summary(Z)
```

```{r}
data <- Z[, c("sex", "age")]
data$sex <- sex
ggplot(data) + 
  geom_density(aes(x = age, colour = sex)) +
  ggtitle("Age ~ sex")
rm(data)
```

```{r}
Z <- as.matrix(Z)
```

Creating parameters for two modes : "int" and "tel". `delta` is defined such that the average measure bias is equal to 1. It depends on `Z`.

```{r}
betaTel <- c(7.0, -0.1, 4.0)
print(betaTel)
delta <- c(1.0, -2.0 * mean(Z[, "age"])^-1L, 2.0 * N / sum(Z[, "sex"]))
betaInt <- betaTel + delta
  

print(betaInt)
```

$Y_{int}$ and $Y_{tel}$ expectations depending on `Z`:

```{r}
data.frame(tel = Z %*% betaTel, int = Z %*% betaInt) %>% 
  pivot_longer(cols = c("tel", "int"), names_to = "mode", values_to = "value") %>% 
  ggplot() + geom_density(aes(x = value, colour = mode))

glue("average value for telephone: {mean(Z %*% betaTel)}")
glue("average value for internet: {mean(Z %*% betaInt)}")
```


```{r}
totBias <- sum(Z %*% delta)
glue("total bias on U: {totBias}")
meanBias <- totBias / N
glue("average bias on U: {meanBias}")
```

We simulate a mode selection MAR (Missing At Random) under a logistic model, with $Z$ as variable:

```{r}
# With MAR

expit <- function(x) 1.0 / (1.0 + exp(-x))

alphaInt <- c(0.7, -0.02, -0.5)
pInt <- expit(Z %*% alphaInt) %>% as.vector()

alphaTel <- c(0.3, 0.02, -0.5)
pTel <- expit(Z %*% alphaTel) %>% as.vector()
```

Here are some details about the $p_{int}$ and $p_{tel}$:

```{r}
data.frame(mode = factor(rep(c("int", "tel"), each = N)), 
           prob = c(pInt, pTel)) %>% 
  ggplot() + 
  geom_density(aes(x = prob, color = mode)) +
  ggtitle("Distribution of p_int and p_tel")
```

```{r}
pInt[sex == "Man"] %>% summary()
pInt[sex == "Woman"] %>% summary()
```

```{r}
cat("internet probabilities:\n")
summary(pInt) %>% print()
cat("telephone probabilities:\n")
summary(pTel) %>% print()
```

## Simulation functions

Randomly affect a mode (or non-response) to each unit

```{r}
gen_choice_bimode <- function(I, p1, p2, mode1 = "int", mode2 = "tel")
{
  N <- length(p1)
  
  R1 <- runif(N) <= p1
  R2 <- runif(N) <= p2
  
  modes <- rep("nr", N)
  modes[R1] <- mode1
  
  modes[!R1 & R2] <- mode2
  
  modes[!I] <- "nr"
  
  modes
}
```

Parameters:

-   `meanZ` and `varZ` if `Z` is variable (i.e. `fixZ == FALSE`). constant Z can be given with `Z`
-   $\alpha_{tel}$ and $\alpha_min$, coefficients of conditional expectations of $r_{tel}$ and $r_{int}$
-   $\beta_{tel}$ and $\beta_{int}$, coefficients of conditional expectations of $Y_{tel}$ and $Y_{int}$
-   the sampling type (`sampling`)
-   the conditional standard deviations of $Y_{tel}$ and $Y_{int}$ (`sdInt` and `sdTel`)
-   the law of $Y_{tel}$ (`YtelLaw`)
-   the law of $Y_{int}$ (`YintLaw`)
-   the state of $\phi$ (`phi`)
-   the number of iterations (`K`)
-   the random seed (`seed`)

```{r}
simulationUncounf <- 
  function(N,
           meanZ = numeric(length(alphaInt)), 
           covarZ = diag(1.0, length(alphaInt)), 
           fixZ = TRUE,
           sampling = "SRS",
           alphaInt, alphaTel, 
           betaInt, betaTel, 
           YintLaw = "gaussian", YtelLaw = "gaussian",
           sdInt = 1.0, sdTel = 1.0, 
           phi = rep(0.5, N), K = 1000L,
           Z = NULL,
           n = ceiling(N / 4L),
           seed = 123L)
  {
    
    nbCores <- detectCores() - 1L
    cluster <- makeCluster(nbCores)
    
    # Making clusters random-independants
    clusterSetRNGStream(cl = cluster, iseed = seed)
    
    clusterEvalQ(cluster, library(dplyr))
    clusterEvalQ(cluster, library(Matrix))
    clusterEvalQ(cluster, library(tibble))
    clusterEvalQ(cluster, library(marginaleffects))
    clusterEvalQ(cluster, library(MMsampling))
    
    clusterExport(cluster, varlist = c("sampling", 
                                       "betaInt", "betaTel", 
                                       "YintLaw", "YtelLaw", 
                                       "sdInt", "sdTel", 
                                       "n"),
                  envir = environment())
    
    expit <- function(x) 1.0 / (1.0 + exp(-x))

    if (!is.null(Z))
    {
      fixZ <- TRUE
      clusterExport(cluster, 
                    varlist = "Z",
                    envir = environment())
      
    }
    else if (fixZ)
    {
      Z <- mvtnorm::rmvnorm(N, mean = meanZ, sigma = covarZ, checkSymmetry = TRUE)
      clusterExport(cluster,
                    varlist = "Z",
                    envir = environment())
    }
      
    clusterExport(cluster, 
                  varlist = "fixZ",
                  envir = environment())
    
    if (fixZ)
    {
      pInt <- expit(Z %*% alphaInt) %>% as.numeric()
      pq1Mat <- pInt %*% t(pInt)
      diag(pq1Mat) <- pInt
      
      pTel <- expit(Z %*% alphaTel) %>% as.numeric()
      pq2Mat <- pTel %*% t(pTel)
      diag(pq2Mat) <- pTel
      
      clusterExport(cluster, 
                    varlist = c("pInt", "pq1Mat", "pTel", "pq2Mat"),
                    envir = environment())
    }
    else
    {
      clusterExport(cluster, 
                    varlist = c("meanZ", "covarZ",
                                "alphaInt", "alphaTel", 
                                "expit"),
                    envir = environment())
    }
    
    if (fixZ)
    {
      if (sampling == "SRS")
      {
        pi <- rep(n / N, N)
        piMat <- matrix(n * (n - 1L) / (N * (N - 1L)), nrow = N, ncol = N)
        diag(piMat) <- n / N
        
        clusterExport(cluster, 
                      varlist = c("pi", "piMat"),
                      envir = environment())
      }
    }
    
    if (fixZ)
    {
      if (YtelLaw == "gaussian")
      {
        expYtel <- as.vector(Z %*% betaTel)
        covarYtel <- diag(sdTel^2L, N)
      }
      else if (YtelLaw == "exponential")
      {
        expYtel <- as.vector(abs(Z %*% betaTel))
        covarYtel <- diag(expYtel^2L)
      }
      
      if (YintLaw == "gaussian")
      {
        expYint <- as.vector(Z %*% betaInt)
        covarYint <- diag(sdInt^2L, N)
      }
      else if (YintLaw == "exponential")
      {
        expYint <- as.vector(abs(Z %*% betaInt))
        covarYint <- diag(expYint^2L)
      }
      
      clusterExport(cluster,
                    varlist = c("expYtel", "covarYtel", 
                                "expYint", "covarYint"),
                    envir = environment())
    }
    
    clusterExport(cluster, "gen_choice_bimode")
      
    
    if (class(phi) == "character")
      phiType <- phi
    else
      phiType <- "vector"
    
    if (phi == "eq")
      phi <- rep(0.5, N)
  
    else if (phi == "var")
      phi <- seq_len(N) / N
    
    else if (phi == "bestProb")
      phi <- ifelse(pInt >= 0.5, 1.0, 0.0)
    
    clusterExport(cluster, 
                  varlist = "phi", 
                  envir = environment())
    
    monoSim <- function(...)
    {
      nbExperiments <- 12L
      
      partialResults <- data.frame(parameter = character(nbExperiments),
                                   trueEstimator = logical(nbExperiments),
                                   probSelect = character(nbExperiments),
                                   invMatrix = character(nbExperiments),
                                   calculTotal = character(nbExperiments),
                                   estTotPhiBias = numeric(nbExperiments))
      
      row <- 1L
      
      if (!fixZ)
      {
        Z <- mvtnorm::rmvnorm(N, mean = meanZ, 
                              sigma = covarZ, checkSymmetry = TRUE)
        
        
        pInt <- expit(Z %*% alphaInt)
        pq1Mat <- pInt %*% pInt
        diag(pq1Mat) <- pInt
        
        pTel <- expit(Z %*% alphaTel)
        pq2Mat <- pTel %*% pTel
        diag(pq1Mat) <- pTel
      }
      
      p <- ncol(Z)
        
      
      if (sampling == "SRS")
      {
        if (!fixZ)
        {
          pi <- rep(n / N, N)
          piMat <- matrix(n * (n - 1L) / (N * (N - 1L)), nrow = N, ncol = N)
          diag(piMat) <- n / N
        }
        
        
        selectedSample <- sample(seq_len(N), size = n, replace = FALSE)
        
        I <- logical(N)
        I[selectedSample] <- TRUE
        rm(selectedSample)
      }
      
      # Mode selection simulation
      modeChoiceOK <- FALSE
      
      while (!modeChoiceOK)
      {
        # modeChoiceOK <- TRUE
        
        modes <- gen_choice_bimode(I, pInt, pTel)
        trueProbsSelect <- rep(NA_real_, N)
        maskInt <- modes == "int"
        maskTel <- modes == "tel"
        trueProbsSelect[maskInt] <- pInt[maskInt]
        trueProbsSelect[maskTel] <- ((1.0 - pInt) * pTel)[maskTel]
        
        if (rankMatrix(Z[maskInt, , drop = FALSE]) == p && rankMatrix(Z[maskTel, , drop = FALSE]) == p)
          modeChoiceOK <- TRUE
        else
          warning("Singular Zint / Ztel")
        
      }
      
      
      trueWeights <- (pi * trueProbsSelect)^-1L
    
      # Estimation of mode selection probabilities
      estimProbsSelect <- 
        MMsampling::estim_response_prob_sequential(I, Z,
                                                   modes, 
                                                   c("int", "tel"))$unconditional
    
      estimWeights <- (pi * estimProbsSelect)^-1L
      
      
       # Affecting values to Y_int and Y_tel
      if (YtelLaw == "gaussian")
      {
        if (!fixZ)
        {
          expYtel <- as.vector(Z %*% betaTel)
          covarYtel <- diag(sdTel^2L, N)
        }
        Ytel <- expYtel + rnorm(n = N, sd = sdTel)
        
      }
      else if (YtelLaw == "exponential")
      {
        if (!fixZ)
        {
          expYtel <- as.vector(abs(Z %*% betaTel))
          covarYtel <- diag(expYtel^2L)
        }
        Ytel <- rexp(n = N, rate = expYtel^-1L)
      }
      
      expTotYtel <- sum(expYtel)
      trueTotalYtel <- sum(Ytel)
      
      if (YintLaw == "gaussian")
      {
        if (!fixZ)
        {
          expYint <- as.vector(Z %*% betaInt)
          covarYint <- diag(sdInt^2L, N)
        }
        Yint <- expYint + rnorm(n = N, sd = sdInt)
        
      }
      else if (YintLaw == "exponential")
      {
        if (!fixZ)
        {
          expYint <- as.vector(abs(Z %*% betaInt))
          covarYint <- diag(expYint^2L)
        }
        Yint <- rexp(n = N, rate = expYint^-1L)
      }
        
      deltas <- Yint - Ytel
      
    
      # Evaluating the measure bias total (random value)
      trueTotalBias <- crossprod(phi, deltas) %>% as.vector()
      expPhiBias <- crossprod(phi, expYint - expYtel) %>% as.vector()
      
      # Creating the observed outcome vector
      Yobs <- rep(NA_real_, N)
      Yobs[maskInt] <- Yint[maskInt]
      Yobs[maskTel] <- Ytel[maskTel]
      
      sample <- MMsampling:::MMSample$new(Z = Z, pi = pi, I = I, 
                             modes = modes, Yobs = Yobs, phi = phi)
      
      # Full HT estimation, with full population matrix (Z^tZ)^-1 and
      # known probabilities
      resEval <-
        estim_delta_MCO(sample$Z, sample$Yobs, sample$modes,
                               "int", "tel", "HT", "HT", pi,
                        trueProbsSelect, sampleMatrix = FALSE) %>%
        estim_MB_by_MCO(Z, phi = phi) %>%
        sum()
      
  
      partialResults[row,] <- 
        c(parameter = "HT", trueEstimator = FALSE,
          probSelect = "true", invMatrix = "true",
          calculTotal = "full", estTotPhiBias = resEval)
      
      row <- row + 1L
  
      # Full HT estimation, with sample matrix (Z_S^TZ_S)^-1 and
      # known probabilities
      resEval <-
        estim_delta_MCO(sample$Z, sample$Yobs, sample$modes,
                               "int", "tel", "HT", "HT", pi,
                        trueProbsSelect, sampleMatrix = TRUE) %>%
        estim_MB_by_MCO(Z, phi = phi) %>%
        sum()
  
      partialResults[row,] <- c(parameter = "HT", trueEstimator = FALSE,
                                probSelect = "true", invMatrix = "sample", 
                                calculTotal = "full", estTotPhiBias = resEval)
      
      row <- row + 1L
      
      
      
      
      # Estimation on a unique MCO for Y1 and Y2, with beta X and only a constant
      # delta for the estimation of the measure bias
      deltaEval <- 
        estim_delta_MCO_unique_model_const(Z, Yobs, modes, "int", "tel")
      resEvalFull <- sum(phi) * deltaEval
      resEvalHT <- 
        as.vector(crossprod(phi[maskInt],
                            estimWeights[maskInt]) * 
                    deltaEval)
      
      
      partialResults[c(row, row + 1L),] <- 
        data.frame(parameter = "G-COMP_0_deg",
                   trueEstimator = TRUE,
                   probSelect = "null",
                   invMatrix = "null",
                   calculTotal = c("full", "partial"),
                   estTotPhiBias = c(resEvalFull, resEvalHT))
      
      
      row <- row + 2L
      
      
      # G-COMP first degree estimation, <=> double MCO estimation
      # tic()
      # estimdelta <- estim_delta_MCO(sample$Z, sample$Yobs, sample$modes, 
      #                   "int", "tel", "MCO", "MCO", pi, NULL)
      estMBs <- estim_delta_MCO(sample$Z, sample$Yobs, sample$modes, 
                                "int", "tel", "G-COMP", "G-COMP", pi, NULL, 
                                returnMB = TRUE, order = 1L)
      
      resEvalFull <- crossprod(phi, estMBs) %>% as.vector()
      
      resEvalHT <- crossprod(phi[maskInt] * estimWeights[maskInt],
                             estMBs[maskInt]) %>% as.vector()
      # toc() %>% print()
      
      
      
      partialResults[c(row, row + 1L),] <- 
        data.frame(parameter = "G-COMP_1_deg", trueEstimator = TRUE,
                   probSelect = "null", 
                   invMatrix = "null", calculTotal = c("full", "partial"),
                   estTotPhiBias = c(resEvalFull, resEvalHT))
      
      row <- row + 2L
      
      # G-COMP two degrees estimation
      # tic()
      estMBs <- estim_delta_MCO(sample$Z, sample$Yobs, sample$modes, 
                                "int", "tel", "G-COMP", "G-COMP", pi, NULL, 
                                returnMB = TRUE, order = 2L)
      
      resEvalFull <- crossprod(phi, estMBs) %>% as.vector()
      
      resEvalHT <- crossprod(phi[maskInt] * estimWeights[maskInt],
                             estMBs[maskInt]) %>% as.vector()
      # toc() %>% print()
      
      
      
      partialResults[c(row, row + 1L),] <- 
        data.frame(parameter = "G-COMP_2_deg", trueEstimator = TRUE,
                   probSelect = "null", 
                   invMatrix = "null", calculTotal = c("full", "partial"),
                   estTotPhiBias = c(resEvalFull, resEvalHT))
      
      row <- row + 2L
      
      
      
      # Full HT estimation, with full population matrix (Z^tZ)^-1 and
      # unknown probabilities
      # tic()
      estimdelta <- 
        estim_delta_MCO(sample$Z, sample$Yobs, sample$modes, 
                        "int", "tel", "HT", "HT", pi, 
                        estimProbsSelect, sampleMatrix = FALSE)
      
      resEvalFull <- estimdelta %>% 
        estim_MB_by_MCO(Z, phi = phi) %>% 
        sum()
      
      resEvalHT <- estimdelta %>% 
        estim_MB_by_MCO(Z, 
                        phi = phi, 
                        weights = estimWeights,
                        mask = maskInt) %>% 
        sum()
    
      # toc() %>% print()
     
      
      partialResults[c(row, row + 1L),] <- 
        data.frame(parameter = "HT", trueEstimator = TRUE,
                   probSelect = "estimation", invMatrix = "true", 
                   calculTotal = c("full", "partial"), 
                   estTotPhiBias = c(resEvalFull, resEvalHT))
      
      row <- row + 2L
      
      # Full HT estimation, with sample matrix (Z_S^TZ_S)^-1 and
      # unknown probabilities
      # tic()
      estimdelta <- 
        estim_delta_MCO(sample$Z, sample$Yobs, sample$modes, 
                        "int", "tel", "HT", "HT", pi, 
                        estimProbsSelect, sampleMatrix = TRUE) 
      
      
      resEvalFull <- estimdelta %>% 
        estim_MB_by_MCO(Z, phi = phi) %>% 
        sum()
      
      resEvalHT <- estimdelta %>% 
        estim_MB_by_MCO(Z, 
                        phi = phi, 
                        weights = estimWeights, 
                        mask = maskInt) %>% 
        sum()
    
      # toc() %>% print()
      
      partialResults[c(row, row + 1L),] <- 
        data.frame(parameter = "HT", trueEstimator = TRUE,
                   probSelect = "estimation", invMatrix = "sample", 
                   calculTotal = c("full", "partial"), 
                   estTotPhiBias = c(resEvalFull, resEvalHT))
      
      row <- row + 2L
      
      # Estimations of t_phi1 and t_phi2
      # - With true weights
      estTotPhiYintHTTrueMP <- 
        phi[maskInt] * 
        trueWeights[maskInt] * 
        Yint[maskInt]
      
      estTotPhiYintHTTrueMP <- sum(estTotPhiYintHTTrueMP)
      
      estTotPhiYtelHTTrueMP <- 
        (1.0 - phi[maskTel]) * 
        trueWeights[maskTel] * 
        Ytel[maskTel]
      
      # - With estimated weights
      estTotPhiYtelHTTrueMP <- sum(estTotPhiYtelHTTrueMP)
    
      estTotPhiYintHTEstMP <-
        phi[maskInt] *
        estimWeights[maskInt] *
        Yint[maskInt]
    
      estTotPhiYintHTEstMP <- sum(estTotPhiYintHTEstMP)
    
      estTotPhiYtelHTEstmMP <-
        (1.0 - phi[maskTel]) *
        estimWeights[maskTel] *
        Ytel[maskTel]
    
      estTotPhiYtelHTEstmMP <- sum(estTotPhiYtelHTEstmMP)
      
      ## Don't know why but some columns are
      ##  automatically converted as character
      partialResults$estTotPhiBias <- as.numeric(partialResults$estTotPhiBias)
      partialResults$trueEstimator <- as.logical(partialResults$trueEstimator)
      # Value estimated only on telephone answers, with estimated selection probabilities
      benchmark <- crossprod(estimWeights[maskTel], Ytel[maskTel]) %>% 
        as.vector()
      trueWeightsBenchmark <- crossprod(trueWeights[maskTel], Ytel[maskTel]) %>% 
        as.vector()

      
      partialResults <- partialResults %>% 
        add_column(.before = 1L, expn = sum(pi)) %>% 
        add_column(.after = "expn", n = sum(I)) %>% 
        add_column(.after = "n", trueTotalYtel = trueTotalYtel) %>% 
        add_column(.after = "trueTotalYtel", expTotYtel = expTotYtel) %>% 
        add_column(.before = "estTotPhiBias", truePhiBias = trueTotalBias) %>% 
        add_column(.after = "truePhiBias", expPhiBias = expPhiBias) %>% 
        add_column(.after = "expPhiBias", 
                   estTotPhiYintTrueMP = estTotPhiYintHTTrueMP) %>% 
        add_column(.after = "estTotPhiYintTrueMP", 
                   estTotPhiYintEstMP = estTotPhiYintHTEstMP) %>% 
        add_column(.after = "estTotPhiYintEstMP", 
                   estTotPhiYtelTrueMP = estTotPhiYtelHTTrueMP) %>% 
        add_column(.after = "estTotPhiYtelTrueMP", 
                   estTotPhiYtelEstMP = estTotPhiYtelHTEstmMP) %>% 
        mutate(.after = "estTotPhiYtelEstMP",
               estTotYtelTrueMP = estTotPhiYintTrueMP + 
                 estTotPhiYtelTrueMP -
                 estTotPhiBias) %>% 
        mutate(.after = "estTotYtelTrueMP", 
               estTotYtelEstMP = estTotPhiYintEstMP + 
                 estTotPhiYtelEstMP -
                 estTotPhiBias) %>% 
        add_column(.after = "estTotYtelEstMP", benchmark = benchmark) %>% 
        add_column(.after = "benchmark", TWBenchmark = trueWeightsBenchmark)
        
      #results <- rbind(results, partialResults)
    }
    
    clusterExport(cluster, 
                  varlist = "monoSim", 
                  envir = environment())
    
    ##browser()
    
    #results <- lapply(X = seq_len(K), FUN = monoSim)
    results <- parLapply(cluster, X = seq_len(K), fun = monoSim)
    
    stopCluster(cluster)
      

    if (fixZ)
    {
      parameters <- results[[1L]] %>% 
      select(parameter, probSelect, invMatrix, calculTotal)
      
      parameters[, c("expVar2", "expVarPhi1", "expVarPhi2", 
                     "expCovarPhi12", "expVarPhiDelta", 
                     "expCovarPhi1Delta", "expCovarPhi2Delta")] <- NA_real_
    
      for (l in seq_len(nrow(parameters)))
      {
        parameter <- parameters[l, ]
        
        if (parameter$parameter == "HT" && 
            parameter$invMatrix == "true" && 
            parameter$calculTotal == "full")
        {
          expVars <- var_estim_tot_BM(modeTotBiased = "HT", modeTotRef = "HT",
                                      calculTotal = "full",
                                      expY1 = expYint, expY2 = expYtel,
                                      covarY1 = covarYint, covarY2 = covarYtel,
                                      piMat = piMat,
                                      pq1Mat = pq1Mat, pq2Mat = pq2Mat,
                                      phi = phi,
                                      subResults = TRUE)
          
          parameters[l, names(expVars)] <- expVars
        }
      }
    }
    
    
    results <- do.call("rbind", results)
    
    if (any((betaInt - betaTel)[-1L] != 0.0))
        MBtype <- "variable"
      else
        MBtype <- "constant"
    
    results <- results %>% 
      add_column(.before = "n", sampling = sampling) %>% 
      add_column(.before = "sampling", N = N) %>% 
      add_column(.after = "n", YtelLaw = factor(YtelLaw)) %>% 
      add_column(.after = "YtelLaw", sdTel = sdTel) %>% 
      add_column(.after = "YtelLaw", YintLaw = factor(YintLaw)) %>% 
      add_column(.after = "YintLaw", sdInt = sdInt) %>% 
      add_column(.after = "YintLaw",
                 MBtype = factor(MBtype)) %>% 
      add_column(.after = "MBtype", phi = factor(phiType))
    
    if (fixZ)
    {
      suppressMessages(results <- results %>% inner_join(parameters, by = NULL))
    }
      
    
    
    # We calculate the real variance of the benchmark estimator
    if (fixZ)
    {
      sdTWBenchmark <- var_HT_seq_phi2(expY2 = expYtel, 
                                       covarY2 = covarYtel,
                                       piMat = piMat,
                                       pq1Mat = pq1Mat,
                                       pq2Mat = pq2Mat,
                                       phi = numeric(N)) %>% sqrt()
      
      results <- results %>% 
        mutate(expSDTWBenchmark = sdTWBenchmark)
    }
    
    results
  }
```


-   `trueTotalYtel`: $t_{tel} =\sum_{k \in U} y_{2k}$ for this iteration
-   `expTotYtel` : $\mathbb{E}[t_{tel}]=\mathbb{E} [\sum_{k \in U} y_{2k}]$
-   `estTotPhiBias` : $t_{\phi \hat{\Delta y}}$
-   `truePhiBias` : $t_{\phi\Delta y}=\sum_{k\in U} \phi_k \Delta y_k$
-   `expPhiBias` : $\mathbb{E}[t_{\phi\Delta y}]$
-   `estTotPhiYintTrueMP` : $\hat{t}_{p,\phi y_1} = \sum_{k \in S_r}\frac{\phi_k y_{1k}}{\pi_k p_{1k}}$
-   `estTotPhiYintEstMP` : $\hat{t}_{\hat{p},\phi y_1} = \sum_{k \in S_r}\frac{\phi_k y_{1k}}{\pi_k \hat{p}_{1k}}$
-   `estTotPhiYintEstMP` : $\hat{t}_{\hat{p},\phi y_1} + \hat{t}_{\hat{p},\phi y_2} - t_{\phi \hat{\Delta y}}$
-   `benchmark` : $\sum_{k \in S_{mr}} \frac{y_{2k}}{\pi_k(1-p_{1k})p_{2k}}$
-   `calculTotal` : `full` if we calculate $\hat{t}_{\phi \hat{\Delta y}}$ (imputation on the entire population), `partial` if it is $t_{\phi \hat{\Delta y}}$ (on $S_{r\bullet}$)


## Measure bias evaluation

Evaluation of $K$ experiments

```{r}
K <- 2000L
```

```{r}
#| echo: false

results <- NULL
nbResults <- 0L

# Grid of all evaluated parameters
parameters <- expand_grid(constBias = c(TRUE, FALSE), 
                          sampling = "SRS",#c("SRS", "STSRS"),
                          YtelLaw = c("gaussian", "exponential"),
                          YintLaw = c("gaussian", "exponential"),
                          signAge = c("plus", "minus"),
                          phi = c("eq", "var"),
                          sdY = c(1.0, 2.0, 5.0)) %>% 
  mutate(sdY = 
           ifelse(YtelLaw == "gaussian" |
                    YintLaw == "gaussian", sdY, NA_real_)) %>% 
  distinct()


betaTelMinus <- betaTel
betaIntMinus <- betaInt

# Case when the sign a the age coefficient for telephone is positive
betaTelPlus <- betaTel
betaTelPlus[-1L] <- -betaTel[-1L]
betaIntPlus <- betaInt
betaIntPlus[-1L] <- -betaInt[-1L]

bar <- progress_bar$new(total = nrow(parameters),
                        format = "[:bar] :current/:total (:percent) eta: :eta")

for (i in seq_len(nrow(parameters)))
{
  tic()
  expParams <- parameters[i, ]
  #print(expParams)

  
  if (expParams$signAge == "plus")
  {
    betaIntTemp <- betaIntPlus
    betaTelTemp <- betaTelPlus
  }
  else if (expParams$signAge == "minus")
  {
    betaIntTemp <- betaIntMinus
    betaTelTemp <- betaTelMinus
  }
  
  if (expParams$constBias)
    betaIntTemp[-1L] <- betaTelTemp[-1L]
  
  expResults <- simulationUncounf(N, K = K,
                                  Z = Z, fixZ = TRUE,
                                  sampling = expParams$sampling,
                                  alphaInt = alphaInt,
                                  alphaTel = alphaTel,
                                  betaInt = betaIntTemp,
                                  betaTel = betaTelTemp,
                                  YtelLaw = expParams$YtelLaw,
                                  YintLaw = expParams$YintLaw,
                                  phi = expParams$phi,
                                  sdInt = expParams$sdY,
                                  sdTel = expParams$sdY,
                                  seed = 200L)
  
  expResults <- expResults %>% 
    rename(sd = sdInt) %>% 
    select(-sdTel) %>% 
    mutate(signAge = expParams$signAge)

  if (i == 1L)
    expNbResults <- nrow(expResults)
  
  nbResults <- nbResults + expNbResults
  expResults <- expResults %>% 
    add_column(.before = 1L, 
               experiment = factor(rep(nbResults + seq_len(K), 
                                       each = expNbResults / K)))
  
  results <- rbind(results, expResults)
  
  #t <- toc(quiet = TRUE)
  
  #glue("{round(unname(t$toc - t$tic))}s ({i} / {nrow(parameters)})") %>% print()
  bar$tick()
}

rm(i, 
   betaIntMinus, betaTelMinus, 
   betaIntPlus, betaTelPlus, 
   betaIntTemp, betaTelTemp, 
   nbResults, t, expResults)

results$signAge <- as.factor(results$signAge)
results$parameter <- as.factor(results$parameter)
results$probSelect <- as.factor(results$probSelect)
results$invMatrix <- as.factor(results$invMatrix)
results$calculTotal <- as.factor(results$calculTotal)

results <- results %>% 
  mutate(.after = "estTotPhiBias", diffPhiBias = estTotPhiBias - truePhiBias) %>% 
  mutate(.after = "estTotPhiYtelEstMP", 
         diffTotYtelEstMP = estTotYtelEstMP - trueTotalYtel) %>% 
  mutate(.after = "estTotPhiYtelTrueMP",
         diffTotYtelTrueMP = estTotYtelTrueMP - trueTotalYtel) %>% 
  mutate(.after = diffTotYtelTrueMP, diffBenchmark = benchmark - trueTotalYtel)
```

## Impact of $K$

We would like to consider the impact of $K$ on the different results, especially knowing if it is needed to have an important $K$ to infer.

We focus on a simple particular case:
```{r}
temp <- results %>% 
  filter(sampling == "SRS",
         YintLaw == "gaussian", YtelLaw == "gaussian",
         parameter == "HT", probSelect == "true",
         invMatrix == "true", calculTotal == "full",
         phi == "eq", sd == 1.0, MBtype == "variable",
         signAge == "plus")
```

Evolution of the bias:
```{r}
sumBiases <- cumsum(temp[, c("diffPhiBias", "diffTotYtelEstMP")])

Kvec <- seq_len(K)

biases <- 
  data.frame(totPhiDelta =  sumBiases[, "diffPhiBias"] / Kvec,
             totYtel = sumBiases[, "diffTotYtelEstMP"] / Kvec,
             K = Kvec)

biases %>% 
  pivot_longer(cols = c("totPhiDelta", "totYtel"), 
               names_to = "target", 
               values_to = "estBias") %>% 
  ggplot() +
  geom_point(aes(x = K, y = estBias, colour = target)) +
  ggtitle("Estimated bias depending on the number of evaluations (K)")

rm(biases)
```

And the RMSE:
```{r}
sumSqErrors <- cumsum(temp[, c("diffPhiBias", "diffTotYtelEstMP")]^2L)

RMSEs <- 
  data.frame(totPhiDelta =  sumSqErrors[-1L, "diffPhiBias"] / Kvec[-1L],
             totYtel = sumSqErrors[-1L, "diffTotYtelEstMP"] / Kvec[-1L],
             K = Kvec[-1L])

RMSEs %>% 
  pivot_longer(cols = c("totPhiDelta", "totYtel"), 
               names_to = "target", 
               values_to = "estRMSE") %>% 
  ggplot() +
  geom_point(aes(x = K, y = estRMSE, colour = target)) +
  ggtitle("Estimated RMSE depending on the number of evaluations (K)")

rm(temp, RMSEs)
```


## Ex : Gaussian constant measure bias

Results of each parameter for the case of SRS with **constant** measure bias and Gaussian laws (with $\sigma =1$).

### Measure bias total

$$\text{relError} = \frac{1}{K}\sum_{k=1}^K \frac{\hat{t}_{\phi\Delta y,k}-t_{\phi\Delta y,k}}{\mathbb{E}[t_{\phi\Delta y}]}$$

$$\text{relRMSE} = \frac{\sqrt{\frac{1}{K}\sum_{k=1}^K (\hat{t}_{\phi\Delta y,k}-t_{\phi\Delta y,k})^2}}{|\mathbb{E}[t_{\phi\Delta y}]|}$$

```{r}
temp <- results %>% 
  filter(YtelLaw == "gaussian", YintLaw == "gaussian", 
         sampling == "SRS", 
         MBtype == "constant", signAge == "plus",
         probSelect != "true", sd == 1.0) %>% 
  select(-sampling, -MBtype) %>% 
  group_by(phi, parameter, probSelect, invMatrix, calculTotal)

temp %>% 
  summarise(K = n(),
            relError = round(mean(diffPhiBias / abs(expPhiBias)), 4L), 
            relRMSE = round(sqrt(mean(diffPhiBias^2L / expPhiBias^2L)), 4L)) %>% 
  ungroup() %>% 
  arrange(relRMSE)
```

### telephone total estimation

```{r}
temp %>% 
  summarise(K = n(),
            #reldiffTotalTrueMean = round(mean(diffTotYtelTrueMP / abs(expTotYtel)) , 4L), 
            relTotError = round(mean(diffTotYtelEstMP / abs(expTotYtel)), 4L),
            relDiffBenchmarkMean = round(mean(diffBenchmark / abs(expTotYtel)), 4L),
            #relRMSETrue = round(sqrt(mean(diffTotYtelTrueMP^2L / expTotYtel^2L)), 4L),
            relRMSEParam = round(sqrt(mean(diffTotYtelEstMP^2L / expTotYtel^2L)), 4L),
            relExpSD = round(mean(expVar2 / expTotYtel), 4L),
            relRMSEBenchmark = round(sqrt(mean(diffBenchmark^2L / expTotYtel^2L)), 4L),
            relExpSDTWBenchmark = mean(expSDTWBenchmark / abs(expTotYtel))) %>% 
  ungroup() %>% 
  arrange(relRMSEParam)

rm(temp)
```

## Ex : Gaussian variable measure bias

Results of each parameter for the case of SRS with **variable** measure bias and Gaussian laws. First we focus on the bias:


```{r}
temp <- results %>% 
  filter(YtelLaw == "gaussian", YintLaw == "gaussian", 
         sampling == "SRS", MBtype == "variable", trueEstimator) %>% 
  select(-sampling, -MBtype) %>% 
  group_by(sd, phi, parameter, probSelect, invMatrix, calculTotal) %>% 
  summarise(#reldiffTotalTrueMean = round(mean(diffTotYtelTrueMP / abs(expTotYtel)) , 4L), 
            relTotError = round(mean(diffTotYtelEstMP / abs(expTotYtel)) , 4L),
            relDiffBenchmarkMean = round(mean(diffBenchmark / abs(expTotYtel)), 4L),
            #relRMSETrue = round(sqrt(mean(diffTotYtelTrueMP^2L / expTotYtel^2L)), 4L),
            relRMSEParam = round(sqrt(mean(diffTotYtelEstMP^2L / expTotYtel^2L)), 4L),
            relRMSEBenchmark = round(sqrt(mean(diffBenchmark^2L / expTotYtel^2L)), 4L),
            relSdTWBenchmark = mean(expSDTWBenchmark / abs(expTotYtel))) %>% 
  ungroup() %>% 
  group_by(sd) %>% 
  arrange(abs(relTotError), .by_group = TRUE) %>% 
  ungroup()

temp %>% 
  select(-relRMSEParam, -relRMSEBenchmark, -relSdTWBenchmark)
```


And now the RMSE:

```{r}
temp %>% 
  select(-relTotError, -relTotError, -relDiffBenchmarkMean) %>% 
  arrange(relRMSEParam, .by_group = TRUE)
```


It is better to have $\phi_k \equiv \phi$ compared to $\phi_k = \frac{k}{N}$. Summing the bias on exclusively $S_{r\bullet}$ seems to be effective (with `calculTotal = partial`).

```{r}
temp %>%
  mutate(ratioRMSE = relRMSEParam / relRMSEBenchmark) %>% 
  ggplot() + geom_histogram(aes(x = ratioRMSE)) +
  ggtitle("Ratio RMSE parameter compared to RMSE benchmark")
```

Here are the parameters that offer a better RMSE than the benchmark:
```{r}
temp %>% 
  select(-relTotError, -relDiffBenchmarkMean) %>% 
  filter(relRMSEParam <= relRMSEBenchmark) %>% 
  arrange(relRMSEParam)
```

Estimators that are the most present:
```{r}
temp %>% 
  select(-relTotError, -relDiffBenchmarkMean) %>% 
  filter(relRMSEParam <= relRMSEBenchmark) %>% 
  group_by(phi, parameter, probSelect, invMatrix, calculTotal) %>% 
  summarize(n = n()) %>% 
  arrange(-n)
```

And the parameters that offer the worse RMSE compared to the benchmark:

```{r}
temp %>% 
  slice_max(relRMSEParam, n = 5L)
```

```{r}
rm(temp)
```


## More general cases

### Telephone total estimation

Estimated bias for each condition (only for true estimators):

```{r}
temp <- results %>% 
  filter(trueEstimator) %>% 
  group_by(YintLaw, YtelLaw, sd, signAge, MBtype, phi,
           sampling, parameter, probSelect, invMatrix, calculTotal)

temp %>% 
  summarise(relTotError = 
              round(mean(diffTotYtelEstMP / abs(expTotYtel)), 4L))
```


Optimal RMSE for each condition:

```{r}
temp <- temp %>% 
  summarise(#reldiffTotalTrueMean = round(mean(diffTotYtelTrueMP / abs(expTotYtel)) , 4L), 
            relTotError = round(mean(diffTotYtelEstMP / abs(expTotYtel)) , 4L),
            relDiffBenchmarkMean = round(mean(diffBenchmark / abs(expTotYtel)), 4L),
            #relRMSETrue = round(sqrt(mean(diffTotYtelTrueMP^2L / expTotYtel^2L)), 4L),
            relRMSEParam = round(sqrt(mean(diffTotYtelEstMP^2L / expTotYtel^2L)), 4L),
            relRMSEBenchmark = round(sqrt(mean(diffBenchmark^2L / expTotYtel^2L)), 4L)) %>% 
  ungroup() 

temp %>% 
  group_by(sd, YintLaw, YtelLaw, sampling) %>% 
  slice_min(relRMSEParam)
```

Here are the parameters that offer a better RMSE than the benchmark:
```{r}
temp %>% 
  filter(relRMSEParam <= relRMSEBenchmark) %>% 
  group_by(YintLaw, YtelLaw)
```
List of situations that offer a better RMSE with some parameter different than the benchmark:

```{r}
tempBis <- temp %>% 
  group_by(YtelLaw, sd, YintLaw, sampling, signAge, MBtype)

nbExperiments <- n_groups(tempBis)

tempBis %>% 
  summarise(nbEstimators = sum(relRMSEParam <= relRMSEBenchmark),
            bestRelRMSE = min(relRMSEParam),
            relRMSEBenchmark = mean(relRMSEBenchmark)) %>% 
  arrange(bestRelRMSE / relRMSEBenchmark)

rm(tempBis)
```

Estimators that are the most present (which have a lower value of RMSE compared to the benchmark, not necessarily the lowest):
```{r}
temp %>% 
  select(-relTotError, -relDiffBenchmarkMean, -probSelect) %>% 
  filter(relRMSEParam <= relRMSEBenchmark) %>% 
  group_by(phi, parameter, invMatrix, calculTotal) %>% 
  summarize(n = n(), ratio = n / nbExperiments) %>% 
  arrange(-n)
```

Case when HT-sample-partial is the best:

```{r}
temp %>% 
  group_by(YtelLaw, sd, YintLaw, sampling, signAge, MBtype) %>% 
  filter(relRMSEParam <= relRMSEBenchmark) %>% 
  slice_min(relRMSEParam) %>% 
  filter(parameter == "HT", invMatrix == "sample", calculTotal == "partial") %>% 
  distinct(YtelLaw, sd, YintLaw, sampling, signAge, MBtype)
```
RAJOUTER UN COMMENTAIRE
Case when HT-true-full is the best:

```{r}
temp %>% 
  group_by(YtelLaw, sd, YintLaw, sampling, signAge, MBtype) %>% 
  filter(relRMSEParam <= relRMSEBenchmark) %>% 
  slice_min(relRMSEParam) %>% 
  filter(parameter == "HT", invMatrix == "true", calculTotal == "full") %>% 
  distinct(YtelLaw, sd, YintLaw, sampling, signAge, MBtype)
```

RAJOUTER UN COMMENTAIRE

Cases when the triples HT-sample-partial and HT-true-full are not optimal (or not the only one with the lowest RMSE):

```{r}
temp %>% 
  group_by(YtelLaw, sd, YintLaw, sampling, signAge, MBtype) %>% 
  filter(relRMSEParam <= relRMSEBenchmark) %>% 
  slice_min(relRMSEParam) %>% 
  filter(parameter != "HT" | invMatrix != "sample" | calculTotal != "partial", 
         parameter != "HT" | invMatrix != "true" | calculTotal != "full") %>% 
  distinct(YtelLaw, sd, YintLaw, sampling, signAge, MBtype)
  
```

Ã€ CHANGER :
The both estimators seems to be more effective that the others when the measure bias is not a constant with random noise (they are not optimal in 100% of the constant scenarios).


Here are the estimators that are more efficient in the constant cases:

```{r}
temp %>% 
  filter(relRMSEParam <= relRMSEBenchmark, MBtype == "constant") %>% 
  filter(parameter != "HT" | invMatrix == "sample" | calculTotal != "partial", 
         parameter != "HT" | invMatrix != "true" | calculTotal != "full") %>% 
  group_by(YtelLaw, sd, YintLaw, sampling, signAge, MBtype) %>% 
  slice_min(relRMSEParam) %>% 
  ungroup() %>% 
  group_by(phi, parameter, invMatrix, calculTotal) %>% 
  summarize(n = n()) %>% 
  arrange(-n)
```

When `MCO_unique` is efficient?
```{r}
rm(temp)
```

### Variances

Here we focus on the special case when selection probabilities are known and the estimator is Horvitz-Thompson with the complete inverse matrix and the summation for $\hat{t}_{\phi\Delta}$ is made on the entire population.
```{r}
results %>% 
  filter(parameter == "HT", probSelect == "true", 
         invMatrix == "true", calculTotal == "full") %>% 
  group_by(sampling, YintLaw, YtelLaw, sd, MBtype, signAge, phi) %>% 
  summarise(K = n(),
            estVar2 = var(estTotYtelTrueMP),
            expVar2 = mean(expVar2),
            estVarPhi1 = var(estTotPhiYintTrueMP),
            expVarPhi1 = mean(expVarPhi1),
            estVarPhi2 = var(estTotPhiYtelTrueMP),
            expVarPhi2 = mean(expVarPhi2),
            estCovarphi12 = cov(estTotPhiYintTrueMP, estTotYtelTrueMP),
            expCovarPhi12 = mean(expCovarPhi12),
            estCovarphi1Delta = cov(estTotPhiYintTrueMP, estTotPhiBias),
            expCovarPhi1Delta = mean(expCovarPhi1Delta),
            estVarPhiDelta = var(estTotPhiBias),
            expVarPhiDelta = mean(expVarPhiDelta),
            estCovarphi2Delta = cov(estTotPhiYtelTrueMP, estTotPhiBias),
            expCovarPhi2Delta = mean(expCovarPhi2Delta))
```
