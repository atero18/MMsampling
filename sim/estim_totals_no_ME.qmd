---
title: "Estimation of totals (without measure effect)"
format:
  html:
    toc: true
    html-math-method: katex
    css: styles.css
---

```{r}
# knitr::purl("./sim/test_estim.qmd")
```

```{r}
#| message: false
#| warning: false
library(dplyr)
options(dplyr.summarise.inform = FALSE)
library(tibble)
library(tidyr)
library(glue)
library(parallel)
library(ggplot2)
theme_set(theme_light())
## library(Matrix)
library(progress)
## library(marginaleffects)
library(mc2d)
library(mvtnorm)
library(MatchIt)
```

# Population generation

```{r}
source("simulation_functions.R")
```

```{r}
RNGkind(kind = "L'Ecuyer-CMRG")
set.seed(145L)
```

```{r}
N <- 10000L
```

Creating independent covariates, using the 2022 French age pyramid ([INSEE](https://www.insee.fr/fr/statistiques/6688661?sommaire=6686521))

```{r}
gen_covariates <- function(N)
{
  pyramid <- read.csv("./population_pyramid_FR_2022.csv",
                      header = TRUE, dec = ".") %>% 
    mutate(sex = if_else(sex == "Man", 1L, 0L))
  
  groupUnits <- sample(seq_len(nrow(pyramid)), size = N, 
                       replace = TRUE, prob = pyramid$percentage)
  
  pyramid[groupUnits, c("age", "sex")] %>% 
    mutate(const = 1.0, .before = 1L) %>% 
    remove_rownames()
}


Z <- gen_covariates(N)

sex <- factor(Z$sex)
levels(sex) <- c("Woman", "Man")
```

```{r}
summary(Z[, -1L])
```

```{r}
data <- Z[, c("sex", "age")]
data$sex <- sex
ggplot(data) + 
  geom_density(aes(x = age, colour = sex)) +
  ggtitle("Age density conditionally to the sex")

data %>% 
  group_by(sex) %>% 
  summarize(meanAge = mean(age))
rm(data)
```

```{r}
Z <- as.matrix(Z)
```

Creating a regression vector for both mode : $\beta$ is defined to have in average a counterfactual expectation for each mode equal to one.

```{r}
beta <- c(0.0, -0.1, 4.0)
beta[1L] <- 1.0 - mean(Z %*% beta)
print(beta)
```

$Y_{1}$ and $Y_{2}$ expectations depebd on `Z`:

```{r}
data.frame(Yexp = Z %*% beta) %>% 
  ggplot() + 
  geom_density(aes(x = Yexp)) +
  ggtitle("Distribution of the potential outcomes expected values")
```

We simulate a mode selection MAR (Missing At Random) under a logistic model, with $Z$ as variable:

```{r}
alpha1 <- c(0.7, -0.02, -0.5)

alpha2 <- c(0.4, -0.01, -0.3)
```

```{r}
gen_selection_probabilities <- function(Z, alpha)
{
  expit <- function(x) 1.0 / (1.0 + exp(-x))

  expit(Z %*% alpha) %>%
    as.vector()
}

p1 <- gen_selection_probabilities(Z, alpha1)
p2 <- gen_selection_probabilities(Z, alpha2)
```


Here are some details about the $p_{1k}$ and $p_{2k}$:

```{r}
glue("m1 probabilities:\n")
summary(p1) %>% print()
glue("m2 probabilities:\n")
summary(p2) %>% print()
```

```{r}
data.frame(mode = factor(rep(c("m1", "m2"), each = N)), 
           prob = c(p1, p2)) %>% 
  ggplot() + 
  geom_density(aes(x = prob, color = mode)) +
  ggtitle("Distribution of p1 and p2") +
  xlab("mode selection probability")
```

```{r}
p1[sex == "Man"] %>% summary()
p1[sex == "Woman"] %>% summary()
```

Probability to answer by $m_2$ under to the sequential protocol (i.e. do not answer by $m_1$ and agree to answer by $m_2$):
```{r}
pRep2 <- (1.0 - p1) * p2
summary(pRep2)
```

About $S_{r\bullet}$ (case of SRS with $f = \frac{1}{10}$):

```{r}
# Calculation of the inclusion covariance matrix using the
# second order inclusion probabilities.
pi2_to_covarInc <- function(pi2)
{
  pi <- diag(pi2)
  pi2 - outer(pi, pi)
}

# Generates the second order inclusion probabilities matrix of a
# Simple Random Sampling (SRS) design
piMat_SRS <- function(n, N)
{
  pi_mat <- matrix(n * (n - 1L) / (N * (N - 1L)), nrow = N, ncol = N)
  diag(pi_mat) <- n / N

  pi_mat
}
```


```{r}
f <- 1.0 / 10.0
n <- f * N
expSizeSr <- f * sum(p1)

pi <- rep(f, N)
pi_mat <- piMat_SRS(n, N)
pCov <- pi2_to_covarInc(pi_mat)
varSizeSr <- f * sum(p1 * (1.0 - p1)) + 
  t(p1) %*% pCov %*% p1 %>% 
  as.numeric()

glue("Expected size of Sr : {expSizeSr}")
glue("Variance of the size of Sr : {varSizeSr}")
```

About $S_{mr}$ (case of SRS with $f = \frac{1}{10}$):

```{r}
expSizeSmr <- f * sum(pRep2)

varSizeSmr <- f * sum(pRep2 * (1.0 - p2)) + 
  f * sum(pRep2 * (1.0 - p1)) +
  t(pRep2) %*% pCov %*% pRep2 %>% 
  as.numeric()

glue("Expected size of Smr : {expSizeSmr}")
glue("Variance of the size of Smr : {varSizeSmr}")
```

About $S_a$ (case of SRS with $f = \frac{1}{10}$):

```{r}
expSizeSa <- expSizeSr + expSizeSmr

varSizeSa <- f * sum(pRep2 * (1.0 - p2)) + 
  f * sum(p1 * (1.0 - p1) * (1.0 - p2)) +
  t(p1 + pRep2) %*% pCov %*% (p1 + pRep2) %>% 
  as.numeric()

glue("Expected size of Sa : {expSizeSa}")
glue("Variance of the size of Sa : {varSizeSa}")

rm(f, pCov, pi, pi_mat)
rm(expSizeSr, varSizeSr, 
   expSizeSmr, varSizeSmr, 
   expSizeSa, varSizeSa)
```

# Total estimation

## Total estimators

```{r}
estim_tot_m1 <- function(Yobs, modes, pi, p1, phi = rep(1.0, length(Yobs)))
{
  maskSr <- modes == "m1"
  
  sum((pi[maskSr] * p1[maskSr])^-1L * phi[maskSr] * Yobs[maskSr])
}
```

```{r}
estim_tot_m2 <- function(Yobs, modes, pi, p1, p2, phi = rep(1.0, length(Yobs)))
{
  maskSmr <- modes == "m2"
  
  sum((pi[maskSmr] * (1.0 - p1[maskSmr]) * p2[maskSmr])^-1L *
        phi[maskSmr] * Yobs[maskSmr])
}
```

```{r}
estim_tot_m1_m2 <- function(Yobs, modes, pi, p1, p2, phi = rep(0.5, length(Yobs)))
{
  estim_tot_m1(Yobs, modes, pi, p1, phi) +
    estim_tot_m2(Yobs, modes, pi, p1, p2, 1.0 - phi)
}
```


```{r}
estim_tot_a <- function(Yobs, responses, pi, pa)
{
  maskSa <- responses == "r"
  
  sum((pi[maskSa] * pa[maskSa])^-1L * Yobs[maskSa])
}
```

## Approximate variance estimators

Fisher Information Matrix with a logistic model and weights equal to 1.

```{r}
Fisher_Information_Matrix <- function(prob, 
                                      Z, 
                                      maskSubset = !logical(length(prob)))
{
  probSubset <- prob[maskSubset]
  ZSubset <- Z[maskSubset, , drop = FALSE]

  crossprod(ZSubset, probSubset * (1.0 - probSubset) * ZSubset)
}
```

```{r}
# estim_appr_var_seq_m1 <- function(Yobs,
#                                   modes,
#                                   I, 
#                                   pi_mat,
#                                   p1,
#                                   sd1 = NULL,
#                                   phi = rep(1.0, length(Yobs)),
#                                   correcEstimWeights = FALSE,
#                                   Z = matrix(1.0, nrow = length(Yobs), ncol = 1L))
# {
#   maskSr <- modes == "m1"
#   
#   # If sd1 is not given we use the estimated standard deviation
#   # (assumed independent of the covariates) of the y_1k 
#   # with the m1 outcomes
#   if (is.null(sd1))
#     sd1 <- sd(Yobs[maskSr], na.rm = FALSE)
# 
#   pi <- diag(pi_mat)
#   piSr <- pi[maskSr]
#   p1Sr <- p1[maskSr]
# 
#   # The y_1k are weighted with the phi_k
# 
#   weightedY1Sr <- phi[maskSr] * Yobs[maskSr]
# 
#   # Sampling variability (S)
#   # There is no correction needed for probabilities estimation
#   piSr_mat <- pi_mat[maskSr, maskSr]
#   covarpSr <- pi2_to_covarInc(piSr_mat)
# 
#   correctedY1Srp <- (piSr * p1Sr)^-1L * weightedY1Sr
#   varpEst <-
#     t(correctedY1Srp) %*%
#     (covarpSr / piSr_mat) %*%
#     correctedY1Srp %>%
#     as.numeric()
#   varpEst <- varpEst +
#     sum((1.0 - piSr) * piSr^-2L * p1Sr^-1L * (1.0 - p1Sr^-1L) *
#           weightedY1Sr^2L)
# 
#   # q1 variability (R1)
#   # If we use estimated p_1k weights we have to make a correction
#   correctedY1Srq1 <- correctedY1Srp
# 
#   #   If the probabilities p_1k are estimations we add a linearisation term
#   if (correcEstimWeights)
#   {
#     estVPhi11 <- -crossprod(Z[maskSr, , drop = FALSE],
#                           (pi[maskSr] * p1Sr)^-1L *
#                             phi[maskSr] * Yobs[maskSr] * (1.0 - p1Sr))
# 
# 
#     estbPhi11 <- solve(Fisher_Information_Matrix(p1, Z, I)) %*% estVPhi11
#     correctedY1Srq1 <- correctedY1Srq1 + Z[maskSr, , drop = FALSE] %*% estbPhi11
#   }
# 
#   varq1Est <- sum((1.0 - p1Sr) * correctedY1Srq1^2L)
# 
# 
#   # Y1 variability
#   # We suppose the potential outcomes homoscedastic and
#   # we have an estimator of the variance of the Y1
#   varY1Est <- sum(phi^2L) * sd1^2L
# 
#   varpEst + varq1Est + varY1Est
# }
```

```{r}
# estim_appr_var_seq_m2 <- function(Yobs,
#                                   modes,
#                                   I,
#                                   pi_mat,
#                                   p1,
#                                   p2,
#                                   sd2 = NULL,
#                                   phi = rep(1.0, length(Yobs)),
#                                   correcEstimWeights = FALSE,
#                                   Z = matrix(1.0, nrow = length(Yobs), ncol = 1L))
# {
# 
#   maskSmr <- modes == "m2"
#   
#   # If sd2 is not given we use the estimated standard deviation
#   # (assumed independent of the covariates) of the y_2k 
#   # with the m2 outcomes
#   if (is.null(sd2))
#     sd2 <- sd(Yobs[maskSmr], na.rm = FALSE)
# 
#   pi <- diag(pi_mat)
#   piSmr <- pi[maskSmr]
#   p1Smr <- p1[maskSmr]
#   p1barSmr <- 1.0 - p1Smr
# 
#   p2Smr <- p2[maskSmr]
# 
#   # The y_2k are weighted with the phi_k
#   weightedY2Smr <- phi[maskSmr] * Yobs[maskSmr]
# 
#   # Sampling variability (S)
#   piSmr_mat <- pi_mat[maskSmr, maskSmr]
#   covarpSmr <- pi2_to_covarInc(piSmr_mat)
# 
#   correctedY2Smrp <- (piSmr * p1barSmr * p2Smr)^-1L * weightedY2Smr
#   varpEst <-
#     t(correctedY2Smrp) %*%
#     (covarpSmr / piSmr_mat) %*%
#     correctedY2Smrp %>%
#     as.numeric()
#   varpEst <- varpEst +
#     sum((1.0 - piSmr) * piSmr^-2L * (p1barSmr * p2Smr)^-1L *
#           (1.0 - (p1barSmr * p2Smr)^-1L) * weightedY2Smr^2L)
# 
# 
#   # q1 variability (R1)
#   correctedY2Smrq1 <- (piSmr * p1barSmr)^-1L * weightedY2Smr
# 
#   #   If the probabilities p_1k are estimations we add a term
#   #   that uses the covariates used by the regression estimators of
#   #   alpha1 (the parameter of the logistic model for the m1 response)
#   if (correcEstimWeights)
#   {
#     estVPhi21 <- crossprod(Z[maskSmr, , drop = FALSE],
#                            (pi[maskSmr] * (1.0 - p1Smr) * p2[maskSmr])^-1L *
#                              phi[maskSmr] * Yobs[maskSmr] * p1Smr)
#     
# 
#     estbPhi21 <- solve(Fisher_Information_Matrix(p1, Z, I)) %*% estVPhi21
#     correctedY2Smrq1 <- correctedY2Smrq1 - Z[maskSmr, ] %*% estbPhi21
#   }
# 
#   varq1Est <- sum(p1Smr * p2Smr^-1L * correctedY2Smrq1^2L)
# 
# 
#   # q2 variability (R2)
#   correctedY2Smrq2 <- correctedY2Smrp
# 
#   #   If the probabilities p_1k are estimations we add a term
#   #   that uses the covariates used by the regression estimators of
#   #   alpha2 (the parameter of the logistic model for the mode-2 response)
#   if (correcEstimWeights)
#   {
#     estVPhi22 <- -crossprod(Z[maskSmr, , drop = FALSE],
#                           (pi[maskSmr] * (1.0 - p1[maskSmr]) * p2Smr)^-1L *
#                             (1.0 - p2Smr) * phi[maskSmr] * Yobs[maskSmr])
# 
# 
#     estbPhi22 <- solve(Fisher_Information_Matrix(p2, Z, maskSm)) %*% estVPhi22
#     
#     correctedY2Smrq2 <- correctedY2Smrq2 + Z[maskSmr, ] %*% estbPhi22
#   }
# 
#   varq2Est <- sum((1.0 - p2Smr) * correctedY2Smrq2^2L)
# 
# 
#   # Y2 variability
#   varY2Est <- sum(phi^2L) * sd2^2L
# 
#   varpEst + varq1Est + varq2Est + varY2Est
# }
```

```{r}
# ... : arguments for matching
estim_appr_var_seq_m1_m2 <- function(Yobs,
                                     modes,
                                     I,
                                     pi_mat,
                                     p1,
                                     p2,
                                     sd1 = NULL,
                                     sd2 = sd1,
                                     rho = 0.8,
                                     phi = rep(0.5, length(Yobs)),
                                     correcEstimWeights = TRUE,
                                     Z = matrix(1.0, nrow = length(Yobs), ncol = 1L),
                                     m1Only = FALSE,
                                     m2Only = FALSE,
                                     ...)
{
  
  pi <- diag(pi_mat)
  N <- length(pi)
  
  maskSr <- modes == "m1"
  maskSmr <- modes == "m2"
  maskSa <- maskSr | maskSmr
  na <- sum(maskSa) # Number of respondents
  maskm1Sa <- modes[maskSa] == "m1" # mask of the m1 respondents within Sa
  
  m1Only <- (m1Only || all(phi == 1.0, na.rm = TRUE))
  m2Only <- (m2Only || all(phi == 0.0, na.rm = TRUE)) && !m1Only
  
  if (m1Only)
    phi <- rep(1.0, N)
  else if (m2Only)
    phi <- numeric(N)
  
  if (!m1Only && !m2Only)
    requireNamespace(package = "MatchIt", versionCheck = NULL, quietly = FALSE)
  
  piSa <- pi[maskSa]
  p1Sa <- p1[maskSa]
  p1barSa <- 1.0 - p1Sa
  
  if (!m2Only)
  {
    phiSr <- phi[maskSr]
    Y1Sr <- Yobs[maskSr]
    phiY1Sr <- phiSr * Y1Sr
    
    # If sd1 is not given we use the estimated standard deviation
    # (assumed independent of the covariates) of the y_1k 
    # with the m1 outcomes
    if (is.null(sd1))
      sd1 <- sd(Y1Sr)
    
    piSr <- pi[maskSr]
    p1Sr <- p1[maskSr]
    
    piSr_mat <- pi_mat[maskSr, maskSr]
    covarpSr <- pi2_to_covarInc(piSr_mat)
  }
  else
  {
    rho <- 0.0
    sd1 <- 0.0
  }
    
  
  if (!m1Only)
  {
    phiSmr <- phi[maskSmr]
    Y2Smr <- Yobs[maskSmr]
    phiY2Smr <- (1.0 - phiSmr) * Y2Smr
    
    # If sd2 is not given we use the estimated standard deviation
    # (assumed independent of the covariates) of the y_2k 
    # with the m2 outcomes
    if (is.null(sd2))
      sd2 <- sd(Y2Smr)
    
    piSmr <- pi[maskSmr]
    p1Smr <- p1[maskSmr]
    p1barSmr <- 1.0 - p1Smr
    p2Smr <- p2[maskSmr]
    p2Sa <- p2[maskSa]
    
    piSmr_mat <- pi_mat[maskSmr, maskSmr]
    covarpSmr <- pi2_to_covarInc(piSmr_mat)
    
    
  }
  else
  {
    rho <- 0.0
    sd2 <- 0.0
    p2 <- NULL
  }
  
  # Sampling variability (S)
  # There is no correction needed for probabilities estimation
    # If we use only the m1 outcomes
    # (we do not weight by phi)
  if (m1Only)
  {
    correctedY1Srp <- (piSr * p1Sr)^-1L * Y1Sr
    varpEst <-
      t(correctedY1Srp) %*%
      (covarpSr / piSr_mat) %*%
      correctedY1Srp %>%
      as.numeric()
    varpEst <- varpEst +
      sum((1.0 - piSr) * piSr^-2L * p1Sr^-1L * (1.0 - p1Sr^-1L) *
            Y1Sr^2L)
    
    rm(covarpSr)
  }
    # If we use only the m2 outcomes
    # (we do not weight by 1 - phi)
  else if (m2Only)
  {
    Y2Smr <- Yobs[maskSmr]
    correctedY2Smrp <- (piSmr * p1barSmr * p2Smr)^-1L * Y2Smr
    varpEst <-
      t(correctedY2Smrp) %*%
      (covarpSmr / piSmr_mat) %*%
      correctedY2Smrp %>%
      as.numeric()
    varpEst <- varpEst +
      sum((1.0 - piSmr) * piSmr^-2L * (p1barSmr * p2Smr)^-1L *
            (1.0 - (p1barSmr * p2Smr)^-1L) * Y2Smr^2L)
    
    rm(covarpSmr)
  }
    # If we use the m1 and m2 outcomes
    # We will need here have to estimate the counterfactuals
    # on Sr (y_2k) and Smr (y_2k) by single matching with Z
  else
  {
    # Vectors that contains "estimation" of Y1 and Y2 respectively.
    # It is equal to the true value when it is known.
    YobsSa <- Yobs[maskSa]
    Y1SaEst <- Y2SaEst <- YobsSa
    
    dataMatchingSa <- as.data.frame(Z[maskSa, , drop = FALSE])
    dataMatchingSa$mode <- as.integer(maskm1Sa)
    row.names(dataMatchingSa) <- seq_len(na)
    
    # Estimation of the y_1k on Smr
    if (!all(phiSmr == 0.0))
    {
      matchingSmr <- 
        MatchIt::matchit(mode ~ ., data = dataMatchingSa, 
                         estimand = "ATC", replace = TRUE, ...)
      
      Y1SaEst[!maskm1Sa] <- YobsSa[as.integer(matchingSmr$match.matrix[, 1L])]
      
      rm(matchingSmr)
    }
    
    # Estimation of the y_2k on Sr
    if (!all(phiSr == 1.0))
    {
      matchingSr <- 
        MatchIt::matchit(mode ~ ., data = dataMatchingSa, 
                         estimand = "ATT", replace = TRUE, ...)
    
      Y2SaEst[maskm1Sa] <- YobsSa[as.integer(matchingSr$match.matrix[, 1L])]
      
      rm(matchingSr)
    }
    
    rm(dataMatchingSa)
    
    phiY1SaEst <- phi[maskSa] * Y1SaEst
    phiY2SaEst <- (1.0 - phi[maskSa]) * Y2SaEst
    
    
    piSa_mat <- pi_mat[maskSa, maskSa]
    covarpSa <- pi2_to_covarInc(piSa_mat)
    
    
    # The variance estimator is the average of the variance estimator based on
    # Sr and the one based on Smr
      # Sr
    PhiYSr <- phiY1SaEst[maskm1Sa] + phiY2SaEst[maskm1Sa]
    correctedPhiYSrp <- 
      (piSr * p1Sr)^-1L * PhiYSr
    
    varpSrEst <-
      t(correctedPhiYSrp) %*%
      (covarpSr / piSr_mat) %*%
      correctedPhiYSrp %>%
      as.numeric()
    varpSrEst <- varpSrEst + 
      sum((1.0 - piSr) * piSr^-2L * p1Sr^-1L * (1.0 - p1Sr^-1L) *
            PhiYSr^2L)
    
      # Smr
    PhiYSmr <- phiY1SaEst[!maskm1Sa] + phiY2SaEst[!maskm1Sa]
    correctedPhiYSmrp <- 
      (piSmr * p1barSmr * p2Smr)^-1L * PhiYSmr
    
    varpSmrEst <-
      t(correctedPhiYSmrp) %*%
      (covarpSmr / piSmr_mat) %*%
      correctedPhiYSmrp %>%
      as.numeric()
    varpSmrEst <- varpSmrEst +
      sum((1.0 - piSmr) * piSmr^-2L * (p1barSmr * p2Smr)^-1L *
            (1.0 - (p1barSmr * p2Smr)^-1L) * PhiYSmr^2L)
    
    varpEst <- 0.5 * (varpSrEst + varpSmrEst)
  }
  
  
  # q1 variability (R1)
  if  (correcEstimWeights)
  {
    ZSr <- Z[maskSr, , drop = FALSE]
    estLinCoefq1 <- 0.0
    if (!m2Only)
    {
      estVPhi11 <- -crossprod(ZSr,
                              (piSr * p1Sr)^-1L *
                                phiY1Sr * (1.0 - p1Sr))

      
      estbPhi11 <- solve(Fisher_Information_Matrix(p1, Z, I)) %*% 
        estVPhi11
      
      estLinCoefq1 <- estLinCoefq1 + estbPhi11
    }
    
    if (!m1Only)
    {
      ZSmr <- Z[maskSmr, , drop = FALSE]
      estVPhibar21 <- crossprod(ZSmr,
                                (piSmr * (1.0 - p1Smr) * p2Smr)^-1L *
                                  phiY2Smr * p1Smr)
      
      estbPhibar21 <- solve(Fisher_Information_Matrix(p1, Z, I)) %*% 
        estVPhibar21
      
      estLinCoefq1 <- estLinCoefq1 + estbPhibar21
    }
  }
    # If we use only the m1 outcomes
    # (we do not weight by phi)
  if (m1Only)
  {
    
    correctedY1Srq1 <- correctedY1Srp
    
    if (correcEstimWeights)
      correctedY1Srq1 <- correctedY1Srq1 + ZSr %*% estLinCoefq1
    
    varq1Est <- sum((1.0 - p1Sr) * correctedY1Srq1^2L)
  }
    # If we use only the m2 outcomes
    # (we do not weight by phi)
  else if (m2Only)
  {
    correctedY2Smrq1 <- (piSmr * p1barSmr)^-1L * Y2Smr
    
    if (correcEstimWeights)
      correctedY2Smrq1 <- correctedY2Smrq1 - ZSmr %*% estLinCoefq1
    
    varq1Est <- sum(p1Smr * p2Smr^-1L * correctedY2Smrq1^2L)
  }
    # If we use the m1 and m2 outcomes
    # We will use the estimations of the counterfactuals
  else
  {
     correctedPhiYSaq1 <- piSa^-1L * 
       (p1Sa^-1L * phiY1SaEst - p1barSa^-1L * phiY2SaEst)
     
     if (correcEstimWeights)
     {
       correctedPhiYSaq1 <- 
         correctedPhiYSaq1 + Z[maskSa, , drop = FALSE] %*% estLinCoefq1
     }
    
      weightsq1 <- numeric(na)
      weightsq1[maskm1Sa] <- 1.0 - p1Sr
      weightsq1[!maskm1Sa] <- p1Smr * p2Smr^-1L
      
      varq1Est <- 0.5 * sum(weightsq1 * correctedPhiYSaq1^2L)
  }
  
  
  # q2 variability (R2)
  # There is variability only if we consider m2. We do not need
  # to use counterfactuals estimators
  if (!m1Only)
  {
    correctedY2Smrq2 <- (piSmr * p1barSmr * p2Smr)^-1L * phiY2Smr
    if (correcEstimWeights)
    {
      estVPhibar22 <- -crossprod(ZSmr,
                          (piSmr * (1.0 - p1Smr) * p2Smr)^-1L *
                            (1.0 - p2Smr) * phiY2Smr)

      maskSm <- I & !maskSr
      
      estbPhibar22 <- 
        solve(Fisher_Information_Matrix(p2, Z, maskSm)) %*% estVPhibar22
      
      correctedY2Smrq2 <- correctedY2Smrq2 + ZSmr %*% estbPhibar22
    }
    
    varq2Est <- sum((1.0 - p2Smr) * correctedY2Smrq2^2L)
  }
  else
    varq2Est <- 0.0
  
  
  # Potential outcomes variability
  # We use the mean of the phi_k in case some of them are unknown
  varphiYEst <- 
    mean(phi^2L, na.rm = TRUE) * N * sd1^2L +
    2.0 * mean(phi * (1.0 - phi), na.rm = TRUE) * N * rho * sd1 * sd2 +
    mean((1.0 - phi)^2L, na.rm = TRUE) * N * sd2^2L
  
  
  varpEst + varq1Est + varq2Est + varphiYEst
}
```

```{r}
estim_appr_var_seq_m1 <- function(Yobs, modes, 
                                  I, pi_mat, 
                                  p1, sd1,
                                  correcEstimWeights = TRUE,
                                  Z = matrix(1.0, 
                                             nrow = length(Yobs), ncol = 1L),
                                  ...)
{
  estim_appr_var_seq_m1_m2(Yobs, modes, 
                           I, pi_mat, 
                           p1, p2 = NULL,
                           sd1,
                           sd2 = 0.0,
                           rho = 0.0,
                           phi = rep(1.0, length(Yobs)),
                           correcEstimWeights,
                           Z = Z,
                           m1Only = TRUE,
                           ...)
}
```

```{r}
estim_appr_var_seq_m2 <- function(Yobs, modes, 
                                  I, pi_mat, 
                                  p1, p2, sd2,
                                  correcEstimWeights = TRUE,
                                  Z = matrix(1.0, 
                                             nrow = length(Yobs), ncol = 1L),
                                  ...)
{
  estim_appr_var_seq_m1_m2(Yobs, modes, 
                           I, pi_mat, 
                           p1, p2,
                           sd1 = 0.0,
                           sd2,
                           rho = 0.0,
                           phi = numeric(length(Yobs)),
                           correcEstimWeights,
                           Z,
                           m2Only = TRUE,
                           ...)
}
```

```{r}
estim_appr_var_seq_a <- function(Yobs,
                                 responses,
                                 I, 
                                 pi_mat,
                                 pa,
                                 sd = NULL,
                                 correcEstimWeights = TRUE,
                                 Z = matrix(1.0, nrow = length(Yobs), ncol = 1L),
                                 ...)
{
  responses[responses == "r"] <- "m1"
  
  estim_appr_var_seq_m1(Yobs, responses, I, 
                        pi_mat, pa, sd, 
                        correcEstimWeights,
                        Z,
                        ...)
}
```


## Expansion estimators true variance

CONDITIONS INDEPENDANCE

```{r}
var_expansion_m1_m2 <- function(Y1exp, Y2exp, 
                                pi_mat, 
                                p1, p2, 
                                sd1 = 0.0, sd2 = 0.0, rho = 0.0, 
                                phi = rep(0.5, length(Y1exp)))
{
  pi <- diag(pi_mat)
  
  p1bar <- 1.0 - p1
  
  phibar <- 1.0 - phi
  
  covarPi <- pi2_to_covarInc(pi_mat)
  
  
  # Sampling variability (S)
  correctedY1p <- pi^-1L * (phi * Y1exp + phibar * Y2exp)
  varp <- as.numeric(t(correctedY1p) %*% covarPi %*% correctedY1p) +
    sum(pi^-1L * (1.0 - pi) * 
          (phi^2L * sd1^2L + phibar^2L * sd2^2L +
             2.0 * phi * phibar * rho * sd1 * sd2))
  
  # q1 variability (R1)
  # with the independence between p and q1
  # Variance of the term phik y1k / p1k - phikbar y2k / p1kbar
  varCorrectedDifference <- 
    (p1^-2L * phi^2L * sd1^2L + 
       p1bar^-2L * phibar^2L * sd2^2L -
       2.0 * (p1 * p1bar)^-1L * phi * phibar * rho * sd1 * sd2)
  varq1 <- 
    sum(pi^-1L * p1 * p1bar * 
    (varCorrectedDifference + 
       (p1^-1L * phi * Y1exp - p1bar^-1L * phibar^2L * Y2exp)^2L))
     
    
  # q2 variability (R2)
  # with the conditional independence between p and q1 ; and q1 and q2
  if (any(phibar > 0.0))
  {
    varPhibarY2 <- phibar^2L * (sd2^2L + Y2exp^2L) # Variance of each phikbar y_2k
    varq2 <- sum((pi * p1bar * p2)^-1L * (1.0 - p2) * varPhibarY2)
  }
  else
    varq2 <- 0.0
  
  # potential outcomes variability
  varPhiY <- 
    sum(phi^2L) * sd1^2L +
    2.0 * sum(phi * phibar) * rho * sd1 * sd2 +
    sum(phibar^2L) * sd2^2L
  
  varp + varq1 + varq2 + varPhiY
}
```

```{r}
var_expansion_m1 <- function(Y1exp, 
                             pi_mat, 
                             p1, 
                             sd1 = 0.0,
                             phi = rep(1.0, length(Y1exp)))
{
  var_expansion_m1_m2(Y1exp, Y2exp = numeric(length(Y1exp)), 
                      pi_mat,
                      p1, p2 = NULL, 
                      sd1, sd2 = 0.0, rho = 0.0, 
                      phi)
}
```


```{r}
var_expansion_m2 <- function(Y2exp, 
                             pi_mat, 
                             p1, p2, 
                             sd2 = 0.0, 
                             phi = rep(1.0, length(Y2exp)))
{
  var_expansion_m1_m2(Y1exp = numeric(length(Y2exp)), Y2exp, 
                      pi_mat, 
                      p1, p2, 
                      sd1 = 0.0, sd2, rho = 0.0, 
                      1.0 - phi)
}
```



```{r}
# var_expansion_m1 <- function(Y1exp,
#                              pi_mat,
#                              p1,
#                              sd1 = 0.0,
#                              phi = rep(1.0, length(Y1exp)))
# {
#   pi <- diag(pi_mat)
#   
# 
#   # Sampling variability (S)
#   covarPi <- pi2_to_covarInc(pi_mat)
#   correctedY1p <- pi^-1L * phi * Y1exp
#   varp <- as.numeric(t(correctedY1p) %*% covarPi %*% correctedY1p) +
#     sum(pi^-1L * (1.0 - pi) * phi^2L) * sd1^2L
# 
#   # q1 variability (R1)
#   # with the independence between p and q1
#   varq1 <- sum((pi * p1)^-1L * (1.0 - p1) * phi^2L * (sd1^2L + Y1exp^2L))
# 
#   # Y1 variability
#   varY1 <- sum(phi^2L) * sd1^2L
# 
#   varp + varq1 + varY1
# }
```

```{r}
# var_expansion_m2 <- function(Y2exp,
#                              pi_mat,
#                              p1, p2,
#                              sd2 = 0.0,
#                              phi = rep(1.0, length(Y2exp)))
# {
#   pi <- diag(pi_mat)
#   p1bar <- 1.0 - p1
# 
#   # Sampling variability (S)
#   covarPi <- pi2_to_covarInc(pi_mat)
#   correctedY2p <- pi^-1L * phi * Y2exp
#   varp <- as.numeric(t(correctedY2p) %*% covarPi %*% correctedY2p) +
#     sum(pi^-1L * (1.0 - pi) * phi^2L) * sd2^2L
# 
#   # q1 variability (R1)
#   varPhiY2 <- phi^2L * (sd2^2L + Y2exp^2L) # Variance of each phi_k y_2k
#   varq1 <- sum((pi * p1bar)^-1L * p1 * varPhiY2)
# 
#   # q2 variability (R2)
#   varq2 <- sum((pi * p1bar * p2)^-1L * (1.0 - p2) * varPhiY2)
# 
#   # Y2 variability
#   varY2 <- sum(phi^2L) * sd2^2L
# 
#   varp + varq1 + varq2 + varY2
# }
```

```{r}
var_expansion_a <- function(Yexp,
                            pi_mat,
                            pa,
                            sd = 0.0)
{
  var_expansion_m1(Yexp, pi_mat, pa, sd)
}
```


# Simulation
## Grid of parameters

```{r}
ratio_n_vec <- c(0.16, 0.25, 0.4)
ratio_n_ref <- min(ratio_n_vec)
n_vec <- as.integer(ratio_n_vec * N)
n_ref <- integer(ratio_n_ref * N)
sd1_vec <- c(1.0, 2.0, 5.0)
sd1_ref <- sd1_vec[1L]
ratio_sd_vec <- c(0.25, 0.5, 1.0, 2.0, 4.0)
rho_vec <- c(0.8, 0.9, 1.0)
rho_ref <- rho_vec[1L]

# Variation of the sample fraction n / N and sd1 with sd1 = sd2 
# and correlation rho between Y1 and Y2 fixed
paramVar_n <- 
  expand.grid(ratio_n = ratio_n_vec, 
              sd1 = sd1_vec, ratio_sd = 1.0, 
              rho = rho_ref)

# Variation of sd1 and sd2 with correlation rho between Y1 and Y2 fixed
paramVar_sd <- 
  expand.grid(ratio_n = ratio_n_ref, 
              sd1 = sd1_vec, ratio_sd = ratio_sd_vec,
              rho = rho_ref)

# Variation of the variance with sd1 = sd2 and rho = 1
paramVar_sdEq <- 
  expand.grid(ratio_n = ratio_n_ref, 
              sd1 = sd1_vec, ratio_sd = 1.0,
              rho = 1.0)

# Variation of the correlation between Y1 and Y2 (rho) with 
# sd1 = sd2 fixed
paramVar_rho <- 
  expand.grid(ratio_n = ratio_n_ref, 
              sd1 = sd1_ref, ratio_sd = 1.0,
              rho = rho_vec)

parameters <- rbind(paramVar_n, paramVar_sd, paramVar_sdEq, paramVar_rho)

parameters <- parameters %>% 
  distinct() %>% 
  mutate(n = as.integer(ratio_n * N), .after = "ratio_n") %>% 
  mutate(sd2 = sd1 * ratio_sd, .after = "ratio_sd")
```

```{r}
head(parameters)
glue("Size of the grid: {nrow(parameters)} iterations.")
```

## Simulation function

```{r}
simulation_tphi <- function(Z,
                            sampling = "SRS",
                            alpha1, alpha2,
                            alphaa,
                            beta, 
                            sd1 = 1.0, sd2 = sd1, 
                            rho = 0.8,
                            phi = rep(0.5, N), 
                            M = 10000L,
                            n = ceiling(N / 10L),
                            seed = 123L,
                            nCores = detectCores() - 1L,
                            calcVariance = TRUE)
{
  set.seed(seed)
  
  N <- nrow(Z)
  q <- ncol(Z)
  
  expit <- function(x) 1.0 / (1.0 + exp(-x))

  p1 <- expit(Z %*% alpha1) %>% as.numeric()
  p2 <- expit(Z %*% alpha2) %>% as.numeric()
  pa <- expit(Z %*% alphaa) %>% as.numeric()
  
  Yexp <- Z %*% beta

  if (sampling == "SRS")
  {
    pi <- rep(n / N, N)
    pi_mat <- piMat_SRS(n, N)
  }
  
  
  # Variance matrix of the potential outcomes for one unit, for the vector
  # (y_1k, y_2k)^T
  varYUnit_mat <- matrix(c(sd1^2L, rho * sd1 * sd2, rho * sd1 * sd2, sd2^2L),
                         nrow = 2L, ncol = 2L)
  rownames(varYUnit_mat) <- colnames(varYUnit_mat) <- c("y1k", "y2k")

  monoSim <- function(...)
  {
    if (sampling == "SRS")
    {
      selectedSample <- sample(seq_len(N), size = n, replace = FALSE)
      
      I <- logical(N)
      I[selectedSample] <- TRUE
      rm(selectedSample)
    }
    
    
    dataModes <- gen_choice_bimode(I, p1, p2, Z)
    modes <- dataModes$mode
    
    maskSr <- modes == "m1"
    n1 <- sum(maskSr)
    maskSmr <- modes == "m2"
    n2 <- sum(maskSmr)
    
    ## trueProbsSelect <- dataModes$probSelect
    
    rm(dataModes)
    
    ## trueWeights <- (pi * trueProbsSelect)^-1L
  
    # Estimation of mode selection probabilities p1k and p2k 
    # (logistic regression)
    estimProbsData <-
      MMsampling::estim_response_prob_sequential(I, Z,
                                                 modes,
                                                 c("m1", "m2"),
                                                 chosenOnly = FALSE)
    
    # Generating values for Y_int and Y_tel
      # Generation for each unit of independent couples (e_1k, e_2k) 
      # with centered multivariate normal distribution and as variance
      # the variance of the couple (y_1k, y_2k) 
    YpotOutRes_mat <- 
      mvtnorm::rmvnorm(n = N, 
                       mean = numeric(2L), sigma = varYUnit_mat,
                       checkSymmetry = FALSE)
    
      # Changing the expectations to have the potential outcomes :
      # y_1k = E[y_k | Z] + e_1k and y_1k = E[y_k | Z] + e_2k
    Y1 <- Yexp + YpotOutRes_mat[, 1L]
    names(Y1) <- paste0("y1", seq_len(N))
    
    Y2 <- Yexp + YpotOutRes_mat[, 2L]
    names(Y2) <- paste0("y2", seq_len(N))
    
    rm(YpotOutRes_mat)

    
    # Creating the observed outcome vector
    Yobs <- rep(NA_real_, N)
    Yobs[modes == "m1"] <- Y1[modes == "m1"]
    Yobs[modes == "m2"] <- Y2[modes == "m2"]
    names(Yobs) <- paste0("yobs", seq_len(N))
    
    # Estimations with Y1 (total of the y_1k)
     # With true probabilities
    tot1TW <- estim_tot_m1(Yobs, modes, pi, p1)
    

    if (calcVariance)
    {
      # The variance of Y1 is assumed known. The true probabilities are
      # used in the calculation.
      apprVar1TW <-
        estim_appr_var_seq_m1(Yobs,
                              modes,
                              I,
                              pi_mat,
                              p1,
                              sd1,
                              correcEstimWeights = FALSE)
    }
    else
      apprVar1TW <- NA_real_
    
      # With estimated probabilities
    estimp1 <- estimProbsData$conditional[, "m1"]
    tot1EW <- estim_tot_m1(Yobs, modes, pi, estimp1)
    

    if (calcVariance)
    {
      # The variance of Y1 is assumed known.
      apprVar1EW <-
        estim_appr_var_seq_m1(Yobs,
                              modes,
                              I,
                              pi_mat,
                              estimp1,
                              sd1,
                              correcEstimWeights = TRUE,
                              Z)
    }
    else
      apprVar1EW <- NA_real_
    
    # Estimations with Y2 (total of the y_2k)
      # With true probabilities
    tot2TW <- estim_tot_m2(Yobs, modes, pi, p1, p2)
    
    
    if (calcVariance)
    {
      # The variance of Y2 is assumed known. The true probabilities are
      # used in the calculation.
      apprVar2TW <-
        estim_appr_var_seq_m2(Yobs,
                              modes,
                              I,
                              pi_mat,
                              p1,
                              p2,
                              sd2,
                              correcEstimWeights = FALSE)
    }
    else
      apprVar2TW <- NA_real_
    
      # With estimated probabilities
    estimp2 <-  estimProbsData$conditional[, "m2"]
    tot2EW <- estim_tot_m2(Yobs, modes, pi, estimp1, estimp2)
    
    if (calcVariance)
    {
      # The variance of Y1 is assumed known.
      apprVar2EW <-
        estim_appr_var_seq_m2(Yobs,
                              modes,
                              I,
                              pi_mat,
                              estimp1,
                              estimp2,
                              sd2,
                              correcEstimWeights = TRUE,
                              Z)
    }
    else
      apprVar2EW <- NA_real_
    

    # Estimations with Y1 and Y2 assumezd equal (total of the y_k)
    # 
    # We consider two cases here :
    # 1) when p_a follow a logistic model and we have Y1 = Y2 
    #  (considered when sd1 = sd2 and rho = 1)
    # 2) when p_1 and p_2 follow a logistic model like before 
    #  and Y1 != Y2 in general
   
    # Case 1
    if (sd1 == sd2 && rho == 1.0)
    {
      Ra <- runif(n = N) <= pa
      # "r" if unit k would agree to answer by any mode
      # if asked
      respStat <- if_else(Ra, "r", "nr") 
    
      maskSa <- I & Ra
      # "r" if unit k answered by any mode
      answers <- if_else(maskSa, "r", "nr")
    
      YobsEq <- rep(NA_real_, N)
      YobsEq[maskSa] <- Y1[maskSa]
    }
    # Case 2
    else
    {
      answers <- if_else(modes %in% c("m1", "m2"), "r", "nr")
      YobsEq <- Yobs
    }
    
    # With true probabilities
    totaTW <- estim_tot_a(YobsEq, answers, pi, pa)
    
    if (calcVariance)
    {
      # Unbiased estimation of the variance of the total estimator.
      # The variance of Y is assumed known. The true probabilities are
      # used in the calculation.
      apprVaraTW <-
        estim_appr_var_seq_a(YobsEq,
                             answers,
                             I,
                             pi_mat,
                             pa,
                             sd1,
                             correcEstimWeights = FALSE)
    }
    else
      apprVaraTW <- NA_real_

    # With estimated probabilities
    dataEstimpa <- 
      cbind(response = as.integer(Ra), Z) %>% 
      as.data.frame()
    model <- glm(response ~ Z, data = dataEstimpa,
                 family = binomial, subset = I)

    estimpa <- predict(model, newdata = as.data.frame(Z), type = "response")
    
    rm(dataEstimpa, model)
  
    totaEW <- estim_tot_a(YobsEq, answers, pi, estimpa)
    
    if (calcVariance)
    {
      # Unbiased estimation of the variance of the total estimator.
      # The variance of Y is assumed known. The true probabilities are
      # used in the calculation.
      apprVaraEW <-
        estim_appr_var_seq_a(YobsEq,
                             answers,
                             I,
                             pi_mat,
                             estimpa,
                             sd1,
                             correcEstimWeights = TRUE,
                             Z)
    }
    else
      apprVaraEW <- NA_real_
    
    # Estimations with Y1 and Y2 weighted by phi
      # With true probabilities
    totPhiTW <- estim_tot_m1_m2(Yobs, modes, pi, p1, p2, phi)
    
    if (calcVariance)
    {
      apprVarPhiTW <- 
        estim_appr_var_seq_m1_m2(Yobs,
                                 modes,
                                 I,
                                 pi_mat,
                                 p1,
                                 p2,
                                 sd1,
                                 sd2,
                                 rho,
                                 phi,
                                 correcEstimWeights = FALSE)
    }
    else
      apprVarPhiTW <- NA_real_
    
      # With estimated probabilities
    totPhiEW <- estim_tot_m1_m2(Yobs, modes, pi, estimp1, estimp2, phi)
    
    
    if (calcVariance)
    {
      apprVarPhiEW <- 
        estim_appr_var_seq_m1_m2(Yobs,
                                 modes,
                                 I,
                                 pi_mat,
                                 estimp1,
                                 estimp2,
                                 sd1,
                                 sd2,
                                 rho,
                                 phi,
                                 correcEstimWeights = TRUE,
                                 Z)
    }
    else
      apprVarPhiEW <- NA_real_
    

    tibble(estimator = c("tot1TW", "tot1EW", 
                         "tot2TW", "tot2EW", 
                         "totaTW", "totaEW",
                         "totphiTW", "totphiEW"),
           sample = rep(c("Sr", "Smr", "Sa", "Sa"), each = 2L),
           estimand = rep(c("t_1", "t_2", "t_=", "t_phi"), each = 2L),
           estimation = c(tot1TW, tot1EW, 
                          tot2TW, tot2EW, 
                          totaTW, totaEW,
                          totPhiTW, totPhiEW),
           apprVar = c(apprVar1TW, apprVar1EW, 
                       apprVar2TW, apprVar2EW,
                       apprVaraTW, apprVaraEW,
                       apprVarPhiTW, apprVarPhiEW)) %>% 
      mutate(weights = rep_len(c("true", "estimated"), length.out = n()),
             .after = "sample")
  }
  # res <- lapply(seq_len(M), FUN = monoSim)
  
  res <- mclapply(seq_len(M), FUN = monoSim, mc.cores = nCores)
  
  res <- do.call("rbind", res)
  
  trueVar1TW <- var_expansion_m1(Yexp, pi_mat, p1, sd1)
  
  trueVar2TW <- var_expansion_m2(Yexp, pi_mat, p1, p2, sd2)
  
  if (sd1 == sd2)
    trueVaraTW <- var_expansion_a(Yexp, pi_mat, pa, sd1)
  else
    trueVaraTW <- NaN
  
  trueVarPhi <- var_expansion_m1_m2(Yexp, Yexp, 
                                    pi_mat, 
                                    p1, p2, 
                                    sd1, sd2, rho, phi)
  
  trueVar <- rep.int(c(trueVar1TW, NA_real_, 
                       trueVar2TW, NA_real_,
                       trueVaraTW, NA_real_,
                       trueVarPhi, NA_real_),
                     times = M)
  
  res <- res %>% 
    mutate(expEstimand = sum(Yexp), .after = "estimand") %>% 
    mutate(trueVar = trueVar, .after = "apprVar")
  
  res
}
```

## Simulation

```{r}
Msim <- 1000L
```

The different lines of the grid have the same seed. It is useful to run in different orders the evaluations and because the results from different parameters are never mixed there is no independency issue.


If the number of parallel cores changes, the results might be different.

```{r}
resSimulation <- NULL
set.seed(200L)

pb <- progress::progress_bar$new(format = "[:bar] :percent eta: :eta",
                                 total = nrow(parameters),
                                 clear = TRUE)

pb$tick(0L)

phi = rep(0.5, N)

## alphaa à changer
for (k in seq_len(nrow(parameters)))
{
  simFun <- function(calcVariance = TRUE)
  {
    simulation_tphi(M = Msim,
                    Z = Z,
                    sampling = "SRS",
                    alpha1 = alpha1,
                    alpha2 = alpha2,
                    alphaa = alpha1,
                    beta = beta,
                    phi = phi,
                    sd1 = parameters[k, "sd1"],
                    sd2 = parameters[k, "sd2"],
                    n = parameters[k, "n"],
                    rho = parameters[k, "rho"],
                    seed = NULL,
                    nCores = 30L,
                    calcVariance = calcVariance)
  }
  
  resTempWithVar <- simFun(calcVariance = TRUE) %>% mutate(subset = 1L)
  resTempWithoutVar <- simFun(calcVariance = FALSE) %>% mutate(subset = 2L)
  
  resSimulation <-
    cbind(parameters[k, ], 
          rbind(resTempWithVar, resTempWithoutVar), 
          row.names = NULL) %>%
    rbind(resSimulation)

  pb$tick()
}

rm(pb, resTempWithVar, resTempWithoutVar)

resSimulation <-
  resSimulation %>%
  mutate(phi = 0.5) %>% 
  arrange(n, sd1, sd2, rho)
```

```{r}
rm(Msim)
```

## Properties of the estimators

The first subset will be used for the estimations of the expectation of the totals and the approximate variances via Monte Carlo. The second will be used for the estimation of the variance of the totals via Monte Carlo.

### Approximate unbiasedness of the total estimators

```{r}
resSimulation %>% 
  filter(subset == 1L) %>% 
  group_by(estimand, sample, weights, n, sd1, sd2, rho) %>% 
  summarize(M = n(),
            true_expectation = first(expEstimand),
            MC_expectation = mean(estimation, na.rm = TRUE)) %>% 
  mutate(ratio_MC_true = MC_expectation / true_expectation) %>% 
  ungroup()
```


Here we show average approximate variance and variance of different estimators, with no measure effect.

### Quality of the approximate variance estimators

```{r}
temp <- resSimulation %>% 
  mutate(estimation = if_else(subset == 1L, estimation, NA_real_)) %>% 
  group_by(n, sd1, sd2, rho, estimand, sample, weights) %>% 
  summarize(M = n() / 2L,
            MC_AV = mean(apprVar, na.rm = TRUE),
            MC_var = var(estimation, na.rm = TRUE),
            true_var = first(trueVar)) %>% 
  mutate(MC_AV_by_var = MC_AV / MC_var)

temp
```
```{r}
temp %>% 
  ungroup(estimand, sample, weights) %>% 
  slice_min(MC_AV)
```

## Convergence in law

```{r}
temp <- resSimulation %>% 
  filter(ratio_delta == 0.0)
```

Note : having sd1 = sd2 ensure to have only independent estimators.

```{r}
resSimulation %>% 
  filter(ratio_delta == 0.0,
         sd1 == sd2,
         estimand %in% c("phi1", "phi2"), 
         weights == "estimated") %>% 
  group_by(estimand, n, sd1, rho) %>% 
  summarise(M = n(), shapiro.pval = shapiro.test(estimation)$p.value)


for (sigm in sigmavec)
  {
    for (nb in nvec)
    {
      for (cor in rhovec)
      {
        estimators1 <- resSimulation %>% 
          filter(delta == 0.0,
                 sd1 == sigm,
                 sd2 == sigm,
                 n == nb,
                 estimand == "phi1", 
                 weights == "estimated") %>% 
          select(estimation) %>% 
          pull()
        
        
      
        data2 <- resSimulation %>% 
          filter(delta == 0.0, 
                 sd1 == sigm,
                 sd2 == sigm,
                 n == nb,
                 estimand == "phi2", 
                 weights == "estimated") %>% 
          select(estimation)
      }
    }
  }
```

```{r}
temp <- resultsGaussian %>% 
  filter(Y2Law == "gaussian", Y1Law == "gaussian", 
         sampling == "SRS", 
         MBtype == "constant", signAge == "plus", 
         phi == "eq", trueEstimator) %>% 
  select(experiment, n1, n2, estPhiYintEstMP, expYint, avgEstWeightsInt,
         estPhiYtelEstMP, estPhiBarYtelEstMP, expYtel, normEstPhiBiasDiffHT) %>% 
  group_by(experiment) %>% 
  slice_head(n = 1L) %>% 
  ungroup()
```

### $\hat{t}_{pq\phi1}$

With $\phi \equiv \frac{1}{2}$

```{r}
estimatorsPhi1 <- temp$estPhiYintEstMP

empMean1 <- mean(estimatorsPhi1)

expMean1 <- as.numeric(0.5 * temp[1L, "expYint"])

glue("empirical mean: {empMean1} (expected: {expMean1})")
```

Modifier, utilisation d'un écart-type estimé sur toute la population... :

```{r}

empSD1 <- sd(estimatorsPhi1)

temp %>% 
ggplot() + 
  geom_density(aes(x = estPhiYintEstMP)) + 
  geom_vline(aes(xintercept = empMean1, colour = "constant"), show.legend = TRUE) +
  ggtitle("HT-phi1 estimator with estimated probabilities") +
  xlab("Estimator") +
  scale_color_manual(name = "bias", values = c(constant = "red"))

ks.test(x = (estimatorsPhi1 - empMean1) / empSD1, y = "pnorm")
```

### $\hat{t}_{pq\bar{\phi}2}$

With $\phi \equiv \frac{1}{2}$

```{r}
estimatorsPhi2 <- temp$estPhiYtelEstMP

empMean2 <- mean(estimatorsPhi2)

expMean2 <- 0.5 * as.numeric(temp[1L, "expYtel"])

glue("empirical mean: {empMean2} (expected: {expMean2})")
```

```{r}
empSD2 <- sd(estimatorsPhi2)

temp %>% 
ggplot() + 
  geom_density(aes(x = estimatorsPhi2)) + 
  geom_vline(aes(xintercept = empMean2, colour = "constant"), show.legend = TRUE) +
  ggtitle("HT-phi1 estimator with estimated probabilities") +
  xlab("Estimator") +
  scale_color_manual(name = "bias", values = c(constant = "red"))

ks.test(x = (estimatorsPhi2 - empMean2) / empSD2, y = "pnorm")
```


