---
title: "Estimation of totals (without measure effect)"
format:
  html:
    toc: true
    html-math-method: katex
    css: styles.css
---

```{r}
#| message: false
#| warning: false
# Installation of the library `pacman` if not
# already installed
if (!"pacman" %in% rownames(installed.packages()))
  install.packages("pacman")
```

```{r}
#| message: false
#| warning: false
pacman::p_load(dplyr)
options(dplyr.summarise.inform = FALSE)
pacman::p_load(tibble)
pacman::p_load(tidyr)
pacman::p_load(glue)
pacman::p_load(parallel)
pacman::p_load(ggplot2)
theme_set(theme_light())
pacman::p_load(progress)
## pacman::p_load(marginaleffects)
pacman::p_install(mvtnorm, force = FALSE)
pacman::p_install(MatchIt, force = FALSE)
```

```{r}
#| message: false
#| warning: false
pacman::p_install(devtools, force = FALSE)
devtools::load_all()
```

# Population generation

```{r}
source("simulation_functions.R")
```

```{r}
RNGkind(kind = "L'Ecuyer-CMRG")
set.seed(145L)
```

```{r}
N <- 10000L
```

## Covariates

Creating independent covariates, using the 2022 French age pyramid ([INSEE](https://www.insee.fr/fr/statistiques/6688661?sommaire=6686521))

```{r}
gen_covariates <- function(N)
{
  pyramid <- read.csv("./population_pyramid_FR_2022.csv",
                      header = TRUE, dec = ".") %>% 
    mutate(sex = if_else(sex == "Man", 1L, 0L))
  
  groupUnits <- sample(seq_len(nrow(pyramid)), size = N, 
                       replace = TRUE, prob = pyramid$percentage)
  
  pyramid[groupUnits, c("age", "sex")] %>% 
    mutate(const = 1.0, .before = 1L) %>% 
    remove_rownames()
}


Z <- gen_covariates(N)

sex <- factor(Z$sex)
levels(sex) <- c("Woman", "Man")
```

```{r}
cat("About the age:\n")
summary(Z$age)
cat("About the sex:\n")
table(sex)
```

```{r}
data <- Z[, c("sex", "age")]
data$sex <- sex
ggplot(data) + 
  geom_density(aes(x = age, colour = sex)) +
  ggtitle("Age density conditionally to the sex")

data %>% 
  group_by(sex) %>% 
  summarise(meanAge = mean(age))
rm(data)
```

```{r}
Z <- as.matrix(Z)
```

## Potential outcomes

Creating a regression vector for both mode : $\beta$ is defined to have in average a potential outcome expectation for each mode equal to one.

```{r}
beta <- c(0.0, -0.1, 4.0)
beta[1L] <- 1.0 - mean(Z %*% beta)
print(beta)
```

$Y_{1}$ and $Y_{2}$ expectations depend on `Z`:

```{r}
data.frame(Yexp = Z %*% beta) %>% 
  ggplot() + 
  geom_density(aes(x = Yexp)) +
  ggtitle("Distribution of the potential outcomes expected values") +
  xlab("z_k^T beta")
```
Average of the expectations of the potential outcomes on $U$:

```{r}
mean(Z %*% beta)
```

## Mode selection mechanisms

### Generation of the probabilities (logistic models)

We simulate a mode selection MAR (Missing At Random) under a logistic model, with $Z$ as variable:

```{r}
alpha1 <- c(0.55, -0.015, -0.4)

alpha2 <- c(1.0, -0.01, -0.3)
```

```{r}
gen_selection_probabilities <- function(Z, alpha)
{
  expit <- function(x) 1.0 / (1.0 + exp(-x))

  expit(Z %*% alpha) %>%
    as.vector()
}

p1 <- gen_selection_probabilities(Z, alpha1)
p2 <- gen_selection_probabilities(Z, alpha2)
```


Here are some details about the $p_{1k}$ and $p_{2k}$:

```{r}
glue("m1 probabilities:\n")
summary(p1) %>% print()
glue("m2 probabilities:\n")
summary(p2) %>% print()
```

```{r}
data.frame(mode = factor(rep(c("m1", "m2"), each = N), 
                         levels = c("m1", "m2")), 
           prob = c(p1, p2)) %>% 
  ggplot() + 
  geom_density(aes(x = prob, color = mode)) +
  ggtitle("Distribution of p1 and p2 (sequential logistic model)") +
  xlab("Mode selection probability")
```

```{r}
p1[sex == "Man"] %>% summary()
p1[sex == "Woman"] %>% summary()
```

Probability to answer by $m_2$ under to the sequential protocol (i.e. do not answer by $m_1$ and agree to answer by $m_2$):
```{r}
pRep2 <- (1.0 - p1) * p2
summary(pRep2)
rm(pRep2)
```
Probability to answer under the sequential protocol
```{r}
pRep <- p1 + (1.0 - p1) * p2
summary(pRep)
data.frame(pRep = pRep) %>% 
  ggplot() + 
  geom_density(aes(pRep)) +
  ggtitle("Distribution of the probability to answer (sequential logistic)") +
  xlab("Probability to answer if asked (p_1k + [1 - p_1k]p_2k)")
```
### Size of the sets

About $S_{r\bullet}$:

```{r}
# Generates the second order inclusion probabilities matrix of a
# Simple Random Sampling (SRS) design
piMat_SRS <- function(n, N)
{
  pi_mat <- matrix(n * (n - 1L) / (N * (N - 1L)), nrow = N, ncol = N)
  diag(pi_mat) <- n / N

  pi_mat
}
```


```{r}
f <- 1.6 / 10.0
n <- f * N
expSizeSr <- f * sum(p1)

pi <- rep(f, N)
pi_mat <- piMat_SRS(n, N)
pCov <- pi2_to_covarInc(pi_mat)
varSizeSr <- f * sum(p1 * (1.0 - p1)) + 
  t(p1) %*% pCov %*% p1 %>% 
  as.numeric()

glue("Expected size of Sr : {expSizeSr}")
glue("Variance of the size of Sr : {varSizeSr}")
```

About $S_{mr}$ (case of SRS with $f = \frac{1}{10}$):

```{r}
expSizeSmr <- f * sum(pRep2)

varSizeSmr <- f * sum(pRep2 * (1.0 - p2)) + 
  f * sum(pRep2 * (1.0 - p1)) +
  t(pRep2) %*% pCov %*% pRep2 %>% 
  as.numeric()

glue("Expected size of Smr : {expSizeSmr}")
glue("Variance of the size of Smr : {varSizeSmr}")
```

About $S_a$ (case of SRS with $f = \frac{1}{10}$):

```{r}
expSizeSa <- expSizeSr + expSizeSmr

varSizeSa <- f * sum(pRep2 * (1.0 - p2)) + 
  f * sum(p1 * (1.0 - p1) * (1.0 - p2)) +
  t(p1 + pRep2) %*% pCov %*% (p1 + pRep2) %>% 
  as.numeric()

glue("Expected size of Sa : {expSizeSa}")
glue("Variance of the size of Sa : {varSizeSa}")

rm(expSizeSr, varSizeSr, 
   expSizeSmr, varSizeSmr, 
   expSizeSa, varSizeSa)
```

## Global answer mechanism

Objective: finding the vector $\alpha_a$ that, for a global logistic model, gives the probabilities $p_{ak}$ that are the closest to $p_{1k} + (1-p_{1k})p_{2k}$ with a sequential logistic mechanism.
```{r}
expit <- function(x) 1.0 / (1.0 + exp(-x))
logit <- function(p) log(p / (1.0 - p))
```

```{r}
score_logit_a <- function(alphaa, Z, p1, p2)
{
  paPrime <- p1 + (1.0 - p1) * p2
  pa <- expit(Z %*% alphaa)
  pabar <- 1.0 - pa
  
  2.0 * t(Z) %*% (pa * pabar * (pa - paPrime))
}

hessian_logit_a <- function(alphaa, Z, p1, p2)
{
  paPrime <- p1 + (1.0 - p1) * p2
  pa <- expit(Z %*% alphaa)
  pabar <- 1.0 - pa
  
  2.0 * diag(pa * pabar^2L * (pa - paPrime)) * t(Z) %*% Z + 
    2.0 * diag(pa^2L * pabar * (pa - paPrime)) * t(Z) %*% Z + 
    2.0 * diag(pa^2L * pabar^2L) * t(Z) %*% Z
}

# Initial vector
alphaa <- c(+1.3, -0.01, -0.35)

it <- 0L

while (it < 50L)
{
  it <- it + 1L
  alphaa <- alphaa - solve(hessian_logit_a(alphaa, Z, p1, p2)) %*% score_logit_a(alphaa, Z, p1, p2)
}

rm(it)

alphaa <- as.vector(alphaa)
pa <- gen_selection_probabilities(Z, alphaa)
```

```{r}
data.frame(pa = pa) %>% 
  ggplot() + 
  geom_density(aes(pa)) +
  ggtitle("Distribution of pa (global logistic)") +
  xlab("Probability to answer if asked (p_ak)")
```
```{r}
data.frame(pa = c(pRep, pa),
           mechanism = factor(rep(c("sequential", "global"), each = N),
                              levels = c("sequential", "global"))) %>% 
  ggplot() + 
  geom_density(aes(pa, color = mechanism)) +
  ggtitle("Distribution of the probability to answer depending on the mechanism") +
  xlab("Probability to answer if asked by any mode (pa)")

rm(pRep)
```

RMSE between mechanisms for the probability to answer
```{r}
glue("RMSE: {sqrt(mean(((pa - (p1 + (1.0 - p1) * p2))^2L)))}")
glue("MAE: {mean(abs(pa - (p1 + (1.0 - p1) * p2)))}")
```

Statistics on the Mean Absolute Error (MAE):
```{r}
summary(abs(pa - (p1 + (1.0 - p1) * p2)))
```

Statistics on the Absolute Error rate:

```{r}
summary(abs(pa - (p1 + (1.0 - p1) * p2)) / (p1 + (1.0 - p1) * p2))
ecdf(abs(pa - (p1 + (1.0 - p1) * p2)) /
       (p1 + (1.0 - p1) * p2))(c(0.05, 0.08, 0.1, 0.2))
```

Main population for whom the global logistic model is incorrect (absolute error ratio superior to 0.1):

```{r}
Z[abs(pa - (p1 + (1.0 - p1) * p2)) / (p1 + (1.0 - p1) * p2) > 0.1,
  c("age", "sex")] %>% summary()
```


```{r}
expSizeSa <- f * sum(pa)

varSizeSa <- f * sum(pa * (1.0 - pa)) + 
  t(pa) %*% pCov %*% pa %>% 
  as.numeric()

glue("Expected size of Sa : {expSizeSa}")
glue("Variance of the size of Sa : {varSizeSa}")

rm(expSizeSa, varSizeSa)
rm(f, pCov, pi, pi_mat)
```

# Total estimation
## Approximate variance estimators

```{r}
#' Estimation of the variance of t_ephiy and the approximate variance 
#' of t_pqphiy
#' 
#' 
#' HOMOSCEDASTICITY, INDEPENDENCE
#' @param Yobs vector of the observed outcomes. For the non-respondents
#' the value is not considered and therefore can be equal to NA
#' (numeric vector of size N the size of the population).
#' @param modes vector of the selected mode of each unit.
#' The first mode of the protocol is defined as "m1" and the second as "m2"
#' (character vector or factor of size N).
#' @param pi_mat matrix containing the second order inclusion probabilities
#' pi_kl. The values must be known on Sr^2 (except if `m2Only` = TRUE) and
#' Smr^2 (except if `m1Only` = TRUE) and can be equal to NA otherwise
#' (symmetric numeric matrix of order N).
#' @param p1 vector containing the true or estimated probabilities p_1k.
#' Can be equal to NA for the non-respondents or the units that didn't answer 
#' by m1 is `m1Only` = TRUE (numeric vector of size N).
#' @param p2 vector containing the true or estimated probabilities p_2k.
#' Used if `m1Only` = FALSE. Can be equal to NA for the non-respondents 
#' or the units that didn't answer by m2 is `m2Only` = TRUE (numeric vector of size N).
#' @param sd1 true or estimated value (from a consistent estimator if possible)
#' of the standard deviation of the m1 potential outcomes.
#' Used when `m2Only` = FALSE and `phi` != 0 (positive scalar).
#' @param sd2 true or estimated value (from a consistent estimator if possible)
#' of the standard deviation of the m1 potential outcomes. 
#' Used when `m1Only` = FALSE and `phi` != 1 (positive scalar).
#' @param cov12 the true or estimated covariance between the m1 and m2
#' potential outcomes (from a consistent estimator if possible).
#' Default to `sd1` * `sd2` (i.e. Y1 and Y2 are conditionally col linear)
#' (scalar).
#' @param phi vector containing weights for the total. Must be known on the
#' set of respondents (numeric vector of [0,1]^N).
#' @param eqPotOut TRUE if we consider that y_1k = y_2k on the population
#' (boolean)
#' @param correcEW1 TRUE if we must apply a correction due to the
#' use of estimation of `p1` (boolean).
#' @param correcEW2 TRUE if we must apply a correction due to the
#' use of estimation of `p2` (boolean).
#' @param I vector containing the indicators I_k equal to TRUE if unit k
#' has been selected. Used only if `correcEW1` or `correcEW2` is true
#' (logical vector of size N).
#' @param Z design matrix. Used only when `correcEW1` or `correcEW1` are TRUE
#' (numeric matrix with N rows and q columns).
#' @param m1Only TRUE if we estimate the variance (resp. approximate variance)
#' of t_{e1} (resp. t_{pq1}) and only with the m1 respondents (boolean).
#' @param m2Only TRUE if we estimate the variance (resp. approximate variance)
#' of t_{e2} (resp. t_{pq2}) and only with the m2 respondents (boolean).
#' @param weightSrEstVp weight considering the impact of the sampling design
#' variance estimator made of the m1 respondents vs the m2 respondents. Used
#' only when `m1Only` and `m2Only` are FALSE (scalar in [0,1]).
#' @param weightSrEstVq1 similar to `weightSrEstVp` but for the m1 selection
#' variability (scalar in [0,1]).
#' @param ... arguments for the function `MatchIt::matchit`.
estim_appr_var_seq_m1_m2 <- function(Yobs,
                                     modes,
                                     pi_mat,
                                     p1,
                                     p2,
                                     sd1 = 0.0,
                                     sd2 = 0.0,
                                     cov12 = sd1 * sd2,
                                     phi = rep(0.5, length(Yobs)),
                                     eqPotOut = FALSE,
                                     correcEW1 = TRUE,
                                     correcEW2 = TRUE,
                                     I,
                                     Z = matrix(1.0, nrow = length(Yobs), ncol = 1L),
                                     m1Only = FALSE,
                                     m2Only = FALSE,
                                     weightSrEstVp = 0.5,
                                     weightSrEstVq1 = weightSrEstVp,
                                     ...)
{
  
  pi <- diag(pi_mat)
  N <- length(pi)
  
  maskSr <- modes == "m1"
  maskSmr <- modes == "m2"
  maskSa <- maskSr | maskSmr
  na <- sum(maskSa) # Number of respondents
  maskm1Sa <- modes[maskSa] == "m1" # mask of the m1 respondents within Sa
  
  
  m1Only <- isTRUE(m1Only)
  m2Only <- !m1Only && isTRUE(m2Only)
  
  # In the case we focus on the estimator t_{e1} or t_{pq1} and 
  # we do not want to use the estimated potential outcomes of y_1k on
  # the set of the m2 respondents (i.e. use only the date (z_k, y_1k) in Sr).
  # The weights vector phi is not considered in fine but set to 1 to use 
  # the equations that take phi into account.
  if (m1Only)
  {
    phi <- rep(1.0, N)
    phibar <- numeric(N)
  }
    
  # Same for t_{e2} or t_{pq2}, setting phi to 0
  else if (m2Only)
  {
    phi <- numeric(N)
    phibar <- rep(1.0, N)
  }
  else
  {
    phibar <- 1.0 - phi
    
    eqPotOut <- isTRUE(eqPotOut)
    
    if (eqPotOut)
    {
      sd2 <- sd1
      cov12 <- sd1^2L
    }
  }
    
  
  piSa <- pi[maskSa]
  p1Sa <- p1[maskSa]
  p1barSa <- 1.0 - p1Sa
  
  # If the data of the m1 respondents will be used
  if (!m2Only)
  {
    phiSr <- phi[maskSr]
    Y1Sr <- Yobs[maskSr]
    phiY1Sr <- phiSr * Y1Sr
    
    piSr <- pi[maskSr]
    p1Sr <- p1[maskSr]
    
    piSr_mat <- pi_mat[maskSr, maskSr, drop = FALSE]
    covarpSr <- pi2_to_covarInc(piSr_mat)
  }
  else
    sd1 <- 0.0

    
  # If the data of the m2 respondents will be used
  if (!m1Only)
  {
    phiSmr <- phi[maskSmr]
    Y2Smr <- Yobs[maskSmr]
    phibarY2Smr <- phibar[maskSmr] * Y2Smr
    
    piSmr <- pi[maskSmr]
    p1Smr <- p1[maskSmr]
    p1barSmr <- 1.0 - p1Smr
    p2Smr <- p2[maskSmr]
    p2Sa <- p2[maskSa]
    
    piSmr_mat <- pi_mat[maskSmr, maskSmr, drop = FALSE]
    covarpSmr <- pi2_to_covarInc(piSmr_mat)
  }
  else
  {
    sd2 <- 0.0
    p2 <- NULL # The m2 selection probabilities will not be used
  }
  
  # Sampling design variability (p, S)
  # There is no correction needed for probabilities estimation
    # If we use only the m1 outcomes
    # (we do not weight by phi)
  if (m1Only)
  {
    correctedY1Srp <- (piSr * p1Sr)^-1L * Y1Sr
    varpEst <-
      t(correctedY1Srp) %*%
      (covarpSr / piSr_mat) %*%
      correctedY1Srp %>%
      as.numeric()
    varpEst <- varpEst +
      sum((1.0 - piSr) * piSr^-2L * p1Sr^-1L * (1.0 - p1Sr^-1L) *
            Y1Sr^2L)
    
    # Second order inclusion and covariance matrices are
    # directly deleted due to their important size (#Sr^2).
    # Due to the conditional independence within the selection mechanisms
    # they are not used after.
    rm(piSr_mat, covarpSr)
  }
    # If we use only the m2 outcomes
    # (we do not weight by 1 - phi)
  else if (m2Only)
  {
    Y2Smr <- Yobs[maskSmr]
    correctedY2Smrp <- (piSmr * p1barSmr * p2Smr)^-1L * Y2Smr
    varpEst <-
      t(correctedY2Smrp) %*%
      (covarpSmr / piSmr_mat) %*%
      correctedY2Smrp %>%
      as.numeric()
    varpEst <- varpEst +
      sum((1.0 - piSmr) * piSmr^-2L * (p1barSmr * p2Smr)^-1L *
            (1.0 - (p1barSmr * p2Smr)^-1L) * Y2Smr^2L)
    
    # Unused matrices of size #Smr^2 deleted
    rm(piSmr_mat, covarpSmr)
  }
    # If we use the m1 and m2 outcomes
    # We will need here have to estimate the counterfactuals
    # on Sr (y_2k) and Smr (y_2k) by single matching with Z
  else
  {
    # If Y1 = Y2 on U we can set Y1Est = Y2Est on Sa equal
    # to the vector of observed values Yobs
    if (eqPotOut)
      Y1Est <- Y2Est <- Yobs[maskSa]
    else
    {
      YEst <- estim_counterfactuals(Yobs, modes, Z, ...)
      Y1Est <- YEst[maskSa, "Y1Est"]
      Y2Est <- YEst[maskSa, "Y2Est"]
      rm(YEst)
    }
    
    
    phiY1SaEst <- phi[maskSa] * Y1Est
    phibarY2SaEst <- phibar[maskSa] * Y2Est
    
    piSa_mat <- pi_mat[maskSa, maskSa, drop = FALSE]
    covarpSa <- pi2_to_covarInc(piSa_mat)
    
    
    # The variance estimator is the weighted average of 
    # the variance estimator based on Sr and the one based on Smr
      # Sr
    PhiYSr <- phiY1SaEst[maskm1Sa] + phibarY2SaEst[maskm1Sa]
    correctedPhiYSrp <- 
      (piSr * p1Sr)^-1L * PhiYSr
    
    varpSrEst <-
      t(correctedPhiYSrp) %*%
      (covarpSr / piSr_mat) %*%
      correctedPhiYSrp %>%
      as.numeric()
    varpSrEst <- varpSrEst + 
      sum((1.0 - piSr) * piSr^-2L * p1Sr^-1L * (1.0 - p1Sr^-1L) *
            PhiYSr^2L)
    
      # Smr
    PhiYSmr <- phiY1SaEst[!maskm1Sa] + phibarY2SaEst[!maskm1Sa]
    correctedPhiYSmrp <- 
      (piSmr * p1barSmr * p2Smr)^-1L * PhiYSmr
    
    varpSmrEst <-
      t(correctedPhiYSmrp) %*%
      (covarpSmr / piSmr_mat) %*%
      correctedPhiYSmrp %>%
      as.numeric()
    varpSmrEst <- varpSmrEst +
      sum((1.0 - piSmr) * piSmr^-2L * (p1barSmr * p2Smr)^-1L *
            (1.0 - (p1barSmr * p2Smr)^-1L) * PhiYSmr^2L)
    
    varpEst <- weightSrEstVp * varpSrEst + (1.0 - weightSrEstVp) * varpSmrEst
    
    rm(piSr_mat, covarpSr, piSmr_mat, covarpSmr)
  }
  
  
  # m1 selection variability (q1, R1)
  if  (correcEW1)
  {
    ZSr <- Z[maskSr, , drop = FALSE]
    estLinCoefq1 <- 0.0
    if (!m2Only)
    {
      estVPhi11 <- -crossprod(ZSr,
                              (piSr * p1Sr)^-1L *
                                phiY1Sr * (1.0 - p1Sr))

      
      estbPhi11 <- solve(Fisher_Information_Matrix(p1, Z, I)) %*% 
        estVPhi11
      
      estLinCoefq1 <- estLinCoefq1 + estbPhi11
    }
    
    if (!m1Only)
    {
      ZSmr <- Z[maskSmr, , drop = FALSE]
      estVPhibar21 <- crossprod(ZSmr,
                                (piSmr * (1.0 - p1Smr) * p2Smr)^-1L *
                                  phibarY2Smr * p1Smr)
      
      estbPhibar21 <- solve(Fisher_Information_Matrix(p1, Z, I)) %*% 
        estVPhibar21
      
      estLinCoefq1 <- estLinCoefq1 + estbPhibar21
    }
  }
    # If we use only the m1 outcomes
    # (we do not weight by phi)
  if (m1Only)
  {
    
    correctedY1Srq1 <- correctedY1Srp
    
    if (correcEW1)
      correctedY1Srq1 <- correctedY1Srq1 + ZSr %*% estLinCoefq1
    
    varq1Est <- sum((1.0 - p1Sr) * correctedY1Srq1^2L)
  }
    # If we use only the m2 outcomes
    # (we do not weight by phi)
  else if (m2Only)
  {
    correctedY2Smrq1 <- (piSmr * p1barSmr)^-1L * Y2Smr
    
    if (correcEW1)
      correctedY2Smrq1 <- correctedY2Smrq1 - ZSmr %*% estLinCoefq1
    
    varq1Est <- sum(p1Smr * p2Smr^-1L * correctedY2Smrq1^2L)
  }
    # If we use the m1 and m2 outcomes, we will use the estimations
    # of the counterfactuals. As the estimation of the variability due
    # to the sampling design, we consider the weighted average of 
    # the variance estimator based on Sr and the one based on Smr
  else
  {
     correctedPhiYSaq1 <- piSa^-1L * 
       (p1Sa^-1L * phiY1SaEst - p1barSa^-1L * phibarY2SaEst)
     
     if (correcEW1)
     {
       correctedPhiYSaq1 <- 
         correctedPhiYSaq1 + Z[maskSa, , drop = FALSE] %*% estLinCoefq1
     }
    
      weightsq1 <- numeric(na)
      weightsq1[maskm1Sa] <- weightSrEstVq1 * (1.0 - p1Sr)
      weightsq1[!maskm1Sa] <- (1.0 - weightSrEstVq1) * (p1Smr * p2Smr^-1L)
      
      varq1Est <- sum(weightsq1 * correctedPhiYSaq1^2L)
  }
  
  
  # m2 selection variability (q2, R2)
  # There is variability only if we consider m2. We do not need
  # to use counterfactuals estimators
  if (!m1Only)
  {
    correctedY2Smrq2 <- (piSmr * p1barSmr * p2Smr)^-1L * phibarY2Smr
    if (correcEW2)
    {
      estVPhibar22 <- -crossprod(ZSmr,
                          (piSmr * (1.0 - p1Smr) * p2Smr)^-1L *
                            (1.0 - p2Smr) * phibarY2Smr)

      maskSm <- I & !maskSr
      
      estbPhibar22 <- 
        solve(Fisher_Information_Matrix(p2, Z, maskSm)) %*% estVPhibar22
      
      correctedY2Smrq2 <- correctedY2Smrq2 + ZSmr %*% estbPhibar22
    }
    
    varq2Est <- sum((1.0 - p2Smr) * correctedY2Smrq2^2L)
  }
  else
    varq2Est <- 0.0
  
  
  # Potential outcomes variability
  if (sd1 <= 0.0 || sd2 <= 0.0)
    cov12 <- 0.0
  
  # We use the mean of the phi_k in case some of them are unknown
  # (if they are all known it becomes ||phi||_2^2, <phi, 1 - phi>
  # and ||1 - phi||_2^2)).
  varphiYEst <- 
    mean(phi^2L, na.rm = TRUE) * N * sd1^2L +
    2.0 * mean(phi * phibar, na.rm = TRUE) * N * cov12 +
    mean(phibar^2L, na.rm = TRUE) * N * sd2^2L
  
  
  varpEst + varq1Est + varq2Est + varphiYEst
}
```

```{r}
#' Estimation of the variance of t_e1 and the approximate variance 
#' of t_pq1
#' 
#' 
#' HOMOSCEDASTICITY
#' @param Yobs vector of the observed outcomes. For the non-respondents
#' the value is not considered and therefore can be equal to NA
#' (numeric vector of size N the size of the population).
#' @param modes 
#' @param pi_mat matrix containing the second order inclusion probabilities
#' pi_kl. The values must be known on Sr^2 and can be equal to NA otherwise
#' (symmetric numeric matrix of order N).
#' @param p1 vector containing the true or estimated probabilities p_1k.
#' Can be equal to NA for the units that didn't answer by m1
#' (numeric vector of size N).
#' @param sd1 true or estimated value (from a consistent estimator if possible)
#' of the standard deviation of the m1 potential outcomes (positive scalar).
#' @param correcEW1 TRUE if we must apply a correction due to the
#' use of estimations of `p1` (boolean).
#' @param I vector containing the indicators I_k equal to TRUE if unit k
#' has been selected. Used only if `correcEW1` = TRUE
#' (logical vector of size N).
#' @param Z design matrix. Used only when `correcEW1` = TRUE
#' (numeric matrix with N rows and q columns).
#' @param m1Only TRUE if we estimate the variance of t_{pq1} and only with
#' the m1 respondents (boolean).
#' @param m2Only TRUE if we estimate the variance of t_{pq2} and only with
#' the m2 respondents (boolean).
#' @param ... arguments for the function `MatchIt::matchit`.
estim_appr_var_seq_m1 <- function(Yobs, modes, 
                                  pi_mat, 
                                  p1, sd1,
                                  correcEW1 = TRUE,
                                  I,
                                  Z = matrix(1.0, 
                                             nrow = length(Yobs), ncol = 1L),
                                  ...)
{
  estim_appr_var_seq_m1_m2(Yobs, modes, 
                           pi_mat, 
                           p1, p2 = NULL,
                           sd1,
                           sd2 = 0.0,
                           cov12 = 0.0,
                           phi = rep(1.0, length(Yobs)),
                           eqPotOut = NULL,
                           correcEW1,
                           correcEW2 = FALSE,
                           I,
                           Z,
                           m1Only = TRUE,
                           ...)
}
```

```{r}
estim_appr_var_seq_m2 <- function(Yobs, modes, 
                                  pi_mat, 
                                  p1, p2, sd2,
                                  correcEW1 = TRUE,
                                  correcEW2 = TRUE,
                                  I,
                                  Z = matrix(1.0, 
                                             nrow = length(Yobs), ncol = 1L),
                                  ...)
{
  estim_appr_var_seq_m1_m2(Yobs, modes, 
                           pi_mat, 
                           p1, p2,
                           sd1 = 0.0,
                           sd2,
                           cov12 = 0.0,
                           phi = numeric(length(Yobs)),
                           eqPotOut = NULL,
                           correcEW1,
                           correcEW2,
                           I,
                           Z,
                           m2Only = TRUE,
                           ...)
}
```

```{r}
#' Is assumed that Y1 = Y2
estim_appr_var_seq_a <- function(Yobs,
                                 responses,
                                 pi_mat,
                                 pa,
                                 sd = NULL,
                                 correcEW = TRUE,
                                 I,
                                 Z = matrix(1.0, nrow = length(Yobs), ncol = 1L),
                                 ...)
{
  responses[responses == "r"] <- "m1"
  
  estim_appr_var_seq_m1(Yobs, responses,  
                        pi_mat, pa, sd,
                        correcEW,
                        I,
                        Z,
                        ...)
}
```


## Expansion estimators true variance

CONDITIONS INDEPENDANCE HOMOSCEDASTICITE

```{r}
var_expansion_m1_m2 <- function(Y1exp, Y2exp, 
                                pi_mat, 
                                p1, p2, 
                                sd1 = 0.0, sd2 = 0.0, cov12 = sd1 * sd2, 
                                phi = rep(0.5, length(Y1exp)))
{
  pi <- diag(pi_mat)
  
  p1bar <- 1.0 - p1
  
  phibar <- 1.0 - phi
  
  covarPi <- pi2_to_covarInc(pi_mat)
  
  
  # Sampling design variability (p, S)
  correctedY1p <- pi^-1L * (phi * Y1exp + phibar * Y2exp)
  varp <- as.numeric(t(correctedY1p) %*% covarPi %*% correctedY1p) +
    sum(pi^-1L * (1.0 - pi) * 
          (phi^2L * sd1^2L + phibar^2L * sd2^2L +
             2.0 * phi * phibar * cov12))
  
  # m1 selection variability (q1, R1)
  # with the independence between p and q1
  # Variance of the term phik y1k / p1k - phikbar y2k / p1kbar
  varCorrectedDifference <- 
    (p1^-2L * phi^2L * sd1^2L + 
       p1bar^-2L * phibar^2L * sd2^2L -
       2.0 * (p1 * p1bar)^-1L * phi * phibar * cov12)
  varq1 <- 
    sum(pi^-1L * p1 * p1bar * 
    (varCorrectedDifference + 
       (p1^-1L * phi * Y1exp - p1bar^-1L * phibar^2L * Y2exp)^2L))
     
    
  # m2 selection variability (q2, R2)
  # with the conditional independence between p and q1 ; and q1 and q2
  if (any(phibar > 0.0))
  {
    varPhibarY2 <- phibar^2L * (sd2^2L + Y2exp^2L) # Variance of each phikbar y_2k
    varq2 <- sum((pi * p1bar * p2)^-1L * (1.0 - p2) * varPhibarY2)
  }
  else
    varq2 <- 0.0
  
  # potential outcomes variability
  varPhiY <- 
    sum(phi^2L) * sd1^2L +
    2.0 * sum(phi * phibar) * cov12 +
    sum(phibar^2L) * sd2^2L
  
  varp + varq1 + varq2 + varPhiY
}
```

```{r}
var_expansion_m1 <- function(Y1exp, 
                             pi_mat, 
                             p1, 
                             sd1 = 0.0,
                             phi = rep(1.0, length(Y1exp)))
{
  var_expansion_m1_m2(Y1exp, Y2exp = numeric(length(Y1exp)), 
                      pi_mat,
                      p1, p2 = NULL, 
                      sd1, sd2 = 0.0, cov12 = 0.0, 
                      phi)
}
```


```{r}
var_expansion_m2 <- function(Y2exp, 
                             pi_mat, 
                             p1, p2, 
                             sd2 = 0.0, 
                             phi = rep(1.0, length(Y2exp)))
{
  var_expansion_m1_m2(Y1exp = numeric(length(Y2exp)), Y2exp, 
                      pi_mat, 
                      p1, p2, 
                      sd1 = 0.0, sd2, cov12 = 0.0, 
                      1.0 - phi)
}
```



```{r}
# var_expansion_m1 <- function(Y1exp,
#                              pi_mat,
#                              p1,
#                              sd1 = 0.0,
#                              phi = rep(1.0, length(Y1exp)))
# {
#   pi <- diag(pi_mat)
#   
# 
#   # Sampling design variability (p, S)
#   covarPi <- pi2_to_covarInc(pi_mat)
#   correctedY1p <- pi^-1L * phi * Y1exp
#   varp <- as.numeric(t(correctedY1p) %*% covarPi %*% correctedY1p) +
#     sum(pi^-1L * (1.0 - pi) * phi^2L) * sd1^2L
# 
#   # m1 selection variability (q1, R1)
#   # with the independence between p and q1
#   varq1 <- sum((pi * p1)^-1L * (1.0 - p1) * phi^2L * (sd1^2L + Y1exp^2L))
# 
#   # Y1 variability
#   varY1 <- sum(phi^2L) * sd1^2L
# 
#   varp + varq1 + varY1
# }
```

```{r}
# var_expansion_m2 <- function(Y2exp,
#                              pi_mat,
#                              p1, p2,
#                              sd2 = 0.0,
#                              phi = rep(1.0, length(Y2exp)))
# {
#   pi <- diag(pi_mat)
#   p1bar <- 1.0 - p1
# 
#   # Sampling design variability (p, S)
#   covarPi <- pi2_to_covarInc(pi_mat)
#   correctedY2p <- pi^-1L * phi * Y2exp
#   varp <- as.numeric(t(correctedY2p) %*% covarPi %*% correctedY2p) +
#     sum(pi^-1L * (1.0 - pi) * phi^2L) * sd2^2L
# 
#   # m1 selection variability (q1, R1)
#   varPhiY2 <- phi^2L * (sd2^2L + Y2exp^2L) # Variance of each phi_k y_2k
#   varq1 <- sum((pi * p1bar)^-1L * p1 * varPhiY2)
# 
#   # m2 selection variability (q2, R2)
#   varq2 <- sum((pi * p1bar * p2)^-1L * (1.0 - p2) * varPhiY2)
# 
#   # Y2 variability
#   varY2 <- sum(phi^2L) * sd2^2L
# 
#   varp + varq1 + varq2 + varY2
# }
```

```{r}
var_expansion_a <- function(Yexp,
                            pi_mat,
                            pa,
                            sd = 0.0)
{
  var_expansion_m1(Yexp, pi_mat, pa, sd)
}
```


# Simulation
## Division in stratum

Because we will consider STSRS, we decide to divide our population into 4 stratum of size (1000, 2000, 3000, 4000) (as did in Kim & Kim 2007). We will take the 1000 first units (order inceasingly by `age`) for the first strata, etc.

With k-means on `age`, we obtain 4 strata of approximately the same size (i.e. 2500), then correspond approximately to dividing by the quartiles of `age`. With k-means on `sex` and `age`, we have two clusters per sex.

```{r}
nbStrata <- 4L
orderAge <- order(Z[, "age"])
strata <- integer(N)
strata[orderAge[seq_len(1000L)]] <- 1L
strata[orderAge[seq(1001L, 3000L)]] <- 2L
strata[orderAge[seq(3001L, 6000L)]] <- 3L
strata[orderAge[seq(6001L, 10000L)]] <- 4L
rm(orderAge)
```

```{r}
Z %>% 
  as.data.frame() %>% 
  mutate(stratum = strata) %>% 
  group_by(stratum) %>% 
  summarise(n = n(),
            minAge = min(age),
            avgAge = mean(age),
            maxAge = max(age),
            percMen = 100.0 * mean(sex))
```

We will consider the same number of sample units ($n / 4$) per stratum.

## Grid of parameters

```{r}
R_Sp <- function(Z, beta, epsilon)
{
  Y <- Z %*% beta + epsilon
  1.0 - sum(epsilon^2L) / sum((Y - mean(Y))^2L)
}
```

Random generation of potential outcomes vectors, considered fixed afeter, in order to have $R²$ close to 0.2 and 0.5, respectively. Variables are not dependent because values are corrected in order to have a total $t_y$ equal to $N$.

```{r}
set.seed(123L)
epsilon0.2 <- rnorm(N, mean = 0.0, sd = 6.43)
Y0.2 <- Z %*% beta + epsilon0.2
Y0.2 <- Y0.2 - (sum(Y0.2) - N) / N
R_Sp(Z, beta, epsilon0.2)
epsilon0.5 <- rnorm(N, mean = 0.0, sd = 3.27)
Y0.5 <- Z %*% beta + epsilon0.5
Y0.5 <- Y0.5 - (sum(Y0.5) - N) / N
R_Sp(Z, beta, epsilon0.5)
rm(epsilon0.2, epsilon0.5)
```

```{r}
R_Sp(Z, beta, rnorm(N, mean = 0.0, sd = 5.0))
```

```{r}
samplingDesign_vec <- c("SRS", "STSRS")
R_Sp_vec <- c(0.2, 0.5)
ratio_n_vec <- c(0.16, 0.25, 0.4)
n_vec <- as.integer(ratio_n_vec * N)

parameters <- tidyr::expand_grid(R_Sp = R_Sp_vec, 
                                 samplingDesign = samplingDesign_vec, 
                                 n = n_vec)

parameters <- as.data.frame(parameters)
```

```{r}
head(parameters)
glue("Size of the grid: {nrow(parameters)} iterations.")
```

## Simulation function

```{r}
simulation_tphi <- function(Z,
                            samplingDesign = "SRS",
                            alpha1, alpha2,
                            alphaa = alpha1,
                            beta, 
                            sd1 = 1.0, sd2 = sd1, 
                            rho = 0.8,
                            phi = rep(0.5, N), 
                            M = 10^4L,
                            n = ceiling(N / 10L),
                            strata = NULL,
                            seed = 123L,
                            nCores = detectCores() - 1L,
                            calcVariance = TRUE,
                            Y = NULL)
{
  set.seed(seed)
  
  N <- nrow(Z)
  q <- ncol(Z)
  
  expit <- function(x) 1.0 / (1.0 + exp(-x))

  # Sequential logistic model
  p1 <- expit(Z %*% alpha1) %>% as.numeric()
  p2 <- expit(Z %*% alpha2) %>% as.numeric()
  # Global logistic model
  pa <- expit(Z %*% alphaa) %>% as.numeric()
  
  if (sd1 == 0.0 && sd2 == 0.0)
  {
    rho <- 1.0
    if (is.null(Y))
      Y <- Yexp <- Z %*% beta
    else
      Yexp <- Y
  }
  else
    Yexp <- Z %*% beta
  
  # Case when Y1 = Y2 (almost surely, conditionally to X): the variance
  # estimation changes because there is no counterfactual that needs
  # to be estimated
  eqPotOut <- sd1 == sd2 && rho == 1.0
  
  if (samplingDesign == "SRS")
  {
    pi <- rep(n / N, N)
    pi_mat <- piMat_SRS(n, N)
  }
  
  else if (samplingDesign == "STSRS")
  {
    pi_mat <- matrix(0.0, nrow = N, ncol = N)
    for (stratum in unique(strata))
    {
      nStratum <- n[stratum]
      NStratum <- sum(strata == stratum)
      pi_mat[which(strata == stratum), 
             which(strata == stratum)] <- piMat_SRS(nStratum, NStratum)
    }
    
    pi <- diag(pi_mat)
  }
  
  
  # Variance matrix of the potential outcomes for one unit, for the vector
  # (y_1k, y_2k)^T
  varYUnit_mat <- matrix(c(sd1^2L, rho * sd1 * sd2, rho * sd1 * sd2, sd2^2L),
                         nrow = 2L, ncol = 2L)
  rownames(varYUnit_mat) <- colnames(varYUnit_mat) <- c("y1k", "y2k")

  monoSim <- function(...)
  {
    if (samplingDesign == "SRS")
    {
      selectedSample <- sample(seq_len(N), size = n, replace = FALSE)
      
      I <- logical(N)
      I[selectedSample] <- TRUE
      rm(selectedSample)
    }
    
    else if (samplingDesign == "STSRS")
    {
      I <- logical(N)
      for (stratum in unique(strata))
      {
        selectedSampleStratum <- 
          sample(which(strata == stratum), size = n[stratum], replace = FALSE)
        I[selectedSampleStratum] <- TRUE
      }
      rm(selectedSampleStratum)
    }
    
    
    dataModes <- gen_choice_bimode(I, p1, p2, Z)
    modes <- dataModes$mode
    
    maskSr <- modes == "m1"
    n1 <- sum(maskSr)
    maskSmr <- modes == "m2"
    n2 <- sum(maskSmr)
    
    ## trueProbsSelect <- dataModes$probSelect
    
    rm(dataModes)
    
    ## trueWeights <- (pi * trueProbsSelect)^-1L
  
    # Estimation of mode selection probabilities p1k and p2k 
    # (logistic regression)
    estimProbsData <-
      MMsampling::estim_response_prob_sequential(I, Z,
                                                 modes,
                                                 c("m1", "m2"),
                                                 chosenOnly = FALSE)
    
    # Generating values for Y_int and Y_tel
    if (sd1 == 0.0 && sd2 == 0.0)
      Y1 <- Y2 <- Y
    else
    {
      # Generation for each unit of independent couples (e_1k, e_2k) 
      # with centered multivariate normal distribution and as variance
      # the variance of the couple (y_1k, y_2k) 
      YpotOutRes_mat <- 
        mvtnorm::rmvnorm(n = N, 
                         mean = numeric(2L), sigma = varYUnit_mat,
                         checkSymmetry = FALSE)
      
        # Changing the expectations to have the potential outcomes :
        # y_1k = E[y_k | Z] + e_1k and y_1k = E[y_k | Z] + e_2k
      Y1 <- Yexp + YpotOutRes_mat[, 1L]
      names(Y1) <- paste0("y1", seq_len(N))
      
      Y2 <- Yexp + YpotOutRes_mat[, 2L]
      names(Y2) <- paste0("y2", seq_len(N))
      
      rm(YpotOutRes_mat)
      
      if (sd1 == sd2 && rho == 1.0)
        Y2 <- Y1
    }
    
    # Creating the observed outcome vector
    Yobs <- rep(NA_real_, N)
    Yobs[maskSr] <- Y1[maskSr]
    Yobs[maskSmr] <- Y2[maskSmr]
    names(Yobs) <- paste0("yobs", seq_len(N))
    
    # Estimations with Y1 (total of the y_1k)
      # If we have `sd1` = 0 we consider the deterministic case
    if (sd1 == 0.0)
      estimsd1 <- 0.0
    else
      estimsd1 <- summary.lm(lm(Yobs ~ Z, subset = maskSr))$sigma
    
     # With true probabilities
    tot1TW <- estim_tot_m1(Yobs, modes, pi, p1)
    

    if (calcVariance)
    {
      # The variance of Y1 is assumed known. The true probabilities are
      # used in the calculation.
      apprVar1TW <-
        estim_appr_var_seq_m1(Yobs,
                              modes,
                              pi_mat,
                              p1,
                              estimsd1,
                              correcEW1 = FALSE)
    }
    else
      apprVar1TW <- NA_real_
    
      # With estimated probabilities
    estimp1 <- estimProbsData$conditional[, "m1"]
    tot1EW <- estim_tot_m1(Yobs, modes, pi, estimp1)
    

    if (calcVariance)
    {
      # The variance of Y1 is assumed known.
      apprVar1EW <-
        estim_appr_var_seq_m1(Yobs,
                              modes,
                              pi_mat,
                              estimp1,
                              estimsd1,
                              correcEW1 = TRUE,
                              I,
                              Z)
    }
    else
      apprVar1EW <- NA_real_
    
    # Estimations with Y2 (total of the y_2k)
      # If we have `sd2` = 0 we consider the deterministic case
    if (sd2 == 0.0)
      estimsd2 <- 0.0
    else
      estimsd2 <- summary.lm(lm(Yobs ~ Z, subset = maskSmr))$sigma
    
      # With true probabilities
    tot2TW <- estim_tot_m2(Yobs, modes, pi, p1, p2)
    
    
    if (calcVariance)
    {
      # The variance of Y2 is assumed known. The true probabilities are
      # used in the calculation.
      apprVar2TW <-
        estim_appr_var_seq_m2(Yobs,
                              modes,
                              pi_mat,
                              p1,
                              p2,
                              estimsd2,
                              correcEW1 = FALSE,
                              correcEW2 = FALSE)
    }
    else
      apprVar2TW <- NA_real_
    
      # With estimated probabilities
    estimp2 <-  estimProbsData$conditional[, "m2"]
    tot2EW <- estim_tot_m2(Yobs, modes, pi, estimp1, estimp2)
    
    if (calcVariance)
    {
      # The variance of Y1 is assumed known.
      apprVar2EW <-
        estim_appr_var_seq_m2(Yobs,
                              modes,
                              pi_mat,
                              estimp1,
                              estimp2,
                              estimsd2,
                              correcEW1 = TRUE,
                              correcEW2 = TRUE,
                              I,
                              Z)
    }
    else
      apprVar2EW <- NA_real_
    

    # Estimations with the global logistic model

    Ra <- runif(n = N) <= pa
    # "r" if unit k would agree to answer by any mode
    # if asked
    respStat <- if_else(Ra, "r", "nr") 
  
    maskSa <- I & Ra
    # "r" if unit k answered by any mode
    answers <- if_else(maskSa, "r", "nr")
  
    YobsEq <- rep(NA_real_, N)
    YobsEq[maskSa] <- Y1[maskSa]
    
    # If `sd1` and `sd2` are equal to zero, we consider 
      # the deterministic case
    if (sd1 == 0.0 && sd2 == 0.0)
      estimsd <- 0.0
    else
      estimsd <- summary.lm(lm(YobsEq ~ Z, subset = maskSa))$sigma
  
    # With true probabilities
    totaTW <- estim_tot_a(YobsEq, answers, pi, pa)
    
    if (calcVariance)
    {
      # Unbiased estimation of the variance of the total estimator.
      # The variance of Y is assumed known. The true probabilities are
      # used in the calculation.
      apprVaraTW <-
        estim_appr_var_seq_a(YobsEq,
                             answers,
                             pi_mat,
                             pa,
                             estimsd,
                             correcEW = FALSE)
    }
    else
      apprVaraTW <- NA_real_

    # With estimated probabilities
    dataEstimpa <- 
      cbind(response = as.integer(maskSa), Z) %>% 
      as.data.frame()
    model <- glm(response ~ Z, data = dataEstimpa,
                 family = binomial, subset = I)
    estimpa <- predict(model, newdata = as.data.frame(Z), type = "response")
    rm(dataEstimpa, model)
  
    totaEW <- estim_tot_a(YobsEq, answers, pi, estimpa)
    
    if (calcVariance)
    {
      # Unbiased estimation of the variance of the total estimator.
      # The variance of Y is assumed known. The true probabilities are
      # used in the calculation.
      apprVaraEW <-
        estim_appr_var_seq_a(YobsEq,
                             answers,
                             pi_mat,
                             estimpa,
                             estimsd,
                             correcEW = TRUE,
                             I,
                             Z)
    }
    else
      apprVaraEW <- NA_real_
    
    # Estimations with Y1 and Y2 weighted
      # If `sd1` and `sd2` are equal to zero, we consider 
      # the deterministic case
    if (sd1 == 0.0 && sd2 == 0.0)
      estimcov12 <- 0.0
    else
    {
      estimcov12 <- 
      estim_cov_12(Yobs = Yobs, modes = modes, 
                   sd1 = estimsd1, sd2 = estimsd2, Z = Z, clamp = FALSE)
    }
    
      # With true probabilities
    totPhiTW <- estim_tot_m1_m2(Yobs, modes, pi, p1, p2, phi)
    # Case phi = #S_r. / #S_a
    phiSize <- rep(sum(maskSr) / (sum(maskSr) + sum(maskSmr)), N)
    totPhiSizeTW <- estim_tot_m1_m2(Yobs, modes, pi, p1, p2, phiSize)
    # Case phi = p1, which gives the estimator 
    # t^ = \sum_{k \in \Sr} y_{1k} / pi_k 
    #  + \sum_{k \in \Sr} y_{2k} / (pi_k p_2k)
    totNop1TW <- estim_tot_m1_m2(Yobs, modes, pi, p1, p2, phi = p1)
    
    if (calcVariance)
    {
      apprVarPhiTW <- 
        estim_appr_var_seq_m1_m2(Yobs,
                                 modes,
                                 pi_mat,
                                 p1,
                                 p2,
                                 estimsd1,
                                 estimsd2,
                                 estimcov12,
                                 phi,
                                 eqPotOut,
                                 correcEW1 = FALSE,
                                 correcEW2 = FALSE)
      
      apprVarPhiSizeTW <- 
        estim_appr_var_seq_m1_m2(Yobs,
                                 modes,
                                 pi_mat,
                                 p1,
                                 p2,
                                 estimsd1,
                                 estimsd2,
                                 estimcov12,
                                 phiSize,
                                 eqPotOut,
                                 correcEW1 = FALSE,
                                 correcEW2 = FALSE)
      
      apprVarNop1TW <- 
        estim_appr_var_seq_m1_m2(Yobs,
                                 modes,
                                 pi_mat,
                                 p1,
                                 p2,
                                 estimsd1,
                                 estimsd2,
                                 estimcov12,
                                 phi = p1,
                                 eqPotOut,
                                 correcEW1 = FALSE,
                                 correcEW2 = FALSE)
    }
    else
      apprVarPhiTW <- apprVarPhiSizeTW <- apprVarNop1TW <- NA_real_
    
      # With estimated probabilities
    totPhiEW <- estim_tot_m1_m2(Yobs, modes, pi, estimp1, estimp2, phi)
    totPhiSizeEW <- estim_tot_m1_m2(Yobs, modes, pi, estimp1, estimp2, phiSize)
    # For phi = p1, we do not estimate the probabilities p1k
    totNop1EW <- estim_tot_m1_m2(Yobs, modes, pi, p1, estimp2, phi = p1)
    if (calcVariance)
    {
      apprVarPhiEW <- 
        estim_appr_var_seq_m1_m2(Yobs,
                                 modes,
                                 pi_mat,
                                 estimp1,
                                 estimp2,
                                 estimsd1,
                                 estimsd2,
                                 estimcov12,
                                 phi,
                                 eqPotOut,
                                 correcEW1 = TRUE,
                                 correcEW2 = TRUE,
                                 I,
                                 Z)
      
      apprVarPhiSizeEW <- 
        estim_appr_var_seq_m1_m2(Yobs,
                                 modes,
                                 pi_mat,
                                 estimp1,
                                 estimp2,
                                 estimsd1,
                                 estimsd2,
                                 estimcov12,
                                 phiSize,
                                 eqPotOut,
                                 correcEW1 = TRUE,
                                 correcEW2 = TRUE,
                                 I,
                                 Z)
      
      apprVarNop1EW <- 
        estim_appr_var_seq_m1_m2(Yobs,
                                 modes,
                                 pi_mat,
                                 p1, # True value of p1
                                 estimp2,
                                 estimsd1,
                                 estimsd2,
                                 estimcov12,
                                 phi = p1,
                                 eqPotOut,
                                 correcEW1 = TRUE,
                                 correcEW2 = TRUE,
                                 I,
                                 Z)
    }
    else
      apprVarPhiEW <- apprVarPhiSizeEW <- apprVarNop1EW <- NA_real_
    
    
    tibble(estimator = c("tot1TW", "tot1EW", 
                         "tot2TW", "tot2EW", 
                         "totaTW", "totaEW",
                         "totphiTW", "totphiEW",
                         "totphiSizeTW", "totphiSizeEW",
                         "totNop1TW", "totNop1EW"),
           sample = rep(c("Sr.", "Smr", "Sa", "Sa", "Sa", "Sa"), each = 2L),
           mechanism = rep(c("sequential_logistic", "sequential_logistic", 
                             "global_logistic", "sequential_logistic", 
                             "sequential_logistic", "sequential_logistic"),
                           each = 2L),
           estimand = rep(c("t_1", "t_2", "t_ay", 
                            "t_phiy", "t_phiSizey", "t_nop1y"), each = 2L),
           estimation = c(tot1TW, tot1EW, 
                          tot2TW, tot2EW, 
                          totaTW, totaEW,
                          totPhiTW, totPhiEW,
                          totPhiSizeTW, totPhiSizeEW,
                          totNop1TW, totNop1EW),
           apprVar = c(apprVar1TW, apprVar1EW, 
                       apprVar2TW, apprVar2EW,
                       apprVaraTW, apprVaraEW,
                       apprVarPhiTW, apprVarPhiEW,
                       apprVarPhiSizeTW, apprVarPhiSizeEW,
                       apprVarNop1TW, apprVarNop1EW)) %>% 
      mutate(weights = rep_len(c("true", "estimated"), length.out = n()),
             .after = "sample")
  }
  
  nCores <- min(nCores, M, detectCores() - 1L)
  if (nCores <= 1L)
    res <- lapply(seq_len(M), FUN = monoSim)
  else
    res <- mclapply(seq_len(M), FUN = monoSim, mc.cores = nCores)
    
  
  res <- do.call("rbind", res)
  
  trueVar1TW <- var_expansion_m1(Yexp, pi_mat, p1, sd1)
  
  trueVar2TW <- var_expansion_m2(Yexp, pi_mat, p1, p2, sd2)
  
  if (sd1 == sd2 && rho == 1.0)
    trueVaraTW <- var_expansion_a(Yexp, pi_mat, pa, sd1)
  else
    trueVaraTW <- NA_real_
  
  trueVarPhi <- var_expansion_m1_m2(Yexp, Yexp, 
                                    pi_mat, 
                                    p1, p2, 
                                    sd1, sd2, rho * sd1 * sd2, phi)
  
  trueVarNop1 <- var_expansion_m1_m2(Yexp, Yexp, 
                                     pi_mat, 
                                     p1, p2, 
                                     sd1, sd2, rho * sd1 * sd2, p1)
  
  trueVar <- rep.int(c(trueVar1TW, NA_real_, 
                       trueVar2TW, NA_real_,
                       trueVaraTW, NA_real_,
                       trueVarPhi, NA_real_,
                       NA_real_, NA_real_,
                       trueVarNop1, NA_real_),
                     times = M)
  
  res <- res %>% 
    mutate(expEstimand = sum(Yexp), .after = "estimand") %>% 
    mutate(trueVar = trueVar, .after = "apprVar") %>% 
    filter(!is.na(estimation))
  
  res
}
```

## Simulation

```{r}
Msim <- 2000L
```

The different lines of the grid have the same seed. It is useful to run in different orders the evaluations and because the results from different parameters are never mixed there is no independency issue.


If the number of parallel cores changes, the results might be different.

We define the case $\sigma_1 = \sigma_2$ and $\rho = 1$ as $Y_1 = Y_2$.

```{r}
resSimulation <- NULL
set.seed(200L)

pb <- progress::progress_bar$new(format = "[:bar] :percent eta: :eta",
                                 total = nrow(parameters),
                                 clear = TRUE)

pb$tick(0L)

constPhi <- 0.5
phi = rep(constPhi, N)

for (k in seq_len(nrow(parameters)))
{
  if (parameters[k, "R_Sp"] == 0.2)
    Y <- Y0.2
  else if (parameters[k, "R_Sp"] == 0.5)
    Y <- Y0.5
  
  if (parameters[k, "samplingDesign"] == "SRS")
    n <- parameters[k, "n"]
  else if (parameters[k, "samplingDesign"] == "STSRS")
  {
    if (!parameters[k, "n"] %% nbStrata == 0L)
      warning("Non-integer sample size n_h for STSRS. Ceiled.")
  
    n <- rep(ceiling(parameters[k, "n"] / nbStrata), nbStrata) %>% as.integer()
  }
    
  
  simFun <- function(calcVariance = TRUE)
  {
    simulation_tphi(M = Msim,
                    Z = Z,
                    samplingDesign = parameters[k, "samplingDesign"],
                    alpha1 = alpha1,
                    alpha2 = alpha2,
                    alphaa = alphaa,
                    beta = NULL,
                    phi = phi,
                    sd1 = 0.0,
                    sd2 = 0.0,
                    n = n,
                    strata = strata,
                    rho = 1.0,
                    seed = NULL,
                    nCores = 40L,
                    calcVariance = calcVariance,
                    Y = Y)
  }
  
  resTempWithVar <- simFun(calcVariance = TRUE) %>% mutate(subset = 1L)
  resTempWithoutVar <- simFun(calcVariance = FALSE) %>% mutate(subset = 2L)
  
  resSimulation <-
    cbind(parameters[k, ], 
          rbind(resTempWithVar, resTempWithoutVar), 
          row.names = NULL) %>% 
    rbind(resSimulation)
    

  pb$tick()
}

rm(pb, resTempWithVar, resTempWithoutVar, n, Y)

resSimulation <-
  resSimulation %>%
  mutate(phi = case_when(estimand == "t_1" ~ "1",
                         estimand == "t_2" ~ "0",
                         estimand == "t_phiy" ~ as.character(constPhi),
                         estimand == "t_phiSizey" ~ "size_Sr.",
                         estimand == "t_nop1y" ~ "p1",
                         TRUE ~ "/"),
         .after = "estimand")
  # arrange(n, sd1, sd2, rho)
```

## Properties of the estimators

The first subset will be used for the estimations of the expectation of the totals and the approximate variances via Monte Carlo. The second will be used for the estimation of the variance of the totals via Monte Carlo.

### Approximate unbiasedness of the total estimators

```{r}
resSimulation %>% 
  filter(subset == 1L) %>% 
  group_by(mechanism, R_Sp,
           samplingDesign, n,
           estimand, phi, sample, weights) %>% 
  summarise(M = n(),
            true_expectation = first(expEstimand),
            MC_expectation = mean(estimation, na.rm = TRUE)) %>% 
  # mutate(bias_MC = MC_expectation - true_expectation) %>% 
  mutate(ratio_MC_true = MC_expectation / true_expectation) %>% 
  ungroup()
```


Here we show average approximate variance and variance of different estimators, with no measure effect.

### Quality of the approximate variance estimators

```{r}
temp <- resSimulation %>% 
  mutate(estimation = if_else(subset == 1L, estimation, NA_real_)) %>% 
  filter(weights == "estimated") %>% 
  group_by(mechanism, R_Sp, samplingDesign, n,
           estimand, phi, sample) %>% 
  summarise(M = n() / 2L,
            MC_AV = mean(apprVar, na.rm = TRUE),
            MC_var = var(estimation, na.rm = TRUE),
            true_var = first(trueVar),) %>% 
  mutate(MC_AV_by_var = MC_AV / MC_var, MC_sd = sqrt(MC_var)) %>% 
  ungroup()

temp
```

### Which estimator should we use

Considering the approximate variance, on the last $M$ iterations

Only for the sequential logistic model. Consider the estimators with true and estimated probabilities.

```{r}
resSimulation %>% 
  filter(subset == 2L, mechanism == "sequential_logistic") %>% 
  group_by(R_Sp, samplingDesign, n, estimand, phi, weights) %>%
  summarise(MC_var = var(estimation, na.rm = TRUE)) %>% 
  group_by(R_Sp, samplingDesign, n) %>% 
  mutate(ratio_MC_var = max(MC_var) / min(MC_var)) %>% 
  slice_min(MC_var) %>% 
  arrange(estimand)
```

With estimated probabilities only:

```{r}
temp <- resSimulation %>% 
  filter(subset == 2L, 
         mechanism == "sequential_logistic", 
         weights == "estimated") %>% 
  group_by(R_Sp, samplingDesign, n, estimand, phi) %>%
  summarise(MC_var = var(estimation, na.rm = TRUE)) %>%
  group_by(R_Sp, samplingDesign, n) %>% 
  arrange(MC_var, .by_group = TRUE) %>% 
  slice(c(1L, n())) %>% 
  ungroup()

# For the final table we keep only one line for 
# the worst and the best estimator in each scenario
compareVar <- temp %>% 
  select(colnames(parameters)) %>% 
  slice(seq(1L, nrow(temp), 2L))

compareVar$bestEstimator <- compareVar$worseEstimator <- NA_character_
compareVar$ratio_MC_var <- NA_real_

for (k in seq_len(nrow(temp) / 2L))
{
  group <- temp %>% 
    slice(c(2L * k - 1L, 2L * k))
  
  compareVar$worseEstimator[k] <-
    group %>% 
    slice_max(MC_var) %>% 
    select(estimand) %>% 
    pull()
  
  compareVar$bestEstimator[k] <-
    group %>% 
    slice_min(MC_var) %>% 
    select(estimand) %>% 
    pull()
  
  compareVar$ratio_MC_var[k] <- max(group$MC_var) / min(group$MC_var)
}

rm(group)

compareVar
```

```{r}
rm(temp, compareVar)
```

